{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"tm2py-utils","text":"<p>Utilities and analysis tools for Travel Model Two (TM2)</p>"},{"location":"#overview","title":"Overview","text":"<p><code>tm2py-utils</code> provides a collection of utilities for working with Travel Model Two outputs, including:</p> <ul> <li>Summary Generation - Automated summary statistics from CTRAMP model outputs</li> <li>PopulationSim Integration - Synthetic population analysis and validation</li> <li>Network Analysis - Tools for analyzing transportation networks</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Clone repository\ngit clone https://github.com/BayAreaMetro/tm2py-utils.git\ncd tm2py-utils\n\n# Create conda environment\nconda env create -f environment.yml\nconda activate tm2py_utils\n\n# Install package\npip install -e .\n</code></pre> <p>See Installation Guide for detailed instructions.</p>"},{"location":"#generating-summaries","title":"Generating Summaries","text":"<pre><code># Navigate to validation directory\ncd tm2py_utils/summary/validation\n\n# Generate summaries for a model run\npython summarize_model_run.py \"C:/path/to/ctramp_output\"\n\n# View summaries (use Excel, Python, R, or other analysis tools)\n</code></pre> <p>\ud83d\udcda New to the validation system? Check out: - User Guide - Complete user guide - README.md - Toolkit overview - Summaries Guide - System documentation</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#summary-generation-system","title":"\ud83d\udcca Summary Generation System","text":"<p>Simple, transparent tool for generating validation summaries from CTRAMP model outputs:</p> <ul> <li>30 configured summaries covering households, tours, trips, and activity patterns</li> <li>Automatic validation with built-in quality checks</li> <li>Config-driven - Add summaries by editing YAML, no Python coding</li> <li>Fast - Process full model run in ~10 minutes</li> </ul> <pre><code># Generate all summaries for one model run\npython summarize_model_run.py \"C:/path/to/ctramp_output\"\n\n# Custom output location\npython summarize_model_run.py \"C:/path/to/ctramp_output\" --output \"my_results\"\n\n# Strict validation mode (treat warnings as errors)\npython summarize_model_run.py \"C:/path/to/ctramp_output\" --strict\n</code></pre> <p>See Summaries Guide for complete documentation.</p>"},{"location":"#populationsim-integration","title":"\ud83c\udfd8\ufe0f PopulationSim Integration","text":"<p>Analysis tools for synthetic population outputs:</p> <ul> <li>Household demographics (size, income, workers)</li> <li>Person demographics (age distribution)</li> <li>Geographic distribution by county</li> <li>Validation against ACS data</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Installation Guide</li> <li>Summaries User Guide - Start here for generating summaries</li> <li>Summary System Documentation</li> <li>Summary Design System Plan - Design principles and architecture</li> <li>Toolkit README</li> <li>Contributing</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>tm2py_utils/\n\u251c\u2500\u2500 summary/\n\u2502   \u251c\u2500\u2500 validation/                        # NEW: Simple validation toolkit\n\u2502   \u2502   \u251c\u2500\u2500 summarize_model_run.py        # Main tool - generates summaries\n\u2502   \u2502   \u251c\u2500\u2500 validate_summaries.py         # Quality checker\n\u2502   \u2502   \u251c\u2500\u2500 data_model/                   # Configuration files\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ctramp_data_model.yaml   # Summary definitions (edit here!)\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 variable_labels.yaml      # Display labels\n\u2502   \u2502   \u251c\u2500\u2500 outputs/                      # Generated summary CSVs\n\u2502   \u2502   \u251c\u2500\u2500 HOW_TO_SUMMARIZE.md          # User guide\n\u2502   \u2502   \u251c\u2500\u2500 README.md                     # Toolkit overview\n\u2502   \u2502   \u2514\u2500\u2500 archived_validation_system/   # Old multi-dataset comparison system\n\u2502   \u2514\u2500\u2500 core_summaries/                   # DEPRECATED (use validation/ instead)\n\u251c\u2500\u2500 inputs/                                # Input data preparation tools\n\u251c\u2500\u2500 requests/                              # Special analysis requests\n\u2514\u2500\u2500 docs/                                  # Documentation (this site)\n</code></pre>"},{"location":"#related-projects","title":"Related Projects","text":"<ul> <li>tm2py - Main Travel Model Two implementation</li> <li>PopulationSim - Synthetic population generator</li> <li>Bay Area UrbanSim - Land use model</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>MTC Contact: modeling@bayareametro.gov</li> </ul>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"configuration/","title":"Configuration Reference","text":"<p>Complete reference for <code>ctramp_data_model.yaml</code> and related configuration files used by the new validation toolkit.</p>"},{"location":"configuration/#overview","title":"Overview","text":"<p>The new validation system uses YAML configuration files to define: - Data file patterns and column mappings - Value labels (mode codes \u2192 mode names) - Aggregation rules (17 modes \u2192 5 categories) - Binning specifications (age \u2192 age groups) - Summary definitions (what to generate)</p> <p>Main configuration file: <code>data_model/ctramp_data_model.yaml</code></p> <p>No Python coding required - just edit YAML to customize summaries.</p>"},{"location":"configuration/#ctramp_data_modelyaml","title":"ctramp_data_model.yaml","text":"<p>Location: <code>tm2py_utils/summary/validation/data_model/ctramp_data_model.yaml</code></p>"},{"location":"configuration/#file-structure","title":"File Structure","text":"<pre><code># 1. Data source definitions\ndata_sources:\n  persons:\n    file_pattern: \"personData_{iteration}.csv\"\n    columns:\n      person_id: \"person_id\"\n      household_id: \"hh_id\"\n      # ... more columns\n\n# 2. Value mappings (codes to labels)\nvalue_mappings:\n  trip_mode:\n    type: categorical\n    values:\n      1: \"SOV_GP\"\n      2: \"SOV_PAY\"\n      # ... more values\n\n# 3. Aggregation rules\naggregation_specs:\n  trip_mode_agg:\n    source_column: \"trip_mode\"\n    mapping:\n      \"SOV_GP\": \"Auto\"\n      \"SOV_PAY\": \"Auto\"\n      # ... more mappings\n\n# 4. Binning specifications\nbinning_specs:\n  age:\n    breaks: [0, 5, 18, 25, 35, 45, 55, 65, 120]\n    labels: ['0-4', '5-17', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n\n# 5. Summary definitions\nsummaries:\n  auto_ownership_regional:\n    description: \"Regional auto ownership distribution\"\n    data_source: \"households\"\n    # ... more settings\n</code></pre>"},{"location":"configuration/#data-sources","title":"Data Sources","text":"<p>Define how to find and load CTRAMP output files.</p>"},{"location":"configuration/#structure","title":"Structure","text":"<pre><code>data_sources:\n  source_name:\n    file_pattern: \"fileName_{iteration}.csv\"\n    columns:\n      standardized_name: \"ctramp_column_name\"\n</code></pre>"},{"location":"configuration/#example","title":"Example","text":"<pre><code>data_sources:\n  individual_trips:\n    file_pattern: \"indivTripData_{iteration}.csv\"\n    columns:\n      trip_id: \"trip_id\"\n      trip_mode: \"trip_mode\"\n      tour_purpose: \"tour_purpose\"\n      trip_distance_miles: \"trip_distance_miles\"\n      depart_period: \"depart_period\"\n</code></pre> <p>The <code>{iteration}</code> placeholder is replaced automatically (e.g., <code>_1</code>, <code>_3</code>).</p>"},{"location":"configuration/#available-data-sources","title":"Available Data Sources","text":"Source Name File Pattern Description <code>persons</code> <code>personData_{iteration}.csv</code> Person-level data <code>households</code> <code>householdData_{iteration}.csv</code> Household-level data <code>individual_tours</code> <code>indivTourData_{iteration}.csv</code> Individual tour data <code>individual_trips</code> <code>indivTripData_{iteration}.csv</code> Individual trip data <code>joint_tours</code> <code>jointTourData_{iteration}.csv</code> Joint tour data <code>workplace_school_location</code> <code>wsLocResults.csv</code> Work/school location"},{"location":"configuration/#value-mappings","title":"Value Mappings","text":"<p>Map numeric codes to human-readable labels.</p>"},{"location":"configuration/#categorical-mappings","title":"Categorical Mappings","text":"<p>Numeric to text: <pre><code>value_mappings:\n  trip_mode:\n    type: categorical\n    values:\n      1: \"SOV_GP\"      # Drive alone, general purpose lanes\n      2: \"SOV_PAY\"     # Drive alone, toll lanes\n      3: \"SR2_GP\"      # Carpool 2, general purpose\n      4: \"SR2_HOV\"     # Carpool 2, HOV lanes\n      5: \"SR2_PAY\"     # Carpool 2, toll lanes\n      # ... more values\n</code></pre></p> <p>Text values (already labeled):</p> <pre><code>value_mappings:\n  person_type:\n    type: categorical\n    text_values:\n      - \"Full-time worker\"\n      - \"Part-time worker\"\n      - \"University student\"\n      - \"Non-worker\"\n      # ... more values\n</code></pre> <p>The system auto-detects numeric vs. text and applies the appropriate mapping.</p>"},{"location":"configuration/#common-value-mappings","title":"Common Value Mappings","text":"<p>Trip/Tour Modes: - 1-17: Different mode combinations (SOV, HOV, Transit, Walk, Bike, etc.)</p> <p>Tour Purpose: - Work, University, School, Escort, Shopping, Maintenance, Eating Out, Visiting, Discretionary, Work-Based</p> <p>Person Type: - Full-time worker, Part-time worker, University student, Non-worker, Retired, Student (high school), Student (grade school), Pre-school</p> <p>CDAP Activity: - Mandatory, Non-mandatory, Home</p>"},{"location":"configuration/#aggregation-specs","title":"Aggregation Specs","text":"<p>Group detailed categories into broader categories.</p>"},{"location":"configuration/#structure_1","title":"Structure","text":"<pre><code>aggregation_specs:\n  new_column_name:\n    source_column: \"original_column\"\n    mapping:\n      \"original_value_1\": \"new_category\"\n      \"original_value_2\": \"new_category\"\n      \"original_value_3\": \"different_category\"\n</code></pre>"},{"location":"configuration/#example-mode-aggregation","title":"Example: Mode Aggregation","text":"<pre><code>aggregation_specs:\n  trip_mode_agg:\n    source_column: \"trip_mode_name\"\n    mapping:\n      \"SOV_GP\": \"Auto\"\n      \"SOV_PAY\": \"Auto\"\n      \"SR2_GP\": \"Auto\"\n      \"SR2_HOV\": \"Auto\"\n      \"SR2_PAY\": \"Auto\"\n      \"SR3_GP\": \"Auto\"\n      \"SR3_HOV\": \"Auto\"\n      \"SR3_PAY\": \"Auto\"\n      \"Walk-Transit-Walk\": \"Transit\"\n      \"Walk-Transit-Drive\": \"Transit\"\n      \"Drive-Transit-Walk\": \"Transit\"\n      \"Drive-Transit-Drive\": \"Transit\"\n      \"Walk\": \"Active\"\n      \"Bike\": \"Active\"\n      \"School Bus\": \"School Bus\"\n</code></pre> <p>This creates a new column <code>trip_mode_agg</code> with 5 categories instead of 17.</p>"},{"location":"configuration/#binning-specs","title":"Binning Specs","text":"<p>Convert continuous variables into categorical bins.</p>"},{"location":"configuration/#structure_2","title":"Structure","text":"<pre><code>binning_specs:\n  column_name:\n    breaks: [0, 10, 20, 30, 100]     # Bin edges\n    labels: ['0-10', '10-20', '20-30', '30+']  # Bin labels\n</code></pre>"},{"location":"configuration/#example-age-bins","title":"Example: Age Bins","text":"<pre><code>binning_specs:\n  age:\n    breaks: [0, 5, 18, 25, 35, 45, 55, 65, 120]\n    labels: ['0-4', '5-17', '18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n</code></pre> <p>Creates a new column <code>age_bin</code> with 8 age groups.</p>"},{"location":"configuration/#example-distance-bins","title":"Example: Distance Bins","text":"<pre><code>binning_specs:\n  trip_distance_miles:\n    breaks: [0, 1, 3, 5, 10, 50, 1000]\n    labels: ['&lt;1mi', '1-3mi', '3-5mi', '5-10mi', '10-50mi', '50+mi']\n</code></pre> <p>Note: Number of labels must equal number of breaks minus 1.</p>"},{"location":"configuration/#summary-definitions","title":"Summary Definitions","text":"<p>Define what summaries to generate.</p>"},{"location":"configuration/#basic-structure","title":"Basic Structure","text":"<pre><code>summaries:\n  summary_name:\n    description: \"What this summary shows\"\n    data_source: \"individual_trips\"   # Which data table\n    group_by: \"trip_mode_name\"        # Column(s) to group by\n    aggregations:                      # What to calculate\n      trips:\n        column: \"trip_id\"\n        agg: \"count\"\n</code></pre>"},{"location":"configuration/#examples","title":"Examples","text":"<p>Simple count:</p> <pre><code>summaries:\n  auto_ownership_regional:\n    description: \"Regional auto ownership distribution\"\n    data_source: \"households\"\n    group_by: \"num_vehicles\"\n    aggregations:\n      households:\n        column: \"household_id\"\n        agg: \"count\"\n</code></pre> <p>Cross-tabulation:</p> <pre><code>summaries:\n  auto_ownership_by_income:\n    description: \"Auto ownership by income category\"\n    data_source: \"households\"\n    group_by:\n      - \"income_category_bin\"\n      - \"num_vehicles\"\n    aggregations:\n      households:\n        column: \"household_id\"\n        agg: \"count\"\n</code></pre> <p>With multiple aggregations:</p> <pre><code>summaries:\n  trip_distance_distribution:\n    description: \"Trip distance statistics\"\n    data_source: \"individual_trips\"\n    group_by: \"trip_distance_bin\"\n    aggregations:\n      trips:\n        column: \"trip_id\"\n        agg: \"count\"\n      mean_distance:\n        column: \"trip_distance_miles\"\n        agg: \"mean\"\n      total_distance:\n        column: \"trip_distance_miles\"\n        agg: \"sum\"\n</code></pre> <p>With filters:</p> <pre><code>summaries:\n  work_tour_mode:\n    description: \"Work tour mode choice\"\n    data_source: \"individual_tours\"\n    group_by: \"tour_mode_name\"\n    filters:\n      tour_purpose_name: [\"Work\"]\n    aggregations:\n      tours:\n        column: \"tour_id\"\n        agg: \"count\"\n</code></pre>"},{"location":"configuration/#available-aggregation-functions","title":"Available Aggregation Functions","text":"Function Description Example Use <code>count</code> Count rows Number of trips/tours/households <code>sum</code> Sum values Total distance traveled <code>mean</code> Average Average trip distance <code>median</code> Median value Median income <code>min</code> Minimum Shortest trip <code>max</code> Maximum Longest trip <code>std</code> Standard deviation Distance variability"},{"location":"configuration/#command-line-usage","title":"Command Line Usage","text":"<p>Generate summaries using the configured YAML:</p> <pre><code>cd tm2py_utils/summary/validation\npython summarize_model_run.py \"C:/path/to/ctramp_output\"\n</code></pre> <p>Options:</p> <pre><code>python summarize_model_run.py &lt;ctramp_dir&gt; [--output DIR] [--strict]\n</code></pre> Option Description Default <code>ctramp_dir</code> CTRAMP output directory (required) <code>--output DIR</code> Output directory <code>outputs/</code> <code>--strict</code> Treat warnings as errors <code>False</code>"},{"location":"configuration/#file-locations","title":"File Locations","text":"<pre><code>tm2py_utils/summary/validation/\n\u251c\u2500\u2500 summarize_model_run.py          # Main tool\n\u251c\u2500\u2500 validate_summaries.py           # Validation tool\n\u251c\u2500\u2500 data_model/\n\u2502   \u251c\u2500\u2500 ctramp_data_model.yaml     # MAIN CONFIG - Edit this!\n\u2502   \u251c\u2500\u2500 variable_labels.yaml        # Display labels\n\u2502   \u2514\u2500\u2500 ctramp_data_model_loader.py # Helper functions\n\u251c\u2500\u2500 outputs/                         # Generated summaries\n\u2502   \u251c\u2500\u2500 auto_ownership_regional.csv\n\u2502   \u251c\u2500\u2500 tour_mode_choice.csv\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 HOW_TO_SUMMARIZE.md             # User guide\n</code></pre>"},{"location":"configuration/#quick-reference","title":"Quick Reference","text":""},{"location":"configuration/#add-a-new-summary","title":"Add a New Summary","text":"<ol> <li>Edit <code>data_model/ctramp_data_model.yaml</code></li> <li>Add to <code>summaries:</code> section:    <pre><code>my_new_summary:\n  description: \"What this shows\"\n  data_source: \"individual_trips\"\n  group_by: \"column_name\"\n  aggregations:\n    trips:\n      column: \"trip_id\"\n      agg: \"count\"\n</code></pre></li> <li>Run: <code>python summarize_model_run.py \"path/to/ctramp\"</code></li> </ol>"},{"location":"configuration/#add-a-column-mapping","title":"Add a Column Mapping","text":"<p>Edit <code>data_model/ctramp_data_model.yaml</code>, find the data source, add column:</p> <pre><code>data_sources:\n  individual_trips:\n    columns:\n      my_new_column: \"ctramp_column_name\"\n</code></pre>"},{"location":"configuration/#add-a-value-label","title":"Add a Value Label","text":"<p>Edit <code>data_model/ctramp_data_model.yaml</code>, add to <code>value_mappings</code>:</p> <pre><code>value_mappings:\n  my_column:\n    type: categorical\n    values:\n      1: \"Label 1\"\n      2: \"Label 2\"\n</code></pre>"},{"location":"configuration/#create-an-aggregation","title":"Create an Aggregation","text":"<p>Edit <code>data_model/ctramp_data_model.yaml</code>, add to <code>aggregation_specs</code>:</p> <pre><code>aggregation_specs:\n  my_column_agg:\n    source_column: \"my_column_name\"\n    mapping:\n      \"Value 1\": \"Category A\"\n      \"Value 2\": \"Category A\"\n      \"Value 3\": \"Category B\"\n</code></pre>"},{"location":"configuration/#define-bins","title":"Define Bins","text":"<p>Edit <code>data_model/ctramp_data_model.yaml</code>, add to <code>binning_specs</code>:</p> <pre><code>binning_specs:\n  my_numeric_column:\n    breaks: [0, 10, 20, 30, 100]\n    labels: ['0-10', '10-20', '20-30', '30+']\n</code></pre>"},{"location":"configuration/#see-also","title":"See Also","text":"<ul> <li>HOW_TO_SUMMARIZE.md - Complete user guide with examples</li> <li>README.md - Toolkit overview</li> <li>summaries.md - Summary system documentation</li> <li>generate-summaries.md - Detailed generation guide</li> </ul>"},{"location":"contributing/","title":"Contributing to tm2py-utils","text":"<p>Thank you for contributing to tm2py-utils! This guide helps you add summaries, validation checks, and other features.</p> <p>Design Principles</p> <p>Before contributing, please review the Summary Design System Plan to understand the architecture, design principles, and coding standards.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":""},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Conda or virtualenv</li> <li>Git</li> </ul>"},{"location":"contributing/#installation","title":"Installation","text":"<pre><code># Clone repository\ngit clone https://github.com/BayAreaMetro/tm2py-utils.git\ncd tm2py-utils\n\n# Create environment\nconda env create -f environment.yml\nconda activate tm2py_utils\n\n# Install in development mode\npip install -e .\n\n# Install development dependencies\npip install pytest black flake8 mypy\n</code></pre>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"<pre><code>tm2py_utils/\n\u251c\u2500\u2500 summary/\n\u2502   \u251c\u2500\u2500 validation/                        # NEW: Simple validation toolkit\n\u2502   \u2502   \u251c\u2500\u2500 summarize_model_run.py        # Main tool\n\u2502   \u2502   \u251c\u2500\u2500 validate_summaries.py         # Quality checker\n\u2502   \u2502   \u251c\u2500\u2500 data_model/                   # Configuration\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 ctramp_data_model.yaml   # Edit this to add summaries!\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 variable_labels.yaml      # Display labels\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 ctramp_data_model_loader.py\n\u2502   \u2502   \u251c\u2500\u2500 outputs/                      # Generated summaries\n\u2502   \u2502   \u251c\u2500\u2500 HOW_TO_SUMMARIZE.md          # User guide\n\u2502   \u2502   \u251c\u2500\u2500 README.md                     # Toolkit overview\n\u2502   \u2502   \u2514\u2500\u2500 archived_validation_system/   # Old multi-dataset system\n\u2502   \u2514\u2500\u2500 core_summaries/                   # DEPRECATED\n\u251c\u2500\u2500 inputs/                                # Input data processing\n\u251c\u2500\u2500 misc/                                  # Utilities\n\u2514\u2500\u2500 docs/                                  # Documentation\n</code></pre>"},{"location":"contributing/#adding-a-new-summary","title":"Adding a New Summary","text":""},{"location":"contributing/#1-define-in-ctramp_data_modelyaml","title":"1. Define in ctramp_data_model.yaml","text":"<p>Edit <code>tm2py_utils/summary/validation/data_model/ctramp_data_model.yaml</code>:</p> <pre><code>summaries:\n  # ... existing summaries ...\n\n  trip_distance_by_mode_purpose:\n    description: \"Trip distance distribution by mode and purpose\"\n    data_source: \"individual_trips\"\n    group_by:\n      - \"trip_mode_name\"\n      - \"tour_purpose_name\"\n    aggregations:\n      trips:\n        column: \"trip_id\"\n        agg: \"count\"\n      mean_distance:\n        column: \"trip_distance_miles\"\n        agg: \"mean\"\n</code></pre>"},{"location":"contributing/#2-test-generation","title":"2. Test Generation","text":"<pre><code>cd tm2py_utils/summary/validation\n\n# Generate summaries for a test run\npython summarize_model_run.py \"A:/path/to/ctramp_output\" --output \"test_output\"\n</code></pre>"},{"location":"contributing/#3-verify-output","title":"3. Verify Output","text":"<p>Check the generated file:</p> <pre><code>cat test_output/trip_distance_by_mode_purpose.csv\n</code></pre> <p>Expected format: <pre><code>trip_mode_name,tour_purpose_name,trips,mean_distance,share\nDrive Alone,Work,1234567,12.5,0.452\nCarpool 2,Work,234567,10.3,0.086\nWalk-Transit-Walk,Work,156789,8.7,0.057\n...\n</code></pre> ... <pre><code>### 4. Update Documentation\n\nAdd description to appropriate section in `docs/summaries.md`.\n\n## Adding a Column Mapping\n\nIf using new CTRAMP output columns:\n\n### 1. Update Data Model\n\nEdit `data_model/ctramp_data_model.yaml`:\n\n```yaml\nindividual_trips:\n  file_pattern: \"indivTripData_{iteration}.csv\"\n  columns:\n    trip_mode: \"trip_mode\"\n    my_new_column: \"my_new_column\"  # Add mapping\n</code></pre></p>"},{"location":"contributing/#2-add-variable-label","title":"2. Add Variable Label","text":"<p>Edit <code>variable_labels.yaml</code>:</p> <pre><code>my_new_column: \"My New Column Label\"\n</code></pre>"},{"location":"contributing/#3-use-in-summary","title":"3. Use in Summary","text":"<pre><code>custom_summaries:\n  - name: \"summary_with_new_column\"\n    group_by: [\"my_new_column\"]\n    # ...\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":""},{"location":"contributing/#python","title":"Python","text":"<p>Follow PEP 8:</p> <pre><code># Format code\nblack tm2py_utils/\n\n# Check style\nflake8 tm2py_utils/\n\n# Type checking\nmypy tm2py_utils/\n</code></pre>"},{"location":"contributing/#yaml","title":"YAML","text":"<ul> <li>Use 2-space indentation</li> <li>Quote strings with special characters</li> <li>Comment complex sections</li> </ul> <pre><code># Good\ncustom_summaries:\n  - name: \"my_summary\"\n    description: \"Clear description\"\n    group_by: [\"column1\", \"column2\"]\n\n# Avoid\ncustom_summaries:\n    - name: my_summary  # Missing quotes, 4-space indent\n      group_by: [column1]\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":""},{"location":"contributing/#run-existing-tests","title":"Run Existing Tests","text":"<pre><code># All tests\npytest\n\n# Specific test\npytest tm2py_utils/summary/validation/test_summaries.py\n\n# With coverage\npytest --cov=tm2py_utils\n</code></pre>"},{"location":"contributing/#write-new-tests","title":"Write New Tests","text":"<p>Create <code>test_my_feature.py</code>:</p> <pre><code>import pytest\nfrom tm2py_utils.summary.validation import run_all\n\ndef test_my_summary_generation():\n    \"\"\"Test that my_summary generates expected output.\"\"\"\n    # Setup\n    config_path = \"test_config.yaml\"\n\n    # Run\n    run_all.main(config_path)\n\n    # Assert\n    output_file = \"outputs/my_summary.csv\"\n    assert output_file.exists()\n    # ... more assertions\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":""},{"location":"contributing/#update-docs","title":"Update Docs","text":"<p>When adding features, update relevant documentation:</p> <ul> <li><code>docs/summaries.md</code> - For new summaries or configuration options</li> <li><code>docs/configuration.md</code> - For new config parameters</li> <li><code>README.md</code> - For major features</li> </ul>"},{"location":"contributing/#build-docs-locally","title":"Build Docs Locally","text":"<pre><code># Install mkdocs\npip install mkdocs mkdocs-material\n\n# Serve locally\ncd tm2py_utils\nmkdocs serve\n\n# Visit http://localhost:8000\n</code></pre>"},{"location":"contributing/#submitting-changes","title":"Submitting Changes","text":""},{"location":"contributing/#1-create-branch","title":"1. Create Branch","text":"<pre><code>git checkout -b feature/my-new-feature\n</code></pre>"},{"location":"contributing/#2-make-changes","title":"2. Make Changes","text":"<ul> <li>Add summaries to <code>ctramp_data_model.yaml</code></li> <li>Update documentation</li> </ul>"},{"location":"contributing/#3-test-changes","title":"3. Test Changes","text":"<pre><code># Run tests\npytest\n\n# Generate summaries\npython summarize_model_run.py \"path/to/ctramp_output\"\n</code></pre>"},{"location":"contributing/#4-commit","title":"4. Commit","text":"<pre><code>git add .\ngit commit -m \"Add trip length analysis\n\n- Add trip_length_by_mode_purpose summary\n- Update summaries.md documentation\"\n</code></pre>"},{"location":"contributing/#5-push-and-create-pr","title":"5. Push and Create PR","text":"<pre><code>git push origin feature/my-new-feature\n</code></pre> <p>Then create Pull Request on GitHub.</p>"},{"location":"contributing/#common-patterns","title":"Common Patterns","text":""},{"location":"contributing/#binning-continuous-variables","title":"Binning Continuous Variables","text":"<pre><code>custom_summaries:\n  - name: \"trips_by_distance_bin\"\n    group_by: [\"distance_bin\", \"trip_mode\"]\n    bins:\n      distance:\n        breaks: [0, 5, 10, 20, 50, 1000]\n        labels: ['&lt;5mi', '5-10mi', '10-20mi', '20-50mi', '50+mi']\n</code></pre>"},{"location":"contributing/#multiple-aggregations","title":"Multiple Aggregations","text":"<pre><code>custom_summaries:\n  - name: \"trip_stats_by_mode\"\n    group_by: [\"trip_mode\"]\n    aggregations:\n      trips: \"count\"\n      avg_distance: {\"column\": \"trip_distance_miles\", \"agg\": \"mean\"}\n      total_time: {\"column\": \"trip_time_minutes\", \"agg\": \"sum\"}\n      max_distance: {\"column\": \"trip_distance_miles\", \"agg\": \"max\"}\n</code></pre>"},{"location":"contributing/#conditional-filters","title":"Conditional Filters","text":"<pre><code>custom_summaries:\n  - name: \"work_tours_only\"\n    data_source: \"individual_tours\"\n    filters:\n      tour_purpose: [\"Work\"]\n    group_by: [\"tour_mode\"]\n</code></pre>"},{"location":"contributing/#observed-data","title":"Observed Data","text":"<p>The external data files are provided for reference: - PopulationSim summaries in <code>outputs/populationsim/</code> - ACS data in <code>outputs/observed/</code></p> <p>These can be used for manual validation checks.</p> <p>Add to <code>observed_data_sources</code> in config:</p> <pre><code>observed_data_sources:\n  - name: \"ACS 2019\"\n    directory: \"/path/to/acs/data\"\n    files:\n      auto_ownership: \"acs_auto_ownership.csv\"\n</code></pre> <p>Then reference in summary:</p> <pre><code>custom_summaries:\n  - name: \"auto_ownership_regional\"\n    observed_data: \"ACS 2019\"\n    observed_file: \"auto_ownership\"\n</code></pre>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Check docs/</li> <li>Examples: See <code>examples/</code> directory</li> <li>Issues: Open on GitHub</li> <li>Email: modeling@bayareametro.gov</li> </ul>"},{"location":"contributing/#related-resources","title":"Related Resources","text":"<ul> <li>Consolidation Proposal - System architecture</li> <li>Dashboard Deployment Guide - Deployment workflow</li> <li>validation_config.yaml - Live configuration example</li> </ul>"},{"location":"custom-summaries/","title":"Create Custom Summaries","text":"<p>Guide to defining new validation summaries using YAML configuration.</p>"},{"location":"custom-summaries/#overview","title":"Overview","text":"<p>The validation system is fully config-driven - you can create new summaries without writing Python code. All summaries are defined in <code>validation_config.yaml</code> under the <code>summaries</code> section.</p> <p>Design Principles</p> <p>This configuration-driven approach follows the Data-Driven Configuration principle from our design system. For a complete understanding of the system architecture, see the Summary Design System Plan.</p> <p>What you can configure: - Which data table to use (households, persons, tours, trips) - How to group data (dimensions) - Which metrics to calculate (counts, shares, percentages) - Filters to apply - How to bin continuous variables - How to aggregate categories</p> <p>No coding required - just edit YAML and regenerate.</p>"},{"location":"custom-summaries/#basic-summary-structure","title":"Basic Summary Structure","text":""},{"location":"custom-summaries/#minimal-example","title":"Minimal Example","text":"<pre><code>summaries:\n  - name: \"auto_ownership_regional\"\n    data_source: \"households\"\n    group_by: \"num_vehicles\"\n    weight_field: \"sample_rate\"\n    count_name: \"households\"\n</code></pre> <p>Output:</p> <pre><code>num_vehicles,households,share,dataset\n0,150000,0.25,2023 TM2.2 v05\n1,200000,0.33,2023 TM2.2 v05\n2,180000,0.30,2023 TM2.2 v05\n</code></pre>"},{"location":"custom-summaries/#required-fields","title":"Required Fields","text":"Field Type Description Example <code>name</code> string Unique identifier (becomes filename) <code>\"auto_ownership_regional\"</code> <code>data_source</code> string Which table to query <code>\"households\"</code>, <code>\"persons\"</code>, <code>\"individual_tours\"</code>, <code>\"individual_trips\"</code> <code>group_by</code> string or list Columns to group by <code>\"num_vehicles\"</code> or <code>[\"county\", \"num_vehicles\"]</code>"},{"location":"custom-summaries/#optional-fields","title":"Optional Fields","text":"Field Type Description Default Example <code>weight_field</code> string Column containing expansion weights <code>\"sample_rate\"</code> <code>\"sample_rate\"</code> <code>count_name</code> string Name for count metric Based on data_source <code>\"households\"</code>, <code>\"tours\"</code> <code>share_within</code> string or list Calculate shares within groups <code>null</code> (regional) <code>\"income_category\"</code> <code>description</code> string Human-readable description <code>\"\"</code> <code>\"Vehicle ownership by income\"</code> <code>filter</code> string Filter expression (pandas query syntax) <code>null</code> (no filter) <code>\"tour_purpose == 'Work'\"</code> <code>calculate_share</code> boolean Whether to calculate share column <code>true</code> <code>false</code>"},{"location":"custom-summaries/#data-sources","title":"Data Sources","text":"<p>The <code>data_source</code> field determines which table is queried:</p> Data Source Description Available Columns <code>households</code> Household demographics <code>num_vehicles</code>, <code>num_persons</code>, <code>num_workers</code>, <code>income_category</code>, <code>county</code>, <code>county_name</code>, etc. <code>persons</code> Person characteristics <code>person_type</code>, <code>age</code>, <code>gender</code>, <code>cdap</code>, <code>value_of_time</code>, etc. <code>individual_tours</code> Tour-level data <code>tour_purpose</code>, <code>tour_mode</code>, <code>start_period</code>, <code>end_period</code>, <code>tour_distance</code>, etc. <code>individual_trips</code> Trip-level data <code>trip_mode</code>, <code>origin_purpose</code>, <code>destination_purpose</code>, <code>trip_distance</code>, etc. <code>workplace_school_location</code> Work/school locations <code>work_location</code>, <code>school_location</code>, <code>work_location_distance</code>, etc. <p>See CTRAMP Data Model for complete column lists.</p> <p>Column naming: - After data loading, columns use standardized internal names - <code>hh_id</code> \u2192 <code>household_id</code> - <code>size</code> \u2192 <code>num_persons</code> - <code>autos</code> \u2192 <code>num_vehicles</code></p> <p>Use the internal names in your <code>group_by</code> specifications.</p>"},{"location":"custom-summaries/#grouping-dimensions","title":"Grouping Dimensions","text":""},{"location":"custom-summaries/#single-dimension","title":"Single Dimension","text":"<pre><code>- name: \"cdap_distribution\"\n  data_source: \"persons\"\n  group_by: \"cdap\"\n  count_name: \"persons\"\n</code></pre> <p>Output: One row per CDAP value (M, N, H)</p>"},{"location":"custom-summaries/#multiple-dimensions","title":"Multiple Dimensions","text":"<pre><code>- name: \"auto_ownership_by_income\"\n  data_source: \"households\"\n  group_by: [\"income_category\", \"num_vehicles\"]\n  count_name: \"households\"\n</code></pre> <p>Output: One row per combination (income \u00d7 vehicles)</p> <pre><code>income_category,num_vehicles,households,share,dataset\n1,0,50000,0.15,2023 TM2.2 v05\n1,1,80000,0.24,2023 TM2.2 v05\n1,2,70000,0.21,2023 TM2.2 v05\n2,0,40000,0.12,2023 TM2.2 v05\n...\n</code></pre>"},{"location":"custom-summaries/#cross-tabulations","title":"Cross-Tabulations","text":"<p>For mode \u00d7 purpose, destination \u00d7 origin, etc.:</p> <pre><code>- name: \"tour_mode_by_purpose\"\n  data_source: \"individual_tours\"\n  group_by: [\"tour_purpose\", \"tour_mode\"]\n  share_within: \"tour_purpose\"  # Share within each purpose\n</code></pre> <p>Output: Mode distribution for each tour purpose</p>"},{"location":"custom-summaries/#share-calculations","title":"Share Calculations","text":""},{"location":"custom-summaries/#regional-shares-default","title":"Regional Shares (Default)","text":"<pre><code>- name: \"auto_ownership_regional\"\n  data_source: \"households\"\n  group_by: \"num_vehicles\"\n</code></pre> <p>Output: Share = count / total across all records</p> <pre><code>num_vehicles,households,share\n0,150000,0.25\n1,200000,0.33\n2,180000,0.30\n3,120000,0.20\n</code></pre> <p>Share adds to 1.0 (or 100%)</p>"},{"location":"custom-summaries/#shares-within-groups","title":"Shares Within Groups","text":"<pre><code>- name: \"auto_ownership_by_income\"\n  data_source: \"households\"\n  group_by: [\"income_category\", \"num_vehicles\"]\n  share_within: \"income_category\"\n</code></pre> <p>Output: Share = count / total within each income category</p> <pre><code>income_category,num_vehicles,households,share\n1,0,50000,0.33    # Share within income=1\n1,1,80000,0.53\n1,2,20000,0.13\n2,0,30000,0.20    # Share within income=2\n2,1,90000,0.60\n2,2,30000,0.20\n</code></pre> <p>Within each <code>income_category</code>, shares add to 1.0.</p>"},{"location":"custom-summaries/#multiple-grouping-levels","title":"Multiple Grouping Levels","text":"<pre><code>- name: \"auto_ownership_by_household_size_county\"\n  data_source: \"households\"\n  group_by: [\"county\", \"num_persons_agg\", \"num_vehicles\"]\n  share_within: [\"county\", \"num_persons_agg\"]\n</code></pre> <p>Output: Share within each county \u00d7 household_size combination</p> <pre><code>county,num_persons_agg,num_vehicles,households,share\nAlameda,1,0,57000,0.28    # Share within Alameda 1-person households\nAlameda,1,1,100000,0.50\nAlameda,1,2,44000,0.22\nAlameda,2,0,40000,0.15    # Share within Alameda 2-person households\n...\n</code></pre> <p>Shares add to 1.0 within each (county, num_persons_agg) group.</p>"},{"location":"custom-summaries/#disable-share-calculation","title":"Disable Share Calculation","text":"<p>For raw counts without percentages:</p> <pre><code>- name: \"time_of_day_tours\"\n  data_source: \"individual_tours\"\n  group_by: [\"start_period\", \"end_period\"]\n  calculate_share: false\n</code></pre>"},{"location":"custom-summaries/#filtering-data","title":"Filtering Data","text":"<p>Use pandas query syntax to filter records before aggregation.</p>"},{"location":"custom-summaries/#simple-filters","title":"Simple Filters","text":"<p>Filter to work tours only:</p> <pre><code>- name: \"work_tour_modes\"\n  data_source: \"individual_tours\"\n  filter: \"tour_purpose == 'Work'\"\n  group_by: \"tour_mode\"\n</code></pre> <p>Filter to adults (age 18+):</p> <pre><code>- name: \"adult_cdap\"\n  data_source: \"persons\"\n  filter: \"age &gt;= 18\"\n  group_by: \"cdap\"\n</code></pre> <p>Filter to specific county:</p> <pre><code>- name: \"sf_auto_ownership\"\n  data_source: \"households\"\n  filter: \"county_name == 'San Francisco'\"\n  group_by: \"num_vehicles\"\n</code></pre>"},{"location":"custom-summaries/#complex-filters","title":"Complex Filters","text":"<p>Multiple conditions (AND):</p> <pre><code>filter: \"age &gt;= 18 and age &lt;= 65\"\n</code></pre> <p>Multiple conditions (OR):</p> <pre><code>filter: \"tour_purpose == 'Work' or tour_purpose == 'School'\"\n</code></pre> <p>List membership:</p> <pre><code>filter: \"tour_purpose in ['Work', 'School', 'University']\"\n</code></pre> <p>Numeric ranges:</p> <pre><code>filter: \"tour_distance &gt;= 5 and tour_distance &lt; 20\"\n</code></pre> <p>String matching:</p> <pre><code>filter: \"county_name.str.contains('San')\"\n</code></pre>"},{"location":"custom-summaries/#filter-execution","title":"Filter Execution","text":"<p>Filters are applied before aggregation:</p> <ol> <li>Load data</li> <li>Apply filter \u2192 Reduce rows</li> <li>Group by dimensions</li> <li>Calculate counts and shares</li> </ol> <p>Log output:</p> <pre><code>INFO - \u2713 Applied filter: 'tour_purpose == \"Work\"' (1,500,000 \u2192 450,000 rows)\n</code></pre>"},{"location":"custom-summaries/#binning-continuous-variables","title":"Binning Continuous Variables","text":"<p>Convert continuous variables (distance, time, age, income) into categories.</p>"},{"location":"custom-summaries/#define-bins-globally","title":"Define Bins Globally","text":"<p>In <code>validation_config.yaml</code>:</p> <pre><code>binning_specs:\n  tour_distance:\n    bins: [0, 5, 10, 20, 50, 1000]\n    labels: ['0-5', '5-10', '10-20', '20-50', '50+']\n\n  worker_age:\n    bins: [0, 25, 35, 45, 55, 65, 120]\n    labels: ['&lt;25', '25-34', '35-44', '45-54', '55-64', '65+']\n</code></pre>"},{"location":"custom-summaries/#use-binned-columns","title":"Use Binned Columns","text":"<p>The system automatically creates <code>{column}_bin</code> columns:</p> <pre><code>- name: \"tour_distance_distribution\"\n  data_source: \"individual_tours\"\n  group_by: \"tour_distance_bin\"  # Uses binning_specs.tour_distance\n</code></pre> <p>Output:</p> <pre><code>tour_distance_bin,tours,share,dataset\n0-5,250000,0.40,2023 TM2.2 v05\n5-10,180000,0.29,2023 TM2.2 v05\n10-20,120000,0.19,2023 TM2.2 v05\n20-50,60000,0.10,2023 TM2.2 v05\n50+,15000,0.02,2023 TM2.2 v05\n</code></pre>"},{"location":"custom-summaries/#binning-configuration","title":"Binning Configuration","text":"Field Description Example <code>bins</code> Bin edges (inclusive lower, exclusive upper) <code>[0, 5, 10, 20, 50, 1000]</code> <code>labels</code> Category labels (one less than bins) <code>['0-5', '5-10', '10-20', '20-50', '50+']</code> <p>Bin behavior: - <code>bins: [0, 5, 10]</code> creates: <code>[0, 5)</code> and <code>[5, 10)</code> - First bin includes lower edge: <code>[0, 5)</code> \u2192 0 \u2264 x &lt; 5 - Last bin includes upper edge: <code>[50, 1000]</code> \u2192 50 \u2264 x \u2264 1000</p>"},{"location":"custom-summaries/#pre-configured-bins","title":"Pre-Configured Bins","text":"<p>The system includes these bin specifications:</p> Variable Bins Labels <code>tour_distance</code> 0, 5, 10, 20, 50, 1000 0-5, 5-10, 10-20, 20-50, 50+ <code>trip_distance</code> 0, 1, 3, 5, 10, 20, 1000 0-1, 1-3, 3-5, 5-10, 10-20, 20+ <code>tour_duration</code> 0, 30, 60, 120, 240, 10000 0-30, 30-60, 60-120, 120-240, 240+ <code>trip_duration</code> 0, 5, 10, 15, 30, 60, 10000 0-5, 5-10, 10-15, 15-30, 30-60, 60+ <code>worker_age</code> 0, 25, 35, 45, 55, 65, 120 &lt;25, 25-34, 35-44, 45-54, 55-64, 65+ <code>income_category</code> 0, 30000, 60000, 100000, 150000, 1000000000 &lt;30K, 30-60K, 60-100K, 100-150K, 150K+"},{"location":"custom-summaries/#aggregating-categories","title":"Aggregating Categories","text":"<p>Combine detailed categories into broader groups (e.g., 4+ person households, Auto/Transit/Active modes).</p>"},{"location":"custom-summaries/#define-aggregations-globally","title":"Define Aggregations Globally","text":"<p>In <code>validation_config.yaml</code>:</p> <pre><code>aggregation_specs:\n  # Household size: 1, 2, 3, 4+ (match ACS categories)\n  num_persons_agg:\n    apply_to: [\"num_persons\"]\n    mapping:\n      1: 1\n      2: 2\n      3: 3\n      4: 4\n      5: 4\n      6: 4\n      7: 4\n      8: 4\n      9: 4\n      10: 4\n</code></pre>"},{"location":"custom-summaries/#use-aggregated-columns","title":"Use Aggregated Columns","text":"<p>The system automatically creates <code>{column}_agg</code> columns:</p> <pre><code>- name: \"auto_ownership_by_household_size_acs\"\n  data_source: \"households\"\n  group_by: [\"num_persons_agg\", \"num_vehicles\"]  # Uses aggregation_specs.num_persons_agg\n  share_within: \"num_persons_agg\"\n</code></pre> <p>Before aggregation (<code>num_persons</code>): - 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 (10 categories)</p> <p>After aggregation (<code>num_persons_agg</code>): - 1, 2, 3, 4 (4 categories, where 4 = \"4+\")</p>"},{"location":"custom-summaries/#transportation-mode-aggregation","title":"Transportation Mode Aggregation","text":"<p>Group 17 detailed modes into broader categories:</p> <pre><code>aggregation_specs:\n  transportation_mode:\n    apply_to: [\"tour_mode\", \"trip_mode\"]\n    mapping:\n      1: \"Auto - SOV\"        # SOV_GP\n      2: \"Auto - SOV\"        # SOV_PAY\n      3: \"Auto - Shared\"     # SR2_GP\n      4: \"Auto - Shared\"     # SR2_HOV\n      5: \"Auto - Shared\"     # SR2_PAY\n      6: \"Auto - Shared\"     # SR3_GP\n      7: \"Auto - Shared\"     # SR3_HOV\n      8: \"Auto - Shared\"     # SR3_PAY\n      9: \"Active\"            # WALK\n      10: \"Active\"           # BIKE\n      11: \"Transit\"          # WLK_TRN\n      12: \"Transit\"          # PNR_TRN\n      13: \"Transit\"          # KNRPRV_TRN\n      14: \"Transit\"          # KNRTNC_TRN\n      15: \"TNC/Taxi\"         # TAXI\n      16: \"TNC/Taxi\"         # TNC\n      17: \"School Bus\"       # SCHLBUS\n</code></pre> <p>Usage:</p> <pre><code>- name: \"tour_mode_choice_aggregated\"\n  data_source: \"individual_tours\"\n  group_by: \"tour_mode_agg\"  # Uses transportation_mode aggregation\n</code></pre> <p>Output: 6 categories instead of 17</p>"},{"location":"custom-summaries/#aggregation-vs-binning","title":"Aggregation vs. Binning","text":"Binning Aggregation Input Continuous numeric Categorical (codes/text) Process Create ranges Map values to groups Example Distance \u2192 bins 17 modes \u2192 6 groups Suffix <code>_bin</code> <code>_agg</code>"},{"location":"custom-summaries/#complete-examples","title":"Complete Examples","text":""},{"location":"custom-summaries/#example-1-simple-distribution","title":"Example 1: Simple Distribution","text":"<p>Goal: Vehicle ownership distribution</p> <pre><code>- name: \"auto_ownership_regional\"\n  description: \"Regional vehicle ownership distribution\"\n  data_source: \"households\"\n  group_by: \"num_vehicles\"\n  weight_field: \"sample_rate\"\n  count_name: \"households\"\n</code></pre> <p>Output:</p> <pre><code>num_vehicles,households,share,dataset\n0,150000,0.25,2023 TM2.2 v05\n1,200000,0.33,2023 TM2.2 v05\n2,180000,0.30,2023 TM2.2 v05\n3,72000,0.12,2023 TM2.2 v05\n</code></pre>"},{"location":"custom-summaries/#example-2-cross-tabulation-with-shares","title":"Example 2: Cross-Tabulation with Shares","text":"<p>Goal: Mode choice by tour purpose</p> <pre><code>- name: \"tour_mode_by_purpose\"\n  description: \"Tour mode by purpose cross-tabulation\"\n  data_source: \"individual_tours\"\n  group_by: [\"tour_purpose\", \"tour_mode\"]\n  weight_field: \"sample_rate\"\n  count_name: \"tours\"\n  share_within: \"tour_purpose\"\n</code></pre> <p>Output:</p> <pre><code>tour_purpose,tour_mode,tours,share,dataset\nWork,1,80000,0.40,2023 TM2.2 v05\nWork,9,30000,0.15,2023 TM2.2 v05\nWork,11,60000,0.30,2023 TM2.2 v05\nShop,1,120000,0.60,2023 TM2.2 v05\nShop,9,80000,0.40,2023 TM2.2 v05\n</code></pre> <p>Shares add to 1.0 within each <code>tour_purpose</code>.</p>"},{"location":"custom-summaries/#example-3-filtered-binned","title":"Example 3: Filtered + Binned","text":"<p>Goal: Work tour distance distribution (work tours only)</p> <pre><code>- name: \"work_tour_distance\"\n  description: \"Distance distribution for work tours\"\n  data_source: \"individual_tours\"\n  filter: \"tour_purpose == 'Work'\"\n  group_by: \"tour_distance_bin\"\n  weight_field: \"sample_rate\"\n  count_name: \"tours\"\n</code></pre> <p>Output: Distance distribution for work tours only (non-work filtered out)</p>"},{"location":"custom-summaries/#example-4-multi-level-grouping","title":"Example 4: Multi-Level Grouping","text":"<p>Goal: Auto ownership by income and household size</p> <pre><code>- name: \"auto_ownership_by_income_and_size\"\n  description: \"Vehicle ownership by income and household size\"\n  data_source: \"households\"\n  group_by: [\"income_category\", \"num_persons\", \"num_vehicles\"]\n  weight_field: \"sample_rate\"\n  count_name: \"households\"\n  share_within: [\"income_category\", \"num_persons\"]\n</code></pre> <p>Output: Shares add to 1.0 within each (income, household size) combination</p>"},{"location":"custom-summaries/#example-5-aggregated-categories","title":"Example 5: Aggregated Categories","text":"<p>Goal: Simplified mode choice (Auto/Transit/Active/Other)</p> <pre><code>- name: \"tour_mode_choice_aggregated\"\n  description: \"Tour mode choice (aggregated categories)\"\n  data_source: \"individual_tours\"\n  group_by: \"tour_mode_agg\"\n  weight_field: \"sample_rate\"\n  count_name: \"tours\"\n</code></pre> <p>Output:</p> <pre><code>tour_mode_agg,tours,share,dataset\nAuto - SOV,450000,0.45,2023 TM2.2 v05\nAuto - Shared,200000,0.20,2023 TM2.2 v05\nTransit,250000,0.25,2023 TM2.2 v05\nActive,80000,0.08,2023 TM2.2 v05\nTNC/Taxi,20000,0.02,2023 TM2.2 v05\n</code></pre>"},{"location":"custom-summaries/#example-6-geographic-summary","title":"Example 6: Geographic Summary","text":"<p>Goal: Auto ownership by county</p> <pre><code>- name: \"auto_ownership_by_county\"\n  description: \"Vehicle ownership by county\"\n  data_source: \"households\"\n  group_by: [\"county_name\", \"num_vehicles\"]\n  weight_field: \"sample_rate\"\n  count_name: \"households\"\n  share_within: \"county_name\"\n</code></pre> <p>Output: Vehicle distribution for each Bay Area county</p>"},{"location":"custom-summaries/#common-patterns","title":"Common Patterns","text":""},{"location":"custom-summaries/#pattern-1-regional-distribution","title":"Pattern 1: Regional Distribution","text":"<pre><code>group_by: \"variable\"\n# No share_within \u2192 regional shares\n</code></pre>"},{"location":"custom-summaries/#pattern-2-conditional-distribution","title":"Pattern 2: Conditional Distribution","text":"<pre><code>group_by: [\"condition\", \"variable\"]\nshare_within: \"condition\"\n# Share of 'variable' within each 'condition'\n</code></pre>"},{"location":"custom-summaries/#pattern-3-filtered-subset","title":"Pattern 3: Filtered Subset","text":"<pre><code>filter: \"expression\"\ngroup_by: \"variable\"\n# Distribution for filtered records only\n</code></pre>"},{"location":"custom-summaries/#pattern-4-multi-dimensional","title":"Pattern 4: Multi-Dimensional","text":"<pre><code>group_by: [\"dim1\", \"dim2\", \"dim3\"]\nshare_within: [\"dim1\", \"dim2\"]\n# Share within each (dim1, dim2) combination\n</code></pre>"},{"location":"custom-summaries/#troubleshooting","title":"Troubleshooting","text":""},{"location":"custom-summaries/#empty-output","title":"Empty Output","text":"<pre><code>WARNING - Generated my_summary: 0 rows\n</code></pre> <p>Causes: - Filter removed all records - Missing column in data - Column has all null values</p> <p>Solutions: 1. Check filter expression 2. Verify column exists: see Data Model 3. Check for typos in column names</p>"},{"location":"custom-summaries/#missing-columns","title":"Missing Columns","text":"<pre><code>KeyError: 'tour_distance_bin'\n</code></pre> <p>Solution: Add binning spec to <code>binning_specs</code> section for <code>tour_distance</code></p>"},{"location":"custom-summaries/#wrong-data-source","title":"Wrong Data Source","text":"<pre><code>WARNING - Column 'tour_mode' not found\n</code></pre> <p>Cause: Using <code>data_source: \"households\"</code> but <code>tour_mode</code> is in <code>\"individual_tours\"</code></p> <p>Solution: Use correct data source table</p>"},{"location":"custom-summaries/#shares-dont-add-to-10","title":"Shares Don't Add to 1.0","text":"<p>Cause: Using wrong <code>share_within</code> grouping</p> <p>Example:</p> <pre><code>group_by: [\"county\", \"income\", \"vehicles\"]\nshare_within: \"county\"  # Wrong - shares within county, not county\u00d7income\n</code></pre> <p>Fix:</p> <pre><code>share_within: [\"county\", \"income\"]  # Shares within each county\u00d7income combination\n</code></pre>"},{"location":"custom-summaries/#best-practices","title":"Best Practices","text":"<ol> <li>Use descriptive names - <code>auto_ownership_by_income</code> not <code>summary_1</code></li> <li>Add descriptions - Helps future users understand purpose</li> <li>Start simple - Test with single dimension before adding complexity</li> <li>Check shares - Verify they add to 1.0 within expected groups</li> <li>Use aggregations - For matching external data categories (ACS uses 4+ households)</li> <li>Leverage bins - Pre-configured bins for common variables</li> <li>Filter early - Reduces processing time</li> <li>Test incrementally - Add one feature at a time</li> </ol>"},{"location":"custom-summaries/#validation","title":"Validation","text":"<p>Check your summary configuration:</p> <pre><code>python validate_config.py --config validation_config.yaml\n</code></pre> <p>Checks: - Required fields present - Data source valid - Group-by columns exist - Filter syntax correct - Binning specs defined</p>"},{"location":"custom-summaries/#next-steps","title":"Next Steps","text":"<ul> <li>Generate Summaries - Run the summary generation</li> <li>External Data Reference - Location of observed data files</li> <li>Data Model Reference - See available columns</li> <li>Configuration Guide - YAML documentation</li> </ul>"},{"location":"data-model/","title":"CTRAMP Data Model Reference","text":"<p>This document describes the required data format for the validation summary system. All input data must conform to this structure, whether from model outputs or household travel surveys.</p>"},{"location":"data-model/#overview","title":"Overview","text":"<p>The CTRAMP (Coordinated Travel-Regional Activity Modeling Platform) data model consists of four core tables that represent household travel behavior at different levels of detail:</p> <ol> <li>Households - Demographics and vehicle ownership</li> <li>Persons - Individual characteristics and daily patterns</li> <li>Tours - Round-trip journeys from/to home (or workplace)</li> <li>Trips - Individual trip segments within tours</li> </ol> <p>These tables have a hierarchical relationship: households contain persons, persons make tours, tours consist of trips.</p>"},{"location":"data-model/#core-data-files","title":"Core Data Files","text":""},{"location":"data-model/#required-files","title":"Required Files","text":"<p>The system expects these files in each model output directory:</p> File Pattern Description Required <code>householdData_{iteration}.csv</code> Household demographics and vehicle ownership \u2705 <code>personData_{iteration}.csv</code> Person-level attributes and activity patterns \u2705 <code>indivTourData_{iteration}.csv</code> Individual tour patterns (round-trips) \u2705 <code>indivTripData_{iteration}.csv</code> Individual trip segments \u2705 <code>wsLocResults.csv</code> Workplace and school location choices \u26a0\ufe0f Optional <p>Note: <code>{iteration}</code> is typically <code>1</code> for final model outputs (e.g., <code>householdData_1.csv</code>).</p>"},{"location":"data-model/#geography-reference-file","title":"Geography Reference File","text":"<p>The system also requires a geography lookup file to map zones to counties/districts:</p> <ul> <li>File: <code>tm2py_utils/inputs/maz_taz/mazs_tazs_county_tract_PUMA_2.5.csv</code></li> <li>Purpose: Joins home_mgra to county names and planning districts</li> <li>Key columns: <code>MAZ_SEQ</code>, <code>county_name</code>, <code>DistName</code></li> </ul> <p>This file is not in the model output directory - it's a static reference file in the workspace.</p>"},{"location":"data-model/#table-schemas","title":"Table Schemas","text":""},{"location":"data-model/#1-households-householddata_iterationcsv","title":"1. Households (<code>householdData_{iteration}.csv</code>)","text":"<p>Household-level demographics, location, and vehicle ownership.</p> <p>Required Columns:</p> Column Name Description Example Values Notes <code>hh_id</code> Unique household identifier 1562223, 1580323, ... Primary key <code>home_mgra</code> Home location MGRA 3, 4, 5, ..., 1454 Joins to geography lookup <code>income</code> Annual household income (dollars) 140705, 125256, 772355 Continuous dollar amount <code>autos</code> Number of vehicles 0, 1, 2, 3, 4, 5, 6+ Integer count <code>size</code> Household size (persons) 1, 2, 3, ..., 15 Total household members <code>workers</code> Number of workers 0, 1, 2, ... Workers \u2264 size <code>sampleRate</code> Sample expansion factor 0.01, 0.05, 0.5, 1.0 Decimal fraction (0.01 = 1% sample) <p>Optional Columns:</p> Column Name Description Example Values <code>automated_vehicles</code> Number of autonomous vehicles 0, 1, 2 <code>transponder</code> Has toll transponder 0, 1 <code>cdap_pattern</code> Coordinated Daily Activity Pattern \"MMNHH\" (M/N/H per person) <code>jtf_choice</code> Joint tour frequency 0, 1, 2, 3 <p>Key Points: - <code>sampleRate</code> is the sampling fraction, not the expansion factor (system inverts it: 0.01 \u2192 weight of 100.0) - <code>home_mgra</code> must exist in the geography lookup file to get county/district names - <code>income</code> is continuous in dollars, not categorical (binning must be done in postprocessing or summary config)</p> <p>Official Documentation: https://bayareametro.github.io/tm2py/ctramp-outputs/household/</p>"},{"location":"data-model/#2-persons-persondata_iterationcsv","title":"2. Persons (<code>personData_{iteration}.csv</code>)","text":"<p>Individual characteristics, employment, and daily activity patterns.</p> <p>Required Columns:</p> Column Name Description Example Values Notes <code>hh_id</code> Household identifier 1562223, 1580323, ... Foreign key to households <code>person_id</code> Unique person identifier 3806279, 3841021, ... Primary key (globally unique) <code>person_num</code> Person number in household 1, 2, 3, ... 1 to household size <code>age</code> Person age in years 9, 12, 39, 47, 51 Integer <code>gender</code> Gender \"m\", \"f\" Text values: \"m\"=Male, \"f\"=Female <code>type</code> Person type classification Text values See person type values below <p>Person Type Values (<code>type</code>) - Text Strings:</p> Value Description \"Full-time worker\" Full-time worker \"Part-time worker\" Part-time worker \"University student\" University student \"Non-worker\" Non-working adult \"Retired\" Retired adult \"Student of driving age\" Driving-age student (high school) \"Student of non-driving age\" School-age child (K-8) \"Child too young for school\" Preschool child <p>Optional but Common Columns:</p> Column Name Description Example Values <code>cdap</code> Coordinated Daily Activity Pattern \"M\", \"N\", \"H\" <code>value_of_time</code> Value of time ($/hour) 12.50, 25.00 <code>telecommute</code> Telecommute choice 0, 1 <code>transit_subsidy_choice</code> Has transit subsidy 0, 1 <code>transit_pass_choice</code> Transit pass type 0, 1, 2 <code>fp_choice</code> Free parking at work 0, 1 <code>sampleRate</code> Sample expansion factor 0.05, 0.5, 1.0 <p>CDAP Codes: - <code>M</code> = Mandatory (work/school tour) - <code>N</code> = Non-mandatory (shopping, discretionary, etc.) - <code>H</code> = Home (no out-of-home activity)</p> <p>Official Documentation: https://bayareametro.github.io/tm2py/ctramp-outputs/person/</p>"},{"location":"data-model/#3-individual-tours-indivtourdata_iterationcsv","title":"3. Individual Tours (<code>indivTourData_{iteration}.csv</code>)","text":"<p>Round-trip journeys from home (or workplace) to a destination and back.</p> <p>Required Columns:</p> Column Name Description Example Values Notes <code>hh_id</code> Household identifier 1, 2, 3, ... Foreign key <code>person_id</code> Person identifier 1, 2, 3, ... Foreign key <code>person_num</code> Person number in household 1, 2, 3 - <code>person_type</code> Person type classification Text values Same as persons.type <code>tour_id</code> Tour sequence for this person 0, 1, 2, 3 Primary key (0-indexed, unique per person) <code>tour_category</code> High-level tour classification \"MANDATORY\", \"INDIVIDUAL_NON_MANDATORY\", \"AT_WORK\" Text values <code>tour_purpose</code> Specific tour purpose \"Work\", \"Shop\", \"Discretionary\" Text values <code>start_period</code> Departure time period 1-40 30-minute intervals (1=5:00-5:30 AM, 7=8:00-8:30 AM) <code>end_period</code> Return time period 1-40 Same scale as start_period <p>Tour Purpose Values (text strings in data): - <code>Work</code> - Work tour - <code>School</code> - K-12 school tour - <code>University</code> - University/college tour - <code>Escort</code> - Escort someone (pick-up/drop-off) - <code>Shop</code> - Shopping - <code>Maintenance</code> - Personal business - <code>Eating Out</code> - Dining - <code>Visiting</code> - Social/visiting - <code>Discretionary</code> - Recreation/leisure - <code>Work-Based</code> - At-work subtour</p> <p>Optional but Common Columns:</p> Column Name Description Example Values <code>orig_mgra</code> Origin MGRA 100, 200 (home or workplace) <code>dest_mgra</code> Destination MGRA 150, 250 <code>tour_mode</code> Primary tour mode 1-17 (see mode codes) <code>tour_distance</code> Round-trip distance (miles) 5.2, 12.8 <code>tour_time</code> Round-trip time (minutes) 45, 90 <code>num_ob_stops</code> Outbound intermediate stops 0, 1, 2, 3 <code>num_ib_stops</code> Inbound intermediate stops 0, 1, 2, 3 <code>sampleRate</code> Sample expansion factor 0.05, 0.5, 1.0 <p>Time Periods (1-40, 30-minute intervals starting at 5:00 AM): - 1 = 5:00-5:30 AM - 7 = 8:00-8:30 AM (typical morning commute) - 13 = 11:00-11:30 AM - 25 = 5:00-5:30 PM (typical evening commute) - 40 = 3:00-3:30 AM (next day)</p> <p>Official Documentation: https://bayareametro.github.io/tm2py/ctramp-outputs/individual-tours/</p>"},{"location":"data-model/#4-individual-trips-indivtripdata_iterationcsv","title":"4. Individual Trips (<code>indivTripData_{iteration}.csv</code>)","text":"<p>Individual trip segments (one-way movements) that make up tours.</p> <p>Required Columns:</p> Column Name Description Example Values Notes <code>hh_id</code> Household identifier 1, 2, 3, ... Foreign key <code>person_id</code> Person identifier 1, 2, 3, ... Foreign key <code>person_num</code> Person number in household 1, 2, 3 - <code>tour_id</code> Tour identifier 1, 2, 3 Foreign key to tours <p>Optional but Common Columns:</p> Column Name Description Example Values <code>stop_id</code> Trip sequence within tour -1 (direct), 0, 1, 2 <code>inbound</code> Trip direction 0 (outbound), 1 (inbound) <code>tour_purpose</code> Parent tour purpose \"Work\", \"Shop\", etc. <code>orig_purpose</code> Origin activity purpose \"Home\", \"Work\", \"Shop\" <code>dest_purpose</code> Destination activity purpose \"Work\", \"Shop\", \"Home\" <code>orig_mgra</code> Origin MGRA 100, 200 <code>dest_mgra</code> Destination MGRA 150, 250 <code>trip_dist</code> Trip distance (miles) 2.5, 5.0 <code>stop_period</code> Departure time period 1-40 <code>trip_mode</code> Trip transportation mode 1-17 (see mode codes) <code>tour_mode</code> Parent tour mode 1-17 <code>sampleRate</code> Sample expansion factor 0.05, 0.5, 1.0 <p>Stop ID Interpretation: - <code>-1</code> = Direct trip (no intermediate stops) - <code>0</code>, <code>1</code>, <code>2</code>, ... = Intermediate stop sequence</p> <p>Official Documentation: https://bayareametro.github.io/tm2py/ctramp-outputs/individual-trips/</p>"},{"location":"data-model/#5-workplaceschool-location-optional","title":"5. Workplace/School Location (Optional)","text":"<p>Location choice results for work and school.</p> <p>File: <code>wsLocResults.csv</code> (no iteration number)</p> <p>Key Columns:</p> Column Name Description Example Values <code>HHID</code> Household identifier 1, 2, 3 <code>PersonID</code> Person identifier 1, 2, 3 <code>WorkLocation</code> Work MGRA 0 (no work), 100, 200 <code>SchoolLocation</code> School MGRA 0 (no school), 150, 250 <code>WorkLocationDistance</code> Home to work distance 0.0, 5.2, 12.8 <code>SchoolLocationDistance</code> Home to school distance 0.0, 2.5, 8.0 <p>Official Documentation: https://bayareametro.github.io/tm2py/ctramp-outputs/workplace-school-location/</p>"},{"location":"data-model/#transportation-mode-codes","title":"Transportation Mode Codes","text":"<p>The 17-mode standard used for <code>tour_mode</code> and <code>trip_mode</code>:</p> Code Mode Name Description 1 SOV_GP Single Occupant Vehicle - General Purpose lanes 2 SOV_PAY Single Occupant Vehicle - Express/Toll lanes 3 SR2_GP Shared Ride 2 - General Purpose 4 SR2_HOV Shared Ride 2 - HOV lanes 5 SR2_PAY Shared Ride 2 - Express/Toll 6 SR3_GP Shared Ride 3+ - General Purpose 7 SR3_HOV Shared Ride 3+ - HOV lanes 8 SR3_PAY Shared Ride 3+ - Express/Toll 9 WALK_TRN Walk to Transit 10 PNR_TRN Park-and-Ride to Transit 11 KNR_TRN Kiss-and-Ride to Transit 12 TNC_TRN TNC to Transit 13 WALK Walk 14 BIKE Bicycle 15 TAXI Taxi 16 TNC_SINGLE TNC Single (Uber/Lyft alone) 17 TNC_SHARED TNC Shared (UberPool/Lyft Shared) <p>Common Aggregations: - Auto: 1-8 (all SOV and shared ride modes) - Transit: 9-12 (all transit access modes) - Active: 13-14 (walk and bike) - TNC/Taxi: 15-17 (taxi and TNC modes)</p>"},{"location":"data-model/#data-relationships","title":"Data Relationships","text":"<pre><code>households (hh_id)\n    \u2193\npersons (hh_id, person_id)\n    \u2193\ntours (person_id, tour_id)\n    \u2193\ntrips (tour_id, trip_id/stop_id)\n</code></pre> <p>Join Keys: - <code>households.hh_id</code> \u2192 <code>persons.hh_id</code> - <code>persons.person_id</code> \u2192 <code>tours.person_id</code> - <code>tours.tour_id</code> \u2192 <code>trips.tour_id</code> - <code>households.home_mgra</code> \u2192 <code>geography.MAZ_SEQ</code> (for county/district)</p>"},{"location":"data-model/#sample-expansion-weighting","title":"Sample Expansion (Weighting)","text":"<p>CRITICAL: The <code>sampleRate</code> field is a decimal fraction, not an expansion factor.</p> <ul> <li>In CSVs: <code>sampleRate = 0.01</code> means 1% sample (typical for full region model)</li> <li>Expansion factor: <code>1 / sampleRate = 1 / 0.01 = 100.0</code></li> <li>Interpretation: Each record represents 100 actual households/persons/tours/trips</li> </ul> <p>The system automatically inverts <code>sampleRate</code> to calculate weights.</p> <p>Common Values: - <code>0.01</code> = 1% sample (expansion factor 100) - typical for full model runs - <code>0.05</code> = 5% sample (expansion factor 20) - smaller test runs - <code>0.50</code> = 50% sample (expansion factor 2) - quick tests - <code>1.00</code> = 100% sample (expansion factor 1) - no sampling</p> Sample Rate Expansion Factor Meaning 1.0 1.0 100% sample (no expansion) 0.5 2.0 50% sample (each record = 2 real units) 0.05 20.0 5% sample (each record = 20 real units) <p>All summaries are weighted by default using the household <code>sampleRate</code> field.</p>"},{"location":"data-model/#preparing-travel-survey-data","title":"Preparing Travel Survey Data","text":"<p>To validate model outputs with household travel surveys (e.g., NHTS, CHTS), you must transform survey data to match this exact format:</p>"},{"location":"data-model/#required-steps","title":"Required Steps:","text":"<ol> <li> <p>Match column names exactly - Use <code>hh_id</code>, <code>person_id</code>, <code>tour_mode</code>, etc. (not survey-specific names)</p> </li> <li> <p>Align geography - Map survey zones/TAZs to MGRAs used by the model</p> </li> <li> <p>Standardize codes:</p> </li> <li>Person types \u2192 1-8 codes</li> <li>Tour purposes \u2192 \"Work\", \"Shop\", etc. (text values)</li> <li>Transportation modes \u2192 1-17 numeric codes</li> <li> <p>Time periods \u2192 1-48 (30-minute intervals)</p> </li> <li> <p>Add required fields:</p> </li> <li><code>sampleRate</code> - Survey expansion factor (as percentage if &gt;1, invert if needed)</li> <li> <p>Geography lookup - Ensure survey zones map to counties/districts</p> </li> <li> <p>Create hierarchy:</p> </li> <li>Household file with unique <code>hh_id</code></li> <li>Person file with <code>person_id</code> linked to <code>hh_id</code></li> <li>Tour/trip files linked to <code>person_id</code> and <code>tour_id</code></li> </ol>"},{"location":"data-model/#example-transformation","title":"Example Transformation:","text":"<p>Survey Format (before): <pre><code>household_id,num_autos,hh_size,region\n1001,2,3,\"San Francisco\"\n</code></pre></p> <p>CTRAMP Format (after): <pre><code>hh_id,autos,size,home_mgra,income,workers,sampleRate\n1,2,3,450,3,2,0.01\n</code></pre></p> <p>Key Differences: - Survey IDs \u2192 Sequential IDs starting from 1 - Region name \u2192 <code>home_mgra</code> (numeric zone) - Add missing fields: <code>income</code>, <code>workers</code>, <code>sampleRate</code> - Column names match CTRAMP exactly</p>"},{"location":"data-model/#data-validation","title":"Data Validation","text":"<p>The system expects:</p> <p>\u2705 Valid relationships: Every person has a household, every tour has a person \u2705 Consistent geography: All MGRAs exist in geography lookup \u2705 Valid codes: Person types 1-8, modes 1-17, etc. \u2705 Required columns present: See schemas above \u2705 Numeric types correct: IDs as integers, rates as floats  </p> <p>\u274c The system does NOT: - Check for logical errors (e.g., 8-year-old full-time worker) - Validate tour/trip sequences - Verify mode choice feasibility - Standardize survey data formats</p>"},{"location":"data-model/#configuration","title":"Configuration","text":"<p>The data model is defined in <code>ctramp_data_model.yaml</code> which maps:</p> <ol> <li>Input schema - CSV column names \u2192 Internal field names</li> <li>Value mappings - Numeric codes \u2192 Human-readable labels</li> <li>Aggregation specs - How to group categories (e.g., 4+ person households)</li> <li>Weight fields - Which columns contain expansion factors</li> </ol> <p>To customize: Edit <code>ctramp_data_model.yaml</code> if your model uses different column names or codes.</p>"},{"location":"data-model/#official-tm2-documentation","title":"Official TM2 Documentation","text":"<p>Complete CTRAMP data specifications:</p> <ul> <li>Overview: https://bayareametro.github.io/tm2py/ctramp-outputs/</li> <li>Households: https://bayareametro.github.io/tm2py/ctramp-outputs/household/</li> <li>Persons: https://bayareametro.github.io/tm2py/ctramp-outputs/person/</li> <li>Tours: https://bayareametro.github.io/tm2py/ctramp-outputs/individual-tours/</li> <li>Trips: https://bayareametro.github.io/tm2py/ctramp-outputs/individual-trips/</li> <li>Data Dictionaries: https://bayareametro.github.io/tm2py/ctramp-outputs/data-dictionaries/</li> </ul>"},{"location":"data-model/#next-steps","title":"Next Steps","text":"<ul> <li>Generate Summaries - Run the system on model outputs</li> <li>Custom Summaries - Create new aggregations</li> <li>External Data - Integrate ACS/CTPP/survey data</li> <li>Validation System Overview - Return to main guide</li> </ul>"},{"location":"external-data/","title":"External Observed Data","text":"<p>Reference guide for observed data sources used for model validation.</p>"},{"location":"external-data/#overview","title":"Overview","text":"<p>The summaries generated from CTRAMP model runs can be compared against observed data from external sources like census data, employment surveys, and synthetic population outputs.</p> <p>Available External Data Sources:</p>"},{"location":"external-data/#populationsim-summaries","title":"PopulationSim Summaries","text":"<p>Pre-generated PopulationSim summary files are stored in: <pre><code>tm2py_utils/summary/validation/outputs/populationsim/\n</code></pre></p> <p>Files included: - <code>households_by_county.csv</code> - Household distribution by county - <code>households_by_income.csv</code> - Household income distribution - <code>households_by_workers.csv</code> - Household worker distribution - <code>household_size_regional.csv</code> - Regional household size distribution - <code>persons_by_age.csv</code> - Population age distribution</p> <p>Source: These files are generated from PopulationSim output (<code>aggregate_summaries/</code>) and copied here for reference alongside CTRAMP model outputs.</p> <p>See the README in that directory for more details.</p>"},{"location":"external-data/#acs-american-community-survey-data","title":"ACS (American Community Survey) Data","text":"<p>ACS observed data files are stored in: <pre><code>tm2py_utils/summary/validation/outputs/observed/\n</code></pre></p> <p>Files included: - <code>acs_auto_ownership_by_household_size.csv</code> - <code>acs_auto_ownership_by_household_size_county.csv</code> - <code>acs_auto_ownership_by_household_size_regional.csv</code></p>"},{"location":"external-data/#other-external-sources","title":"Other External Sources","text":"<p>Additional external data sources that may be useful for validation: - CTPP (Census Transportation Planning Products) - Journey-to-work patterns - External surveys - Employment surveys, regional studies - Other tabulated data - Pre-aggregated statistics</p> <p>Note: This is for pre-aggregated summary data from external sources, not household travel survey microdata. Household travel surveys should be formatted to match the CTRAMP data model and processed as model inputs</p>"},{"location":"external-data/#system-architecture","title":"System Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 EXTERNAL DATA (ACS/CTPP/Surveys)             \u2502\n\u2502 - Raw census tables                          \u2502\n\u2502 - Pre-aggregated summaries                   \u2502\n\u2502 - Different column names/formats             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n        YOU MUST PREPROCESS TO MATCH\n        MODEL SUMMARY FORMAT\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 PREPROCESSED EXTERNAL DATA                   \u2502\n\u2502 - Same columns as model summaries            \u2502\n\u2502 - Same categories (1,2,3,4+ households)      \u2502\n\u2502 - Same geography (counties match model)      \u2502\n\u2502 - CSV format with dataset column             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n        observed_summaries CONFIG\n        (file paths + column mapping)\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 SYSTEM MERGES                                \u2502\n\u2502 Model Summary + External Data \u2192 Combined CSV \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DASHBOARD VISUALIZATION                      \u2502\n\u2502 Model vs. Observed comparisons               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key principle: You preprocess external data to match model format. The system does NOT automatically convert ACS/CTPP raw data.</p>"},{"location":"external-data/#quick-start","title":"Quick Start","text":""},{"location":"external-data/#step-1-preprocess-external-data","title":"Step 1: Preprocess External Data","text":"<p>Create a CSV matching your model summary format.</p> <p>Example: ACS auto ownership by household size (regional)</p> <p>Required columns (must match model summary): - <code>num_persons</code> (or aggregated field name) - <code>num_vehicles</code> - <code>households</code> (count) - <code>share</code> (percentage)</p> <p>Example file: <code>acs_auto_ownership_by_household_size_regional.csv</code></p> <pre><code>num_persons,num_vehicles,households,share\n1,0,120000,0.30\n1,1,180000,0.45\n1,2,100000,0.25\n2,0,80000,0.15\n2,1,200000,0.38\n2,2,250000,0.47\n3,0,50000,0.10\n3,1,150000,0.30\n3,2,300000,0.60\n4,0,40000,0.08\n4,1,120000,0.24\n4,2,340000,0.68\n</code></pre>"},{"location":"external-data/#step-2-configure-in-validation_configyaml","title":"Step 2: Configure in validation_config.yaml","text":"<p>Add to <code>observed_summaries</code> section:</p> <pre><code>observed_summaries:\n  - name: \"acs_2023\"\n    display_name: \"ACS 2023\"\n    summaries:\n      auto_ownership_by_household_size_acs:\n        file: \"C:\\\\path\\\\to\\\\acs_auto_ownership_by_household_size_regional.csv\"\n        columns:\n          num_persons_agg: \"num_persons\"  # Map 'num_persons' to model's 'num_persons_agg'\n          num_vehicles: \"num_vehicles\"\n          households: \"households\"\n          share: \"share\"\n</code></pre>"},{"location":"external-data/#step-3-create-matching-model-summary","title":"Step 3: Create Matching Model Summary","text":"<p>Ensure you have a model summary with the same name and columns:</p> <pre><code>summaries:\n  - name: \"auto_ownership_by_household_size_acs\"\n    data_source: \"households\"\n    group_by: [\"num_persons_agg\", \"num_vehicles\"]\n    share_within: \"num_persons_agg\"\n</code></pre>"},{"location":"external-data/#step-4-regenerate-summaries","title":"Step 4: Regenerate Summaries","text":"<pre><code>conda activate tm2py-utils\ncd C:\\GitHub\\tm2py-utils\\tm2py_utils\\summary\\validation\npython -m tm2py_utils.summary.validation.summaries.run_all --config validation_config.yaml\n</code></pre> <p>Output: Combined CSV with model + ACS data:</p> <pre><code>num_persons_agg,num_vehicles,households,share,dataset\n1,0,150000,0.28,2023 TM2.2 v05\n1,1,200000,0.37,2023 TM2.2 v05\n1,2,190000,0.35,2023 TM2.2 v05\n1,0,120000,0.30,ACS 2023\n1,1,180000,0.45,ACS 2023\n1,2,100000,0.25,ACS 2023\n...\n</code></pre>"},{"location":"external-data/#configuration-details","title":"Configuration Details","text":""},{"location":"external-data/#observed_summaries-structure","title":"observed_summaries Structure","text":"<pre><code>observed_summaries:\n  - name: \"source_identifier\"           # Internal name (no spaces)\n    display_name: \"Display Name\"        # Name shown in dashboards\n    summaries:\n      summary_name_1:                   # Must match a model summary name\n        file: \"path/to/file.csv\"\n        columns:                        # Column mapping (model_col: file_col)\n          model_column_1: \"file_column_1\"\n          model_column_2: \"file_column_2\"\n      summary_name_2:\n        file: \"path/to/another_file.csv\"\n        columns:\n          ...\n</code></pre> <p>Fields:</p> Field Required Description Example <code>name</code> \u2705 Internal identifier <code>\"acs_2023\"</code> <code>display_name</code> \u2705 Dashboard label <code>\"ACS 2023\"</code> <code>summaries</code> \u2705 Dictionary of summaries to load See below <p>Summary configuration:</p> Field Required Description <code>file</code> \u2705 Absolute path to CSV file <code>columns</code> \u26a0\ufe0f Column name mapping (optional if names match exactly)"},{"location":"external-data/#column-mapping","title":"Column Mapping","text":"<p>Maps external data column names to model column names.</p> <p>Syntax:</p> <pre><code>columns:\n  model_column_name: \"external_file_column_name\"\n</code></pre> <p>Example 1: Column names differ</p> <pre><code>columns:\n  num_persons_agg: \"hh_size\"      # Model uses 'num_persons_agg', file has 'hh_size'\n  num_vehicles: \"vehicles\"        # Model uses 'num_vehicles', file has 'vehicles'\n  households: \"count\"             # Model uses 'households', file has 'count'\n  share: \"percentage\"             # Model uses 'share', file has 'percentage'\n</code></pre> <p>Example 2: Column names match (no mapping needed)</p> <pre><code>columns:\n  num_persons_agg: \"num_persons_agg\"\n  num_vehicles: \"num_vehicles\"\n  households: \"households\"\n  share: \"share\"\n</code></pre> <p>Or omit <code>columns</code> entirely if all names match.</p>"},{"location":"external-data/#data-format-requirements","title":"Data Format Requirements","text":""},{"location":"external-data/#required-columns","title":"Required Columns","text":"<p>External data files must contain:</p> <ol> <li>Dimension columns - Same as model summary's <code>group_by</code></li> <li>Metric columns - Usually <code>households</code>, <code>persons</code>, <code>tours</code>, or <code>trips</code></li> <li>Share column - Percentage (0.0 to 1.0 or 0 to 100)</li> </ol> <p>Do NOT include <code>dataset</code> column - the system adds this automatically.</p>"},{"location":"external-data/#data-types","title":"Data Types","text":"Column Type Format Example Categorical dimensions String or integer <code>\"Alameda\"</code>, <code>1</code> Count metrics Integer or float <code>150000</code>, <code>150000.5</code> Shares Float (0-1) <code>0.25</code> (25%)"},{"location":"external-data/#category-alignment","title":"Category Alignment","text":"<p>Critical: External data categories must match model aggregations.</p> <p>Example: Household size</p> <p>Model uses: <code>num_persons_agg</code> with values <code>1, 2, 3, 4</code> (4 = \"4+\")</p> <p>ACS raw data has: <code>1, 2, 3, 4, 5, 6, 7+</code></p> <p>You must aggregate ACS: <code>1, 2, 3, 4+</code> (combine 4, 5, 6, 7+ \u2192 4)</p> <p>How to aggregate: - See model's <code>aggregation_specs</code> in <code>validation_config.yaml</code> - Match those category definitions in your preprocessing - Use same labels (strings must match exactly)</p>"},{"location":"external-data/#geography-alignment","title":"Geography Alignment","text":"<p>County names must match exactly:</p> <p>Model geography: <pre><code>Alameda\nContra Costa\nMarin\nNapa\nSan Francisco\nSan Mateo\nSanta Clara\nSolano\nSonoma\n</code></pre></p> <p>External data must use identical spelling and capitalization.</p>"},{"location":"external-data/#preprocessing-examples","title":"Preprocessing Examples","text":""},{"location":"external-data/#example-1-acs-household-size-by-vehicles","title":"Example 1: ACS Household Size by Vehicles","text":"<p>Source: ACS Table B08201 (Household Size by Vehicles Available)</p> <p>Raw ACS format:</p> <pre><code>geography,grouping,universe,share\nBay Area,\"Total:\",2490000,1.0\nBay Area,\"Total: 1-person household:\",400000,0.161\nBay Area,\"Total: 1-person household: No vehicle available\",120000,0.048\nBay Area,\"Total: 1-person household: 1 vehicle available\",200000,0.080\nBay Area,\"Total: 1-person household: 2 vehicles available\",80000,0.032\n...\n</code></pre> <p>Preprocessing script: <code>convert_acs_data.py</code></p> <pre><code>import pandas as pd\n\n# Load raw ACS data\ndf = pd.read_csv('acs_raw.csv')\n\n# Parse grouping labels\ndef parse_label(label):\n    if '1-person household:' in label:\n        persons = '1'\n    elif '2-person household:' in label:\n        persons = '2'\n    elif '3-person household:' in label:\n        persons = '3'\n    elif '4-or-more-person household:' in label:\n        persons = '4+'  # Aggregated\n    else:\n        return None, None\n\n    if 'No vehicle' in label:\n        vehicles = 0\n    elif '1 vehicle' in label:\n        vehicles = 1\n    elif '2 vehicles' in label:\n        vehicles = 2\n    elif '3 vehicles' in label:\n        vehicles = 3\n    elif '4 or more' in label:\n        vehicles = 4\n    else:\n        return None, None\n\n    return persons, vehicles\n\n# Extract detail rows\nrecords = []\nfor _, row in df.iterrows():\n    persons, vehicles = parse_label(row['grouping'])\n    if persons and vehicles is not None:\n        records.append({\n            'num_persons': persons,\n            'num_vehicles': vehicles,\n            'households': row['universe'],\n            'share': row['share']\n        })\n\nresult = pd.DataFrame(records)\n\n# Recalculate shares within household size\nresult['share'] = result.groupby('num_persons')['households'].transform(\n    lambda x: x / x.sum()\n)\n\nresult.to_csv('acs_auto_ownership_by_household_size_regional.csv', index=False)\n</code></pre> <p>Output:</p> <pre><code>num_persons,num_vehicles,households,share\n1,0,120000,0.30\n1,1,200000,0.50\n1,2,80000,0.20\n2,0,80000,0.15\n...\n</code></pre>"},{"location":"external-data/#example-2-ctpp-journey-to-work","title":"Example 2: CTPP Journey to Work","text":"<p>Source: CTPP Table A302 (Place of Work by Residence)</p> <p>Goal: Compare commute patterns</p> <p>Preprocessing:</p> <pre><code>import pandas as pd\n\n# Load CTPP data\nctpp = pd.read_csv('ctpp_work_flows.csv')\n\n# Map TAZs to counties\ntaz_to_county = pd.read_csv('taz_county_lookup.csv')\n\n# Aggregate to county-to-county flows\nflows = ctpp.merge(\n    taz_to_county.rename(columns={'county': 'home_county'}),\n    left_on='residence_taz',\n    right_on='taz'\n).merge(\n    taz_to_county.rename(columns={'county': 'work_county'}),\n    left_on='workplace_taz',\n    right_on='taz'\n)\n\nresult = flows.groupby(['home_county', 'work_county'])['workers'].sum().reset_index()\nresult['share'] = result.groupby('home_county')['workers'].transform(lambda x: x / x.sum())\n\nresult.to_csv('ctpp_work_location_by_home_county.csv', index=False)\n</code></pre>"},{"location":"external-data/#example-3-external-employment-survey","title":"Example 3: External Employment Survey","text":"<p>Source: Regional employment survey by industry</p> <p>Goal: Compare employment distribution</p> <p>Format to match model:</p> <pre><code>import pandas as pd\n\nsurvey = pd.read_csv('employment_survey.csv')\n\n# Map survey categories to model person_types\ncategory_map = {\n    'Full-time': 1,\n    'Part-time': 2,\n    'Student': 3,\n    # etc.\n}\n\nsurvey['person_type'] = survey['employment_category'].map(category_map)\n\nresult = survey.groupby('person_type')['persons'].sum().reset_index()\nresult['share'] = result['persons'] / result['persons'].sum()\n\nresult.to_csv('survey_employment_distribution.csv', index=False)\n</code></pre>"},{"location":"external-data/#complete-configuration-example","title":"Complete Configuration Example","text":""},{"location":"external-data/#scenario-compare-model-to-acs-2023","title":"Scenario: Compare Model to ACS 2023","text":"<p>Model summaries to validate: 1. Auto ownership by household size (regional) 2. Auto ownership by household size (county-level)</p> <p>External data: - ACS 2023 data, preprocessed to match model format</p> <p>Configuration:</p> <pre><code># validation_config.yaml\n\n# Model summaries (generate from model data)\nsummaries:\n  - name: \"auto_ownership_by_household_size_acs\"\n    description: \"Vehicle ownership by household size (ACS categories)\"\n    data_source: \"households\"\n    group_by: [\"num_persons_agg\", \"num_vehicles\"]\n    weight_field: \"sample_rate\"\n    count_name: \"households\"\n    share_within: \"num_persons_agg\"\n\n  - name: \"auto_ownership_by_household_size_county\"\n    description: \"Vehicle ownership by household size and county\"\n    data_source: \"households\"\n    group_by: [\"county\", \"num_persons_agg\", \"num_vehicles\"]\n    weight_field: \"sample_rate\"\n    count_name: \"households\"\n    share_within: [\"county\", \"num_persons_agg\"]\n\n# External data (load from preprocessed files)\nobserved_summaries:\n  - name: \"acs_2023\"\n    display_name: \"ACS 2023\"\n    summaries:\n      # Regional comparison\n      auto_ownership_by_household_size_acs:\n        file: \"C:\\\\data\\\\acs\\\\acs_auto_ownership_by_household_size_regional.csv\"\n        columns:\n          num_persons_agg: \"num_persons\"\n          num_vehicles: \"num_vehicles\"\n          households: \"households\"\n          share: \"share\"\n\n      # County-level comparison\n      auto_ownership_by_household_size_county:\n        file: \"C:\\\\data\\\\acs\\\\acs_auto_ownership_by_household_size_county.csv\"\n        columns:\n          county: \"county\"\n          num_persons_agg: \"num_persons\"\n          num_vehicles: \"num_vehicles\"\n          households: \"households\"\n          share: \"share\"\n\n# Aggregation spec (model and ACS must use same categories)\naggregation_specs:\n  num_persons_agg:\n    apply_to: [\"num_persons\"]\n    mapping:\n      1: 1\n      2: 2\n      3: 3\n      4: 4   # 4+ aggregation\n      5: 4\n      6: 4\n      7: 4\n      8: 4\n      9: 4\n      10: 4\n</code></pre>"},{"location":"external-data/#execution-and-output","title":"Execution and Output","text":""},{"location":"external-data/#run-summary-generation","title":"Run Summary Generation","text":"<pre><code>python -m tm2py_utils.summary.validation.summaries.run_all --config validation_config.yaml\n</code></pre> <p>Log output:</p> <pre><code>INFO - Loading data from 2023_version_05: A:\\2023-tm22-dev-version-05\\ctramp_output\nINFO -   \u2713 Loaded households: 2,490,000 records\n...\nINFO - Loading pre-aggregated summaries from acs_2023: ACS 2023\nINFO -   \u2713 Loaded auto_ownership_by_household_size_acs: 20 rows from acs_auto_ownership_by_household_size_regional.csv\nINFO -   \u2713 Loaded auto_ownership_by_household_size_county: 180 rows from acs_auto_ownership_by_household_size_county.csv\n...\nINFO - Combining multi-run summaries...\nINFO -   \u2713 Saved auto_ownership_by_household_size_acs.csv: 60 rows (3 datasets)\nINFO -   \u2713 Saved auto_ownership_by_household_size_county.csv: 539 rows (3 datasets)\n</code></pre>"},{"location":"external-data/#output-file-structure","title":"Output File Structure","text":"<p>Combined file: <code>auto_ownership_by_household_size_acs.csv</code></p> <pre><code>num_persons_agg,num_vehicles,households,share,dataset\n1,0,150000,0.28,2023 TM2.2 v05\n1,1,200000,0.37,2023 TM2.2 v05\n1,2,190000,0.35,2023 TM2.2 v05\n1,0,130000,0.26,2015 TM2.2 Sprint 04\n1,1,210000,0.42,2015 TM2.2 Sprint 04\n1,2,160000,0.32,2015 TM2.2 Sprint 04\n1,0,120000,0.30,ACS 2023\n1,1,180000,0.45,ACS 2023\n1,2,100000,0.25,ACS 2023\n2,0,80000,0.15,2023 TM2.2 v05\n2,1,200000,0.38,2023 TM2.2 v05\n...\n</code></pre> <p>Dataset column values: - <code>2023 TM2.2 v05</code> - From model run - <code>2015 TM2.2 Sprint 04</code> - From older model run - <code>ACS 2023</code> - From external data (<code>display_name</code> in config)</p>"},{"location":"external-data/#troubleshooting","title":"Troubleshooting","text":""},{"location":"external-data/#external-data-not-appearing","title":"External Data Not Appearing","text":"<pre><code>WARNING - Summary file not found: C:\\...\\acs_data.csv\n</code></pre> <p>Solutions: 1. Check file path is absolute (not relative) 2. Verify file exists at specified location 3. Check for typos in path</p>"},{"location":"external-data/#column-not-found","title":"Column Not Found","text":"<pre><code>KeyError: 'num_persons_agg'\n</code></pre> <p>Cause: Column mapping incorrect</p> <p>Solution: Verify column names in external file match <code>columns</code> mapping</p>"},{"location":"external-data/#mismatched-categories","title":"Mismatched Categories","text":"<p>Dashboard shows: Model has 4+ households, ACS shows 4, 5, 6, 7+</p> <p>Cause: External data not aggregated to match model</p> <p>Solution: Preprocess external data to combine 4, 5, 6, 7+ \u2192 \"4+\"</p>"},{"location":"external-data/#wrong-summary-name","title":"Wrong Summary Name","text":"<pre><code>WARNING - No model summary found matching 'wrong_name'\n</code></pre> <p>Cause: <code>observed_summaries</code> key doesn't match any model summary name</p> <p>Solution: Ensure <code>summaries:</code> keys match <code>summaries[].name</code> in config exactly</p>"},{"location":"external-data/#shares-dont-match","title":"Shares Don't Match","text":"<p>Example: ACS share = 0.30, but model share calculated differently</p> <p>Cause: Different <code>share_within</code> grouping</p> <p>Model: <pre><code>share_within: [\"county\", \"num_persons_agg\"]  # Share within county \u00d7 household size\n</code></pre></p> <p>External data: Share might be regional (not within groups)</p> <p>Solution: Recalculate shares in preprocessing to match model's grouping</p>"},{"location":"external-data/#best-practices","title":"Best Practices","text":"<ol> <li>Match aggregations first - Review model's <code>aggregation_specs</code> before preprocessing</li> <li>Use absolute paths - Avoid relative paths in <code>file</code> specifications</li> <li>Standardize geography - County names must match exactly (case-sensitive)</li> <li>Document preprocessing - Keep scripts that generate external data files</li> <li>Version control - Track which ACS/CTPP year/version you're using</li> <li>Test with one summary - Validate workflow before adding multiple summaries</li> <li>Check shares add to 1.0 - Within appropriate grouping levels</li> </ol>"},{"location":"external-data/#data-source-guidelines","title":"Data Source Guidelines","text":""},{"location":"external-data/#acs-american-community-survey","title":"ACS (American Community Survey)","text":"<p>Recommended tables: - B08201 - Household Size by Vehicles - B08134 - Means of Transportation to Work - B08303 - Travel Time to Work - B19001 - Household Income</p> <p>Aggregation notes: - Household size: Use 1, 2, 3, 4+ categories - Vehicles: 0, 1, 2, 3, 4+ (ACS has \"3 or more\", model might have separate 3 and 4+)</p>"},{"location":"external-data/#ctpp-census-transportation-planning-products","title":"CTPP (Census Transportation Planning Products)","text":"<p>Recommended tables: - A302 - Place of Work by Residence - A201 - Journey to Work Flows - A103 - Travel Time to Work</p> <p>Geography notes: - CTPP uses TAZs \u2192 aggregate to counties for comparison - Maintain lookup tables for TAZ-to-county mapping</p>"},{"location":"external-data/#employment-surveys","title":"Employment Surveys","text":"<p>Considerations: - Map employment categories to model's <code>person_type</code> codes - Ensure sample weights/expansion factors applied - Match reference year to model year</p>"},{"location":"external-data/#next-steps","title":"Next Steps","text":"<ul> <li>Generate Summaries - Run the full summary generation</li> <li>Deploy Dashboard - Visualize model vs. observed comparisons</li> <li>Custom Summaries - Create new summary definitions</li> <li>Data Model Reference - Understand model data format</li> </ul>"},{"location":"generate-summaries/","title":"Generate Summaries from Model Runs","text":"<p>Guide to generating validation summaries from CTRAMP model outputs using the new simple toolkit.</p>"},{"location":"generate-summaries/#overview","title":"Overview","text":"<p>The summary generation system reads raw CTRAMP outputs (CSV files) and produces aggregated summary tables for validation and analysis. The process is configuration-driven - add summaries by editing YAML, no Python coding required.</p> <p>System Design</p> <p>To understand the architecture and design principles behind this system, see the Summary Design System Plan.</p> <p>What it does: - Loads CTRAMP output files (households, persons, tours, trips) - Applies value labels (mode 1 \u2192 \"SOV_GP\") - Creates aggregated categories (17 modes \u2192 5 major groups) - Bins continuous variables (age \u2192 age groups, distance \u2192 bins) - Generates weighted frequency tables - Validates results for data quality issues - Saves individual CSV files for each summary</p> <p>Output: 30 CSV files ready for analysis in Excel, pandas, R, or other analysis tools.</p>"},{"location":"generate-summaries/#quick-start","title":"Quick Start","text":""},{"location":"generate-summaries/#1-run-summary-generation","title":"1. Run Summary Generation","text":"<pre><code>cd tm2py_utils/summary/validation\n\n# Generate all summaries for one model run\npython summarize_model_run.py \"C:/path/to/ctramp_output\"\n</code></pre> <p>Summaries are saved to <code>outputs/</code> by default.</p>"},{"location":"generate-summaries/#2-specify-custom-output-location","title":"2. Specify Custom Output Location","text":"<pre><code>python summarize_model_run.py \"C:/path/to/ctramp_output\" --output \"my_results\"\n</code></pre>"},{"location":"generate-summaries/#3-enable-strict-validation","title":"3. Enable Strict Validation","text":"<p>Treat validation warnings as errors:</p> <pre><code>python summarize_model_run.py \"C:/path/to/ctramp_output\" --strict\n</code></pre>"},{"location":"generate-summaries/#expected-input-files","title":"Expected Input Files","text":"<p>The system looks for these files in the CTRAMP output directory:</p>"},{"location":"generate-summaries/#required-files","title":"Required Files","text":"File Pattern Description Example <code>householdData_*.csv</code> Household data <code>householdData_3.csv</code> <code>personData_*.csv</code> Person data <code>personData_3.csv</code> <code>indivTourData_*.csv</code> Individual tours <code>indivTourData_3.csv</code> <code>indivTripData_*.csv</code> Individual trips <code>indivTripData_3.csv</code>"},{"location":"generate-summaries/#optional-files","title":"Optional Files","text":"File Pattern Description Used For <code>wsLocResults.csv</code> Work/school location Commute summaries <code>jointTourData_*.csv</code> Joint tours Joint tour summaries <p>Note: The tool automatically detects the iteration number (e.g., <code>_1.csv</code>, <code>_3.csv</code>).</p> File Pattern Description <code>wsLocResults.csv</code> Workplace/school location (no iteration number) <code>jointTourData_{iteration}.csv</code> Joint household tours <code>jointTripData_{iteration}.csv</code> Joint household trips <p>File Naming: - <code>{iteration}</code> is replaced with the value from <code>input_directories[].iteration</code> config - Default: <code>iteration: 1</code> \u2192 looks for <code>householdData_1.csv</code> - If <code>iteration</code> not specified, uses highest numbered file (e.g., <code>householdData_3.csv</code> if 1, 2, 3 exist)</p> <p>Data Format: All files must match the CTRAMP data model. See that page for required columns and codes.</p>"},{"location":"generate-summaries/#output-structure","title":"Output Structure","text":"<p>The system generates two types of output files:</p>"},{"location":"generate-summaries/#1-per-dataset-files","title":"1. Per-Dataset Files","text":"<p>One file per summary per dataset, with dataset name in filename:</p> <p><pre><code>auto_ownership_regional_2023 TM2.2 v05.csv\nauto_ownership_regional_2015 TM2.2 Sprint 04.csv\n---\n\n## What Gets Generated\n\nThe tool creates **30 individual CSV files**, one for each summary. Each file contains aggregated statistics ready for analysis.\n\n### Example Output Files\n</code></pre> outputs/ \u251c\u2500\u2500 auto_ownership_regional.csv \u251c\u2500\u2500 auto_ownership_by_income.csv \u251c\u2500\u2500 auto_ownership_by_household_size.csv \u251c\u2500\u2500 person_type_distribution.csv \u251c\u2500\u2500 age_distribution.csv \u251c\u2500\u2500 cdap_by_person_type.csv \u251c\u2500\u2500 cdap_regional.csv \u251c\u2500\u2500 tour_frequency_by_purpose.csv \u251c\u2500\u2500 tour_mode_choice.csv \u251c\u2500\u2500 tour_distance_distribution.csv \u251c\u2500\u2500 trip_mode_choice.csv \u251c\u2500\u2500 trip_distance_distribution.csv \u251c\u2500\u2500 time_of_day_tours.csv \u2514\u2500\u2500 ... (30 total) <pre><code>### Example CSV Structure\n\n**Simple distribution** (`auto_ownership_regional.csv`):\n\n```csv\nnum_vehicles,households,share\n0,150234.5,0.054\n1,823456.2,0.298\n2,1245678.3,0.450\n3,445632.1,0.161\n4+,102026.9,0.037\n</code></pre></p> <p>Cross-tabulation (<code>auto_ownership_by_income.csv</code>):</p> <pre><code>income_category_bin,num_vehicles,households,share\n&lt;30K,0,45623.2,0.421\n&lt;30K,1,52341.6,0.483\n&lt;30K,2,9234.5,0.085\n30-60K,0,32456.7,0.156\n30-60K,1,98234.5,0.472\n30-60K,2,65432.1,0.314\n...\n</code></pre> <p>With aggregations (<code>trip_distance_distribution.csv</code>):</p> <pre><code>trip_distance_bin,trips,share,mean_distance\n&lt;1mi,8234567.2,0.342,0.45\n1-3mi,5632451.3,0.234,2.12\n3-5mi,3456234.1,0.143,4.03\n5-10mi,2345678.9,0.097,7.24\n10+mi,1987654.0,0.082,18.45\n</code></pre>"},{"location":"generate-summaries/#pre-configured-summaries","title":"Pre-Configured Summaries","text":"<p>The system includes 30 pre-configured summaries defined in <code>data_model/ctramp_data_model.yaml</code>:</p>"},{"location":"generate-summaries/#household-summaries-3","title":"Household Summaries (3)","text":"<ul> <li>Auto ownership (regional, by income, by household size)</li> </ul>"},{"location":"generate-summaries/#person-activity-summaries-4","title":"Person &amp; Activity Summaries (4)","text":"<ul> <li>Person type distribution</li> <li>Age distribution</li> <li>CDAP by person type</li> <li>CDAP regional</li> </ul>"},{"location":"generate-summaries/#tour-summaries-9","title":"Tour Summaries (9)","text":"<ul> <li>Tour frequency by purpose</li> <li>Tour mode choice (overall and by purpose)</li> <li>Tour distance distributions</li> <li>Time of day patterns</li> <li>Tour start/end times</li> </ul>"},{"location":"generate-summaries/#trip-summaries-8","title":"Trip Summaries (8)","text":"<ul> <li>Trip mode choice (overall and by purpose)</li> <li>Trip purpose distribution</li> <li>Trip distance distributions</li> <li>Trip duration distributions</li> </ul>"},{"location":"generate-summaries/#workschool-location-6","title":"Work/School Location (6)","text":"<ul> <li>Average commute distance</li> <li>Work distance by county</li> <li>Workplace destinations</li> <li>Work location patterns</li> </ul> <p>See <code>data_model/ctramp_data_model.yaml</code> for complete list with full definitions.</p>"},{"location":"generate-summaries/#sample-expansion-weighting","title":"Sample Expansion (Weighting)","text":"<p>Most summaries are automatically weighted by household sample rate.</p> <p>How it works:</p> <ol> <li>System reads sample rate from household data (typically 0.01 to 1.0)</li> <li>Applies expansion factor = <code>1 / sample_rate</code></li> <li>Each household/person/tour/trip is counted with its weight</li> <li>Final counts represent full population estimates</li> </ol> <p>Example: - Sample rate: 0.5 (50% sample) - Expansion factor: 2.0 - Each record represents 2 households in the full population</p>"},{"location":"generate-summaries/#understanding-output-columns","title":"Understanding Output Columns","text":""},{"location":"generate-summaries/#count-columns","title":"Count Columns","text":"<p>Summaries include weighted counts appropriate to the data source:</p> Data Source Count Column Name Example Value households <code>households</code> 2,768,027 persons <code>persons</code> 7,442,845 individual_tours <code>tours</code> 12,345,678 individual_trips <code>trips</code> 25,678,901"},{"location":"generate-summaries/#share-columns","title":"Share Columns","text":"<p>Most summaries include a <code>share</code> column showing the proportion within each group:</p> <pre><code>tour_mode_name,tours,share\nDrive Alone,5234567,0.425\nCarpool 2,1987654,0.161\nWalk-Transit-Walk,987654,0.080\n...\n</code></pre> <p>Shares sum to 1.0 (or 100%) within each grouping level.</p>"},{"location":"generate-summaries/#aggregation-columns","title":"Aggregation Columns","text":"<p>Some summaries include calculated statistics:</p> <pre><code>trip_distance_bin,trips,share,mean_distance,total_distance\n&lt;1mi,8234567,0.342,0.45,3705555\n1-3mi,5632451,0.234,2.12,11940396\n3-5mi,3456234,0.143,4.03,13928622\n...\n</code></pre>"},{"location":"generate-summaries/#command-line-options","title":"Command Line Options","text":"<pre><code>python summarize_model_run.py &lt;ctramp_dir&gt; [OPTIONS]\n</code></pre>"},{"location":"generate-summaries/#arguments","title":"Arguments","text":"Option Description Default Example <code>ctramp_dir</code> Path to CTRAMP output directory (required) <code>\"A:/2015-tm22-dev/ctramp_output\"</code> <code>--output DIR</code> Output directory for summaries <code>outputs/</code> <code>--output \"my_results\"</code> <code>--strict</code> Treat validation warnings as errors <code>False</code> <code>--strict</code>"},{"location":"generate-summaries/#examples","title":"Examples","text":"<pre><code># Basic usage\npython summarize_model_run.py \"C:/model_run/ctramp_output\"\n\n# Custom output location\npython summarize_model_run.py \"C:/model_run/ctramp_output\" --output \"results_2024\"\n\n# Strict validation mode\npython summarize_model_run.py \"C:/model_run/ctramp_output\" --strict\n</code></pre>"},{"location":"generate-summaries/#validation","title":"Validation","text":"<p>The tool automatically validates all summaries after generation. Validation checks for:</p> <ol> <li>Negative values - Flags negative counts in non-negative fields</li> <li>Share totals - Verifies shares sum to ~1.0 within groups (\u00b10.5%)</li> <li>Zero totals - Warns about suspiciously small totals (&lt; 100)</li> <li>Statistical outliers - Identifies extreme values using IQR method</li> <li>Logical consistency - Domain-specific checks:</li> <li>Auto ownership &gt; 10 vehicles</li> <li>Invalid time periods</li> <li>Household size = 0 or &gt; 15</li> <li>Missing expected categories (age bins, etc.)</li> </ol>"},{"location":"generate-summaries/#example-validation-output","title":"Example Validation Output","text":"<pre><code>VALIDATION SUMMARY\n================================================================================\n  Checked 30 summaries\n\n  \u2713 25 summaries passed all checks\n  \u26a0 5 summaries have warnings:\n    - tour_distance_distribution: 2 outliers detected (expected in large datasets)\n    - household_size_distribution: Maximum household size is 18 (valid but unusual)\n    - trip_mode_by_purpose: 12 groups have shares not summing to 1.0 (rounding)\n\n[OK] Validation passed with 5 warnings\n</code></pre> <p>Use <code>--strict</code> flag to fail on warnings:</p> <pre><code>python summarize_model_run.py \"path/to/ctramp\" --strict\n# Exit code 1 if any warnings found\n</code></pre>"},{"location":"generate-summaries/#adding-custom-summaries","title":"Adding Custom Summaries","text":"<p>To add a new summary, edit <code>data_model/ctramp_data_model.yaml</code> and add to the <code>summaries:</code> section.</p>"},{"location":"generate-summaries/#example-trip-mode-by-income","title":"Example: Trip Mode by Income","text":"<pre><code>summaries:\n  # ... existing summaries ...\n\n  trip_mode_by_income:\n    description: \"Trip mode distribution by income category\"\n    data_source: \"individual_trips\"\n    group_by:\n      - \"income_category_bin\"\n      - \"trip_mode_name\"\n    aggregations:\n      trips:\n        column: \"trip_id\"\n        agg: \"count\"\n</code></pre> <p>Then run:</p> <pre><code>python summarize_model_run.py \"path/to/ctramp_output\"\n</code></pre> <p>The new summary <code>trip_mode_by_income.csv</code> will be generated automatically.</p> <p>See User Guide for detailed examples.</p>"},{"location":"generate-summaries/#execution-log","title":"Execution Log","text":"<p>The script provides detailed logging:</p> <pre><code>================================================================================\nSTEP 1: Loading Data Model Configuration\n================================================================================\nReading: data_model/ctramp_data_model.yaml\n[OK] Loaded configuration with 30 summary definitions\n\n================================================================================\nSTEP 2: Loading CTRAMP Output Files\n================================================================================\nSource directory: A:\\2015-tm22-dev-sprint-04\\ctramp_output\n\nLoading persons...\n  File: personData_3.csv\n  Rows: 7,442,845\n  Columns: 21\n  [OK] Loaded and standardized\n\nLoading households...\n  File: householdData_3.csv\n  Rows: 2,768,027\n  Columns: 12\n  [OK] Loaded and standardized\n\n================================================================================\nSTEP 3: Applying Value Labels\n================================================================================\nProcessing persons:\n  [OK] Labeled 'person_type' -&gt; 'person_type_name' (8 values)\n  [OK] Labeled 'cdap_activity' -&gt; 'cdap_activity_name' (3 values)\n\n================================================================================\nSTEP 4: Creating Aggregated Categories\n================================================================================\nProcessing persons:\n  [OK] Aggregated 'age' -&gt; 'age_bin' (8 categories)\n\n================================================================================\nSTEP 5: Binning Continuous Variables\n================================================================================\nProcessing persons:\n  [OK] Binned 'age' -&gt; 'age_bin' (8 bins)\n\n================================================================================\nSTEP 6: Generating Summaries\n================================================================================\n[1] auto_ownership_regional\n    Source: households (2,768,027 rows)\n  [OK] Saved: auto_ownership_regional.csv\n\n[2] auto_ownership_by_income\n    Source: households (2,768,027 rows)\n  [OK] Saved: auto_ownership_by_income.csv\n\n... (28 more summaries)\n\n[OK] Generated 30 summaries in outputs/\n\n================================================================================\nSTEP 7: Validation\n================================================================================\n\nVALIDATION SUMMARY\n================================================================================\n  Checked 30 summaries\n  \u2713 25 summaries passed all checks\n  \u26a0 5 summaries have warnings (outliers expected)\n\n[OK] Validation passed with 5 warnings\n</code></pre>"},{"location":"generate-summaries/#troubleshooting","title":"Troubleshooting","text":""},{"location":"generate-summaries/#file-not-found","title":"File Not Found","text":"<pre><code>[WARN] File not found matching pattern: wsLocResults.csv\n</code></pre> <p>Cause: Optional file missing (work/school location data)</p> <p>Solution: This is normal if your model run doesn't include work location choice. Related summaries will be skipped.</p>"},{"location":"generate-summaries/#column-not-found","title":"Column Not Found","text":"<pre><code>KeyError: 'trip_mode'\n</code></pre> <p>Cause: Expected column missing from CTRAMP output</p> <p>Solutions: 1. Check that files match expected CTRAMP format 2. Review column mappings in <code>data_model/ctramp_data_model.yaml</code> 3. Update YAML if your model uses different column names</p>"},{"location":"generate-summaries/#empty-summaries","title":"Empty Summaries","text":"<pre><code>[WARN] person_type_distribution.csv: 0 rows (empty)\n</code></pre> <p>Causes: - Missing required columns - Data type mismatch (text vs. numeric) - All values filtered out</p> <p>Solutions: 1. Check validation output for specific errors 2. Verify data contains expected values 3. Review filter conditions in summary definition</p>"},{"location":"generate-summaries/#memory-errors","title":"Memory Errors","text":"<p>For very large model runs (&gt;10M persons):</p> <p>Solutions: 1. Run on machine with more RAM (minimum 8 GB recommended) 2. Close other applications 3. Comment out some summaries in YAML to process fewer at once</p>"},{"location":"generate-summaries/#unicodeencoding-errors","title":"Unicode/Encoding Errors","text":"<p>The tool uses ASCII-safe symbols and should work on all Windows terminals. If you see encoding errors, check that your terminal supports UTF-8.</p>"},{"location":"generate-summaries/#performance","title":"Performance","text":"<p>Typical runtime for full Bay Area model (7.4M persons, 2.8M households):</p> <ul> <li>Loading data: ~2-3 minutes</li> <li>Labeling &amp; preprocessing: ~1-2 minutes</li> <li>Generating summaries: ~3-5 minutes</li> <li>Validation: ~30 seconds</li> <li>Total: ~7-11 minutes</li> </ul> <p>Memory usage: ~2-4 GB</p> <p>Tips to speed up: 1. Use SSD storage for CTRAMP output files 2. Run with sufficient RAM (8+ GB recommended) 3. Comment out unneeded summaries in YAML</p>"},{"location":"generate-summaries/#next-steps","title":"Next Steps","text":"<ul> <li>Analyze summaries: Use Excel, Python pandas, R, or BI tools</li> <li>Analyze results: Load CSVs into Excel, Python, R, or other tools for analysis</li> <li>Add custom summaries: Edit <code>ctramp_data_model.yaml</code> to add new analyses</li> <li>Validate data quality: Review validation warnings and investigate issues</li> </ul> <p>See also: - User Guide - Detailed user guide - README.md - Toolkit overview - PREPROCESSING_NOTES.md - Advanced summaries requiring preprocessing</p>"},{"location":"generate-summaries/#advanced-programmatic-usage","title":"Advanced: Programmatic Usage","text":"<p>For integration into automated workflows:</p> <pre><code>from pathlib import Path\nfrom tm2py_utils.summary.validation.summaries.run_all import load_config_file, main\n\n# Load config\nconfig, config_data = load_config_file(Path(\"validation_config.yaml\"))\n\n# Modify programmatically\nconfig.output_directory = Path(\"custom_output_dir\")\n\n# Generate summaries\n# (Call main() or use SummaryGenerator directly)\n</code></pre> <p>See <code>run_all.py</code> source code for full API.</p>"},{"location":"install/","title":"Installation Guide","text":""},{"location":"install/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python: 3.9 or higher</li> <li>Conda: Anaconda or Miniconda</li> <li>Git: For cloning the repository</li> </ul>"},{"location":"install/#installation-steps","title":"Installation Steps","text":""},{"location":"install/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/BayAreaMetro/tm2py-utils.git\ncd tm2py-utils\n</code></pre>"},{"location":"install/#2-create-conda-environment","title":"2. Create Conda Environment","text":"<pre><code># Create environment from environment.yml (if available)\nconda env create -f environment.yml\n\n# Or create manually\nconda create -n tm2py-utils python=3.9 pandas numpy pyyaml\nconda activate tm2py-utils\n</code></pre>"},{"location":"install/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Install required packages\npip install -r requirements.txt\n</code></pre>"},{"location":"install/#4-install-tm2py-utils","title":"4. Install tm2py-utils","text":"<pre><code># Install in development mode\npip install -e .\n</code></pre>"},{"location":"install/#verifying-installation","title":"Verifying Installation","text":"<p>Test that the installation works:</p> <pre><code># Check package is importable\npython -c \"import tm2py_utils; print('tm2py-utils installed successfully!')\"\n\n# List available summaries\ncd tm2py_utils/summary/validation\npython list_summaries.py\n</code></pre>"},{"location":"install/#optional-set-up-data-paths","title":"Optional: Set Up Data Paths","text":"<p>Edit <code>tm2py_utils/summary/validation/validation_config.yaml</code> to point to your model output directories:</p> <pre><code>input_directories:\n  - path: \"E:\\\\model_runs\\\\2023-tm22-dev-version-05\\\\ctramp_output\"\n    name: \"2023_version_05\"\n    display_name: \"2023 TM2.2 v05\"\n</code></pre>"},{"location":"install/#troubleshooting","title":"Troubleshooting","text":""},{"location":"install/#import-errors","title":"Import Errors","text":"<p>If you get <code>ModuleNotFoundError</code>, ensure you've activated the conda environment:</p> <pre><code>conda activate tm2py-utils\n</code></pre>"},{"location":"install/#permission-errors","title":"Permission Errors","text":"<p>On Windows, you may need to run PowerShell as Administrator for some operations.</p>"},{"location":"install/#next-steps","title":"Next Steps","text":"<ul> <li>Generate Summaries - Run the summarizer</li> <li>Summaries Reference - List of available summaries</li> <li>Configuration - YAML data model documentation</li> </ul>"},{"location":"summaries/","title":"Summary Generation System","text":"<p>The tm2py-utils summary system generates aggregated statistics from CTRAMP model outputs for validation.</p>"},{"location":"summaries/#overview","title":"Overview","text":"<p>The system provides: - 30 configured summaries - All defined in <code>ctramp_data_model.yaml</code> - Config-driven - Add summaries by editing YAML, no Python coding required - Simple &amp; transparent - One tool, clear logging, easy to understand - Automatic validation - Built-in quality checks for data issues</p>"},{"location":"summaries/#quick-start","title":"Quick Start","text":""},{"location":"summaries/#generate-summaries-for-one-model-run","title":"Generate Summaries for One Model Run","text":"<pre><code>cd tm2py_utils/summary/validation\npython summarize_model_run.py \"C:/path/to/ctramp_output\"\n</code></pre> <p>This creates CSV summaries in <code>outputs/</code> and automatically validates them.</p>"},{"location":"summaries/#specify-custom-output-directory","title":"Specify Custom Output Directory","text":"<pre><code>python summarize_model_run.py \"C:/path/to/ctramp_output\" --output \"my_results\"\n</code></pre>"},{"location":"summaries/#view-available-summaries","title":"View Available Summaries","text":"<p>Check <code>data_model/ctramp_data_model.yaml</code> to see all 30 summary definitions with documentation.</p>"},{"location":"summaries/#summary-types","title":"Summary Types","text":"<p>Household Summaries: - Auto ownership (regional, by income, by household size)</p> <p>Person &amp; Activity Patterns: - Person type distribution - Age distribution - CDAP patterns (by person type, regional)</p> <p>Tour Summaries: - Tour frequency by purpose - Tour mode choice (overall and by purpose) - Tour distance distributions - Time of day patterns</p> <p>Trip Summaries: - Trip mode choice (overall and by purpose) - Trip purpose distribution - Trip distance and duration distributions</p> <p>Work/School Location: - Average commute distance - Journey to work patterns</p> <p>See <code>data_model/ctramp_data_model.yaml</code> for complete list and definitions.</p>"},{"location":"summaries/#adding-custom-summaries","title":"Adding Custom Summaries","text":"<p>Edit <code>data_model/ctramp_data_model.yaml</code> and add to the <code>summaries:</code> section:</p> <pre><code>custom_summaries:\n  - name: \"my_new_summary\"\n    summary_type: \"validation\"  # or \"core\"\n    description: \"What this summarizes\"\n    data_source: \"individual_trips\"  # or households, tours, persons, etc.\n    group_by: [\"trip_mode\", \"tour_purpose\"]\n    weight_field: \"sample_rate\"\n    count_name: \"trips\"\n    share_within: \"tour_purpose\"  # Calculate shares within groups\n</code></pre>"},{"location":"summaries/#available-data-sources","title":"Available Data Sources","text":"<ul> <li><code>households</code> - Household-level data</li> <li><code>persons</code> - Person-level data</li> <li><code>individual_tours</code> - Tour-level data</li> <li><code>individual_trips</code> - Trip-level data</li> <li><code>workplace_school</code> - Work/school location choice</li> </ul>"},{"location":"summaries/#aggregation-options","title":"Aggregation Options","text":"<p>Simple count: <pre><code>group_by: \"trip_mode\"\ncount_name: \"trips\"\n</code></pre></p> <p>Multiple aggregations: <pre><code>group_by: [\"income_category_bin\", \"trip_mode\"]\naggregations:\n  trips: \"count\"\n  avg_distance: {\"column\": \"trip_distance_miles\", \"agg\": \"mean\"}\n  total_time: {\"column\": \"trip_time_minutes\", \"agg\": \"sum\"}\n</code></pre></p> <p>Share calculations: <pre><code>group_by: [\"tour_purpose\", \"tour_mode\"]\nshare_within: \"tour_purpose\"  # Each purpose sums to 100%\n</code></pre></p>"},{"location":"summaries/#binning-continuous-variables","title":"Binning Continuous Variables","text":"<pre><code>group_by: [\"income_category_bin\", \"trip_mode\"]\nbins:\n  income_category:\n    breaks: [0, 30000, 60000, 100000, 150000, 1000000000]\n    labels: ['&lt;30K', '30-60K', '60-100K', '100-150K', '150K+']\n</code></pre>"},{"location":"summaries/#output-files","title":"Output Files","text":"<p>Summaries are written to the specified output directory (default: <code>outputs/</code>):</p> <pre><code>outputs/\n\u251c\u2500\u2500 auto_ownership_regional.csv\n\u251c\u2500\u2500 tour_mode_choice.csv\n\u251c\u2500\u2500 trip_distance_distribution.csv\n\u251c\u2500\u2500 person_type_distribution.csv\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"summaries/#csv-format","title":"CSV Format","text":"<p>Example <code>tour_mode_choice.csv</code>:</p> <pre><code>tour_mode_name,tours,share\nDrive Alone,450000,0.425\nCarpool 2,180000,0.170\nWalk-Transit-Walk,95000,0.090\n...\n</code></pre>"},{"location":"summaries/#validation","title":"Validation","text":"<p>Summaries are automatically validated after generation. The validator checks for:</p> <ul> <li>Negative values in count/share fields</li> <li>Share totals not summing to ~1.0 within groups</li> <li>Zero or very small totals (&lt; 100)</li> <li>Statistical outliers using IQR method</li> <li>Logical consistency (invalid time periods, impossible household sizes, etc.)</li> </ul> <p>Results are displayed at the end of the run:</p> <pre><code>VALIDATION SUMMARY\n================================================================================\n  \u2713 25 summaries passed all checks\n  \u26a0 5 summaries have warnings (outliers expected in large datasets)\n\n[OK] Validation passed with 5 warnings\n</code></pre> <p>Use <code>--strict</code> mode to treat warnings as errors:</p> <pre><code>python summarize_model_run.py \"C:/path/to/ctramp_output\" --strict\n</code></pre>"},{"location":"summaries/#available-data-sources_1","title":"Available Data Sources","text":"<p>Check <code>data_model/ctramp_data_model.yaml</code> for complete list: - <code>households</code> - Household-level data - <code>persons</code> - Person-level data - <code>individual_tours</code> - Tour-level data - <code>individual_trips</code> - Trip-level data - <code>joint_tours</code> - Joint tour data - <code>workplace_school_location</code> - Work/school location choice</p>"},{"location":"summaries/#aggregation-examples","title":"Aggregation Examples","text":"<p>Simple count: <pre><code>auto_ownership_regional:\n  description: \"Regional auto ownership\"\n  data_source: \"households\"\n  group_by: \"num_vehicles\"\n  aggregations:\n    households:\n      column: \"household_id\"\n      agg: \"count\"\n</code></pre></p> <p>Multiple aggregations with mean/sum: <pre><code>trip_distance_by_mode:\n  description: \"Trip distance statistics by mode\"\n  data_source: \"individual_trips\"\n  group_by: \"trip_mode_name\"\n  aggregations:\n    trips:\n      column: \"trip_id\"\n      agg: \"count\"\n    mean_distance:\n      column: \"trip_distance_miles\"\n      agg: \"mean\"\n    total_distance:\n      column: \"trip_distance_miles\"\n      agg: \"sum\"\n</code></pre></p>"},{"location":"summaries/#data-model","title":"Data Model","text":"<p>The system uses <code>data_model/ctramp_data_model.yaml</code> which defines:</p> <ol> <li>File patterns - How to find CTRAMP output files</li> <li>Column mappings - Standardized column names</li> <li>Value labels - Mode 1 \u2192 \"SOV_GP\", etc.</li> <li>Aggregations - Group modes into categories</li> <li>Binning specs - Age groups, distance bins, etc.</li> <li>Summary definitions - All 30 summaries</li> </ol> <p>Example column mapping:</p> <pre><code>individual_trips:\n  file_pattern: \"indivTripData_{iteration}.csv\"\n  columns:\n    trip_mode: \"trip_mode\"\n    tour_purpose: \"tour_purpose\"\n    trip_distance_miles: \"trip_distance_miles\"\n    depart_period: \"depart_period\"\n</code></pre> <p>Example value mapping:</p> <pre><code>value_mappings:\n  trip_mode:\n    type: categorical\n    values:\n      1: \"SOV_GP\"\n      2: \"SOV_PAY\"\n      3: \"SR2_GP\"\n      # ... etc\n</code></pre>"},{"location":"summaries/#performance","title":"Performance","text":"<p>Typical runtime for a full model run (7.4M persons, 2.8M households):</p> <ul> <li>Loading data: ~2-3 minutes</li> <li>Labeling &amp; preprocessing: ~1-2 minutes  </li> <li>Generating summaries: ~3-5 minutes</li> <li>Validation: ~30 seconds</li> <li>Total: ~7-11 minutes</li> </ul> <p>Memory usage: ~2-4 GB</p>"},{"location":"summaries/#troubleshooting","title":"Troubleshooting","text":""},{"location":"summaries/#file-not-found-errors","title":"File not found errors","text":"<p>Check that your CTRAMP output directory contains the expected files: - <code>personData_3.csv</code> (or <code>personData_1.csv</code> depending on iteration) - <code>householdData_3.csv</code> - <code>indivTourData_3.csv</code> - <code>indivTripData_3.csv</code></p>"},{"location":"summaries/#column-not-found-errors","title":"Column not found errors","text":"<p>Check <code>data_model/ctramp_data_model.yaml</code> for correct column mappings. If your model uses different column names, update the YAML.</p>"},{"location":"summaries/#empty-summaries","title":"Empty summaries","text":"<p>Check validation output - this usually means: - Incorrect filter conditions - Missing required columns - Data type mismatches (text vs. numeric)</p>"},{"location":"summaries/#memory-errors","title":"Memory errors","text":"<p>For very large model runs (&gt; 10M persons), consider: - Processing on a machine with more RAM - Closing other applications - Running fewer summaries at once (comment out some in YAML)</p>"},{"location":"summaries/#comparing-multiple-runs","title":"Comparing Multiple Runs","text":"<p>To analyze multiple model runs:</p> <ol> <li> <p>Generate summaries for each run in separate output directories:    <pre><code>python summarize_model_run.py \"run1/ctramp_output\" --output \"outputs/run1\"\npython summarize_model_run.py \"run2/ctramp_output\" --output \"outputs/run2\"\n</code></pre></p> </li> <li> <p>Load and analyze the CSVs using Excel, Python (pandas), R, or other analysis tools</p> </li> </ol>"},{"location":"summaries/#next-steps","title":"Next Steps","text":"<ul> <li>See HOW_TO_SUMMARIZE.md for detailed user guide</li> <li>Check README.md for toolkit overview</li> <li>Review data_model/ctramp_data_model.yaml for all summary definitions</li> </ul>"},{"location":"summary-design-system/","title":"Summary Design System Plan","text":""},{"location":"summary-design-system/#overview","title":"Overview","text":"<p>This document outlines the design principles, architecture decisions, and implementation strategy for the tm2py-utils summary validation system. It serves as the foundational guide for combining core summaries with validation capabilities while maintaining flexibility and maintainability.</p>"},{"location":"summary-design-system/#core-design-principles","title":"Core Design Principles","text":""},{"location":"summary-design-system/#1-modularity-and-selective-execution","title":"1. Modularity and Selective Execution","text":"<p>Principle: Summaries should be independently executable and selectively runnable.</p> <ul> <li>Run standalone: Summaries can be executed against old model runs without rerunning the model</li> <li>Modular selection: Users can run only one summary or any combination they need</li> <li>Configuration-driven: Summary selection specified in <code>scenario_config</code> via <code>final_components</code> array</li> </ul> <p>Example: <pre><code># Run only essential summaries\nfinal_components = [\"post_processor\", \"network_summary\"]\n\n# Add core summaries\nfinal_components = [\"post_processor\", \"network_summary\", \"core_summary\"]\n\n# Run everything for major validation\nfinal_components = [\"post_processor\", \"network_summary\", \"rtp_summary\", \"calibration_summary\"]\n</code></pre></p> <p>Implementation Requirements: - Each summary type is self-contained - Command-line option to run against processed survey data - Can run across multiple historical model runs</p>"},{"location":"summary-design-system/#2-summary-tiering-system","title":"2. Summary Tiering System","text":"<p>Principle: Different summary types have different stability and execution requirements.</p> <p>Summary Tiers:</p> Tier Type Characteristics Configuration Always Run Core Summaries Stable, infrequently updated, essential validation Always executed, not configurable Configurable RTP Metrics Often changing, project-specific User-selectable via scenario_config Configurable TIP Metrics Project-specific transportation improvements User-selectable via scenario_config Configurable Calibration Summaries Detailed validation against observed data User-selectable via scenario_config <p>Guiding Questions: - What is configurable via scenario_config and what is always run? - Core summary should always run - how do we enforce this?</p>"},{"location":"summary-design-system/#3-data-model-separation","title":"3. Data Model Separation","text":"<p>Principle: Data models live in tm2py and are imported, not redefined in summary code.</p> <p>Architecture: - Data models reside in tm2py data models folder - Summary system pivots off known data model and acceptable values - No hardcoded values or schema definitions in summary code - Fixed schemas ensure consistency</p> <p>Data Models to Implement: - \u2705 CTRAMP data model - \u2705 CTRAMP extended data model - \u23f3 Population synthesizer data model (pending)</p> <p>Benefits: - Single source of truth for data structures - Easier to maintain and update schemas - Automatic validation against known models</p>"},{"location":"summary-design-system/#4-shared-utilities-and-code-reuse","title":"4. Shared Utilities and Code Reuse","text":"<p>Principle: Common operations are extracted into reusable utility functions.</p> <p>Implementation: - Create <code>summary_utils.py</code> (or similar) for shared functions - Common operations include:   - Binning continuous variables   - Calculating weighted averages   - Aggregating by geography or demographic groups   - Applying standard filters</p> <p>Benefits: - Reduced code duplication - Consistent behavior across summaries - Easier testing and debugging - Single place to fix bugs or add features</p>"},{"location":"summary-design-system/#5-multi-environment-compatibility","title":"5. Multi-Environment Compatibility","text":"<p>Principle: Code should work with the tm2py environment when possible, with graceful fallbacks.</p> <p>Strategy: - Primary: Write code compatible with tm2py environment so it can live in tm2py - Fallback: Create controller script that switches environments   - Runs the model in tm2py environment   - Switches to summary environment   - Runs summaries - Current: Code can remain in tm2py-utils during development</p> <p>Benefits: - Future integration with tm2py workflow - Flexibility during development - Clear migration path</p>"},{"location":"summary-design-system/#6-maintainability-and-accessibility","title":"6. Maintainability and Accessibility","text":"<p>Principle: Code should be easy to understand and maintain by a wide audience.</p> <p>Requirements: - Clear file organization - easy to find where to update code - Comprehensive inline documentation - Examples for adding new summaries - Consistent patterns across all summary types - Well-documented extension points</p> <p>Target Audience: - Transportation planners (light coding experience) - Data analysts (moderate Python skills) - Software developers (maintaining the system)</p>"},{"location":"summary-design-system/#7-flexible-data-sources","title":"7. Flexible Data Sources","text":"<p>Principle: Summaries should work with both model outputs and external data sources.</p> <p>Data Source Types: - Model Outputs: CTRAMP household/person/tour/trip data - Survey Data: Household travel surveys formatted to match model output structure - External Data: ACS, CTPP - match format of system outputs for calibration/validation</p> <p>Implementation: - Command-line option to specify data source type - Adapters to normalize different input formats - Common output format regardless of input source</p>"},{"location":"summary-design-system/#8-output-standardization","title":"8. Output Standardization","text":"<p>Principle: All outputs follow consistent format for downstream integration.</p> <p>Standards: - Format: CSV tables labeled with model run identifier - Combinability: CSV tables can be combined across model runs - Visualization Ready: Outputs designed for external visualization systems (Tableau, etc.) - Metadata: Include run information, timestamps, configuration used</p> <p>File Naming: <code>{summary_type}_{model_run_id}_{timestamp}.csv</code></p>"},{"location":"summary-design-system/#system-architecture-idea-needs-more-thinking-before-we-implement","title":"System Architecture Idea Needs More Thinking Before we implement","text":""},{"location":"summary-design-system/#component-organization","title":"Component Organization","text":"<pre><code>tm2py (upstream dependency)\n\u251c\u2500\u2500 data_models/\n\u2502   \u251c\u2500\u2500 ctramp_data_model.py\n\u2502   \u251c\u2500\u2500 ctramp_extended_data_model.py\n\u2502   \u2514\u2500\u2500 population_synthesizer_data_model.py\n\u2514\u2500\u2500 (other tm2py components)\n\ntm2py-utils (summary system)\n\u251c\u2500\u2500 summary/\n\u2502   \u251c\u2500\u2500 core_summaries/        # Always-run summaries\n\u2502   \u251c\u2500\u2500 validation/             # Validation code being developed\n\u2502   \u251c\u2500\u2500 summary_utils.py        # Shared utility functions\n\u2502   \u251c\u2500\u2500 data_readers.py         # Import and validation\n\u2502   \u251c\u2500\u2500 summary_base.py         # Base classes\n\u2502   \u2514\u2500\u2500 output_writers.py       # Standardized output\n\u2514\u2500\u2500 config/\n    \u2514\u2500\u2500 {scenario}/scenario_config.toml\n</code></pre>"},{"location":"summary-design-system/#core-components","title":"Core Components","text":""},{"location":"summary-design-system/#1-data-readers","title":"1. Data Readers","text":"<ul> <li>Purpose: Load and validate model outputs and external data</li> <li>Design: Abstract base class with implementations for different sources</li> <li>Key Features: </li> <li>Automatic iteration detection</li> <li>Schema validation against tm2py data models</li> <li>Support for CTRAMP outputs, survey data, ACS/CTPP</li> <li>Error handling with clear messages</li> </ul>"},{"location":"summary-design-system/#2-summary-utilities-summary_utilspy","title":"2. Summary Utilities (<code>summary_utils.py</code>)","text":"<ul> <li>Purpose: Shared functions used across all summary types</li> <li>Functions:</li> <li>Bin continuous variables (distance, time, etc.)</li> <li>Calculate weighted averages</li> <li>Aggregate by geography/demographics</li> <li>Apply standard filters</li> <li>Format output tables</li> <li>Design: Pure functions, well-tested, documented</li> </ul>"},{"location":"summary-design-system/#3-summary-generators","title":"3. Summary Generators","text":"<ul> <li>Purpose: Transform raw data into validation summaries</li> <li>Design: </li> <li>Base class defining standard interface</li> <li>Plugin-based registry for different summary types</li> <li>Tier-based execution (always-run vs. configurable)</li> <li>Types:</li> <li>Core Summaries (always executed)</li> <li>RTP Metrics (configurable)</li> <li>TIP Metrics (configurable)</li> <li>Calibration Summaries (configurable)</li> </ul>"},{"location":"summary-design-system/#4-configuration-system","title":"4. Configuration System","text":"<ul> <li>Purpose: Control which summaries run and with what parameters</li> <li>Design: TOML-based with scenario-specific overrides</li> <li>Key Elements:</li> <li><code>final_components</code>: Array of summaries to execute</li> <li>Summary-specific parameters</li> <li>Data source specifications</li> <li>Output locations</li> </ul>"},{"location":"summary-design-system/#5-output-writers","title":"5. Output Writers","text":"<ul> <li>Purpose: Standardize output format across all summaries</li> <li>Design: Consistent CSV format with metadata</li> <li>Features: </li> <li>Model run labeling</li> <li>Timestamp inclusion</li> <li>Ready for cross-run comparison</li> <li>Visualization system compatibility</li> </ul>"},{"location":"summary-design-system/#data-flow","title":"Data Flow","text":"<p>``` \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  Data Sources                                \u2502 \u2502  \u251c\u2500\u2500 CTRAMP Outputs                         \u2502 \u2502  \u251c\u2500\u2500 Survey Data                            \u2502 \u2502  \u2514\u2500\u2500 External Data (ACS, CTPP)              \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2193            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502 Data Readers  \u2502 \u2190 tm2py Data Models            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2193            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502 Data Validation\u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2193       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502  Summary Selection     \u2502 \u2190 scenario_config.toml       \u2502  (final_components)    \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2193     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502  Always-Run Tier     \u2502     \u2502  (Core Summaries)    \u2502</p>"},{"location":"summary-design-system/#open-questions","title":"Open Questions","text":"<p>These questions need resolution to finalize the design:</p>"},{"location":"summary-design-system/#integration-strategy","title":"Integration Strategy","text":"<ul> <li>Q: How can we combine the <code>core_summaries</code> code and the <code>validation</code> code we started?</li> <li>Consideration: Lisa says this is a trivial problem - what's the simplest merge strategy?</li> <li>Next Step: Map existing functionality and identify overlaps</li> </ul>"},{"location":"summary-design-system/#configuration-boundaries","title":"Configuration Boundaries","text":"<ul> <li>Q: What is configurable via scenario_config and what is always run?</li> <li>Current Thinking: Core summaries always run, others are configurable</li> <li>Need to Define: Exact list of core vs. configurable summaries</li> </ul>"},{"location":"summary-design-system/#enriched-output","title":"Enriched Output","text":"<ul> <li>Q: Should CTRAMP write out parking costs and skims as enriched outputs?</li> <li>Consideration: Makes data available for special analyses</li> <li>Trade-off: Larger output files vs. easier analysis</li> <li>Next Step: Define enriched output schema and opt-in mechanism</li> </ul>"},{"location":"summary-design-system/#visualization-integration","title":"Visualization Integration","text":"<ul> <li>Q: How do we build the comparison/visualization system?</li> <li>Current Thinking: Tableau as preferred platform</li> <li>Ownership: Melody to take lead on Tableau integration</li> <li>Requirement: Balance automation with transparency</li> <li>Challenge: Avoid opaque pipeline, maintain auditability</li> </ul>"},{"location":"summary-design-system/#population-synthesizer-integration","title":"Population Synthesizer Integration","text":"<ul> <li>Q: How do we add data models from the population synthesizer?</li> <li>Status: Needs implementation</li> <li>Location: Should live in tm2py data models folder</li> <li>Next Step: Define PopSyn output schema</li> </ul>"},{"location":"summary-design-system/#environment-management","title":"Environment Management","text":"<ul> <li>Q: Can we make everything work in tm2py environment?</li> <li>Fallback: Controller script that switches environments</li> <li>Current: Code lives in tm2py-utils</li> <li>Decision Needed: Timeline for tm2py integration</li> </ul>"},{"location":"summary-design-system/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"summary-design-system/#phase-1-foundation-current","title":"Phase 1: Foundation (Current)","text":"<ul> <li>\u2705 Document design principles</li> <li>\u23f3 Merge core_summaries and validation code</li> <li>\u23f3 Create <code>summary_utils.py</code> with shared functions</li> <li>\u23f3 Establish summary tier system</li> <li>\u23f3 Import tm2py data models</li> </ul>"},{"location":"summary-design-system/#phase-2-core-functionality","title":"Phase 2: Core Functionality","text":"<ul> <li>\u23f3 Implement always-run core summaries</li> <li>\u23f3 Build configurable summary selection</li> <li>\u23f3 Add command-line options for different data sources</li> <li>\u23f3 Standardize CSV output format</li> <li>\u23f3 Create scenario_config templates</li> </ul>"},{"location":"summary-design-system/#phase-3-extended-capabilities","title":"Phase 3: Extended Capabilities","text":"<ul> <li>\u23f3 Support for survey data inputs</li> <li>\u23f3 ACS/CTPP format matching</li> <li>\u23f3 Enriched output options</li> <li>\u23f3 Multi-run comparison utilities</li> <li>\u23f3 Population synthesizer integration</li> </ul>"},{"location":"summary-design-system/#phase-4-integration-deployment","title":"Phase 4: Integration &amp; Deployment","text":"<ul> <li>\u23f3 Tableau visualization templates</li> <li>\u23f3 Controller script for environment switching</li> <li>\u23f3 Migration to tm2py environment</li> <li>\u23f3 Full documentation and examples</li> <li>\u23f3 User training and rollout</li> </ul>"},{"location":"summary-design-system/#next-steps","title":"Next Steps","text":""},{"location":"summary-design-system/#immediate-actions","title":"Immediate Actions","text":"<ol> <li>Code Consolidation: Merge core_summaries and validation code paths</li> <li>Shared Utilities: Extract common functions to <code>summary_utils.py</code></li> <li>Data Model Import: Set up imports from tm2py data models</li> <li>Tier Definition: Finalize which summaries are always-run vs. configurable</li> </ol>"},{"location":"summary-design-system/#short-term-goals","title":"Short-Term Goals","text":"<ol> <li>Configuration System: Implement <code>final_components</code> array processing</li> <li>Output Standardization: Ensure all summaries produce compatible CSV format</li> <li>Documentation: Create examples for adding new summaries</li> <li>Testing: Build test suite for shared utilities</li> </ol>"},{"location":"summary-design-system/#medium-term-goals","title":"Medium-Term Goals","text":"<ol> <li>Survey Data Support: Implement adapters for household survey data</li> <li>Visualization Prototype: Work with Melody on Tableau integration</li> <li>Enriched Outputs: Define and implement optional enriched output schema</li> <li>PopSyn Integration: Add population synthesizer data model support</li> </ol>"},{"location":"summary-design-system/#version-history","title":"Version History","text":"Version Date Major Changes 0.2 Dec 2025 Reorganized with principles from team discussion, added open questions and roadmap 0.1 Dec 2025 Initial design system documentation"},{"location":"summary-design-system/#references","title":"References","text":"<ul> <li>Generate Summaries Guide</li> <li>Custom Summaries</li> <li>Configuration</li> <li>Data Model</li> <li>How to Summarize</li> <li>Summary output files: <code>{summary_name}_{scenario_id}.csv</code></li> <li>Configuration files: <code>{purpose}_config.toml</code></li> <li>Example: <code>auto_ownership_2015_base.csv</code>, <code>scenario_config.toml</code></li> </ul>"},{"location":"summary-design-system/#column-naming","title":"Column Naming","text":"<ul> <li>Lowercase with underscores: <code>tour_mode</code>, <code>trip_distance</code></li> <li>Categorical suffixes: <code>_cat</code> for categories, <code>_grp</code> for groups</li> <li>Count columns: <code>n_*</code> prefix (e.g., <code>n_tours</code>, <code>n_trips</code>)</li> <li>Share columns: <code>share_*</code> prefix or <code>*_pct</code> suffix</li> </ul>"},{"location":"summary-design-system/#code-naming","title":"Code Naming","text":"<ul> <li>Classes: PascalCase (e.g., <code>TourModeSummary</code>)</li> <li>Functions: snake_case (e.g., <code>calculate_mode_share</code>)</li> <li>Constants: UPPER_SNAKE_CASE (e.g., <code>DEFAULT_ITERATION</code>)</li> </ul>"},{"location":"summary-design-system/#extension-points","title":"Extension Points","text":""},{"location":"summary-design-system/#adding-new-summaries","title":"Adding New Summaries","text":"<ol> <li>Create summary class inheriting from <code>BaseSummary</code></li> <li>Implement required methods: <code>load_data()</code>, <code>calculate()</code>, <code>format_output()</code></li> <li>Register in summary registry</li> <li>Add configuration template</li> <li>Update documentation</li> </ol>"},{"location":"summary-design-system/#custom-aggregations","title":"Custom Aggregations","text":"<ol> <li>Define aggregation function with standard signature</li> <li>Add to aggregation registry</li> <li>Reference in configuration files</li> <li>Document in custom summaries guide</li> </ol>"},{"location":"summary-design-system/#new-data-sources","title":"New Data Sources","text":"<ol> <li>Create reader class inheriting from <code>BaseDataReader</code></li> <li>Implement schema validation</li> <li>Add to data source registry</li> <li>Update data model documentation</li> </ol>"},{"location":"summary-design-system/#quality-standards","title":"Quality Standards","text":""},{"location":"summary-design-system/#code-quality","title":"Code Quality","text":"<ul> <li>Type hints for all function signatures</li> <li>Docstrings following NumPy style</li> <li>Unit test coverage &gt; 80%</li> <li>Linting with flake8/black</li> </ul>"},{"location":"summary-design-system/#documentation-quality","title":"Documentation Quality","text":"<ul> <li>Every summary has usage examples</li> <li>Configuration options fully documented</li> <li>Troubleshooting guide for common errors</li> <li>Changelog maintained for breaking changes</li> </ul>"},{"location":"summary-design-system/#performance-benchmarks","title":"Performance Benchmarks","text":"<ul> <li>Process 1M household records in &lt; 2 minutes</li> <li>Memory usage &lt; 4GB for typical regional model</li> <li>Individual summaries complete in &lt; 30 seconds</li> </ul>"},{"location":"summary-design-system/#future-directions","title":"Future Directions","text":""},{"location":"summary-design-system/#near-term-enhancements","title":"Near-Term Enhancements","text":"<ul> <li>Parallel processing for multiple summaries</li> <li>Interactive visualization dashboard</li> <li>Automated comparison with observed data</li> <li>Summary templates for common validation tasks</li> </ul>"},{"location":"summary-design-system/#long-term-vision","title":"Long-Term Vision","text":"<ul> <li>Real-time validation during model runs</li> <li>Machine learning-based anomaly detection</li> <li>Integration with calibration workflows</li> <li>Web-based validation report generator</li> </ul>"},{"location":"summary-design-system/#version-history_1","title":"Version History","text":"Version Date Major Changes 0.1 TBD Initial design system documentation"},{"location":"summary-design-system/#references_1","title":"References","text":"<ul> <li>Generate Summaries Guide</li> <li>Custom Summaries</li> <li>Configuration</li> <li>Data Model</li> </ul>"},{"location":"user-guide/","title":"How to Summarize a Model Run","text":"<p>This guide explains how to generate validation summaries from a CTRAMP model run output directory.</p>"},{"location":"user-guide/#quick-start","title":"Quick Start","text":"<p>Run one command pointing to your CTRAMP output directory:</p> <pre><code>python summarize_model_run.py \"C:/model_runs/2015_base/ctramp_output\"\n</code></pre> <p>This creates a <code>summaries/</code> directory with CSV files for each summary (auto ownership, tour mode, trip distance, etc.).</p>"},{"location":"user-guide/#what-you-need","title":"What You Need","text":"<ol> <li>CTRAMP Output Directory - Contains CSV files from your model run:</li> <li><code>householdData_1.csv</code> (or <code>_2.csv</code>, <code>_3.csv</code> for later iterations)</li> <li><code>personData_1.csv</code></li> <li><code>indivTourData_1.csv</code></li> <li> <p><code>indivTripData_1.csv</code></p> </li> <li> <p>Python Environment with pandas and PyYAML installed</p> </li> </ol> <p>The tool automatically finds the highest iteration number if you have multiple (<code>_1.csv</code>, <code>_2.csv</code>, <code>_3.csv</code>).</p>"},{"location":"user-guide/#command-line-options","title":"Command-Line Options","text":""},{"location":"user-guide/#basic-usage","title":"Basic Usage","text":"<pre><code>python summarize_model_run.py &lt;ctramp_dir&gt;\n</code></pre> <p>Example: <pre><code>python summarize_model_run.py \"A:/2023-tm22-dev-version-05/ctramp_output\"\n</code></pre></p>"},{"location":"user-guide/#specify-output-directory","title":"Specify Output Directory","text":"<pre><code>python summarize_model_run.py &lt;ctramp_dir&gt; --output &lt;output_dir&gt;\n</code></pre> <p>Example: <pre><code>python summarize_model_run.py \"A:/2023-tm22-dev-version-05/ctramp_output\" --output \"C:/summaries/2023_v05\"\n</code></pre></p>"},{"location":"user-guide/#what-happens-when-you-run-it","title":"What Happens When You Run It","text":"<p>The tool executes a simple 6-step pipeline with transparent logging:</p>"},{"location":"user-guide/#step-1-load-data-model-configuration","title":"Step 1: Load Data Model Configuration","text":"<p>Reads <code>data_model/ctramp_data_model.yaml</code> which defines: - File patterns to find (e.g., <code>personData_{iteration}.csv</code>) - Column name mappings (e.g., <code>hh_id</code> \u2192 <code>household_id</code>) - Value labels (e.g., mode 1 \u2192 \"SOV_GP\") - Binning specs (e.g., age \u2192 age groups) - Summary definitions (what to calculate)</p>"},{"location":"user-guide/#step-2-load-ctramp-output-files","title":"Step 2: Load CTRAMP Output Files","text":"<ul> <li>Finds files matching patterns in your directory</li> <li>Uses highest iteration number if multiple exist</li> <li>Loads CSVs into memory</li> <li>Renames columns to standardized names</li> </ul> <p>Example output: <pre><code>Loading households...\n  File: householdData_1.csv\n  Rows: 2,611,046\n  Columns: 15\n  \u2713 Loaded and standardized\n</code></pre></p>"},{"location":"user-guide/#step-3-apply-value-labels","title":"Step 3: Apply Value Labels","text":"<p>Creates human-readable columns (e.g., <code>person_type_name</code> from <code>person_type</code> codes): - 1 \u2192 \"Full-time worker\" - 2 \u2192 \"Part-time worker\" - etc.</p> <p>Example output: <pre><code>persons:\n  \u2713 Labeled 'person_type' \u2192 'person_type_name' (8 values)\n  \u2713 Labeled 'gender' \u2192 'gender_name' (2 values)\n</code></pre></p>"},{"location":"user-guide/#step-4-create-aggregated-categories","title":"Step 4: Create Aggregated Categories","text":"<p>Simplifies detailed categories into broader groups: - 17 transportation modes \u2192 5 major categories (Auto-SOV, Auto-Shared, Transit, Active, TNC/Taxi, School Bus) - Detailed household sizes \u2192 ACS-compatible categories (1, 2, 3, 4+)</p> <p>Example output: <pre><code>individual_tours:\n  \u2713 Aggregated 'tour_mode' \u2192 'tour_mode_agg' (5 categories)\n</code></pre></p>"},{"location":"user-guide/#step-5-create-binned-variables","title":"Step 5: Create Binned Variables","text":"<p>Converts continuous variables to categorical bins: - Age \u2192 age groups (0-4, 5-17, 18-24, 25-34, ...) - Distance \u2192 distance bands (0-5mi, 5-10mi, 10-20mi, ...) - Income \u2192 income categories (&lt;30K, 30-60K, 60-100K, ...)</p> <p>Example output: <pre><code>persons:\n  \u2713 Binned 'age' \u2192 'age_bin' (8 bins)\nindividual_tours:\n  \u2713 Binned 'tour_distance' \u2192 'tour_distance_bin' (5 bins)\n</code></pre></p>"},{"location":"user-guide/#step-6-generate-summaries","title":"Step 6: Generate Summaries","text":"<p>Creates weighted frequency tables and saves as CSV files.</p> <p>Example output: <pre><code>[1] auto_ownership_regional\n  Source: households (2,611,046 rows)\n  Result: 7 rows \u00d7 2 columns\n  \u2713 Saved: auto_ownership_regional.csv\n\n[2] tour_mode_distribution\n  Source: individual_tours (11,234,982 rows)\n  Result: 17 rows \u00d7 2 columns\n  \u2713 Saved: tour_mode_distribution.csv\n\nGenerated 23 summaries\n</code></pre></p>"},{"location":"user-guide/#output-files","title":"Output Files","text":"<p>Each summary is saved as a separate CSV file in the output directory.</p> <p>Example outputs:</p> <p>auto_ownership_regional.csv: <pre><code>num_vehicles,households\n0,423156.8\n1,892341.2\n2,945623.1\n3,289432.7\n4,52108.4\n5,7284.2\n6,1099.6\n</code></pre></p> <p>tour_mode_by_purpose.csv: <pre><code>tour_purpose,tour_mode_name,tours,share\nWork,SOV_GP - Single Occupant Vehicle (General Purpose),1823441.5,0.524\nWork,SR2_GP - Shared Ride 2 (General Purpose),456782.3,0.131\nWork,WLK_TRN - Walk to Transit,328901.2,0.094\n...\n</code></pre></p>"},{"location":"user-guide/#what-summaries-are-generated","title":"What Summaries Are Generated","text":"<p>The tool generates 23 standard summaries organized by category:</p>"},{"location":"user-guide/#household-summaries","title":"Household Summaries","text":"<ul> <li><code>auto_ownership_regional.csv</code> - Vehicle ownership distribution</li> <li><code>auto_ownership_by_income.csv</code> - Vehicles by income category</li> <li><code>auto_ownership_by_household_size.csv</code> - Vehicles by household size</li> <li><code>household_size_distribution.csv</code> - Household size distribution</li> <li><code>worker_distribution.csv</code> - Workers per household</li> </ul>"},{"location":"user-guide/#person-summaries","title":"Person Summaries","text":"<ul> <li><code>person_type_distribution.csv</code> - Person type distribution</li> <li><code>age_distribution.csv</code> - Age distribution (binned)</li> <li><code>cdap_by_person_type.csv</code> - Daily activity pattern by person type</li> <li><code>cdap_regional.csv</code> - Regional daily activity patterns</li> </ul>"},{"location":"user-guide/#tour-summaries","title":"Tour Summaries","text":"<ul> <li><code>tour_frequency_by_purpose.csv</code> - Tours by purpose</li> <li><code>tour_mode_distribution.csv</code> - Tour mode (all 17 modes)</li> <li><code>tour_mode_aggregated.csv</code> - Tour mode (5 major categories)</li> <li><code>tour_mode_by_purpose.csv</code> - Mode \u00d7 Purpose cross-tab</li> <li><code>tour_start_time.csv</code> - Departure time distribution</li> <li><code>tour_end_time.csv</code> - Arrival time distribution</li> <li><code>tour_distance_distribution.csv</code> - Distance distribution (binned)</li> </ul>"},{"location":"user-guide/#trip-summaries","title":"Trip Summaries","text":"<ul> <li><code>trip_purpose_distribution.csv</code> - Trip destination purposes</li> <li><code>trip_mode_distribution.csv</code> - Trip mode (all 17 modes)</li> <li><code>trip_mode_aggregated.csv</code> - Trip mode (5 major categories)</li> <li><code>trip_mode_by_purpose.csv</code> - Mode \u00d7 Purpose cross-tab</li> <li><code>trip_distance_distribution.csv</code> - Distance distribution (binned)</li> </ul>"},{"location":"user-guide/#adding-new-summaries","title":"Adding New Summaries","text":"<p>You don't need to write Python code to add summaries! Just edit the YAML configuration.</p>"},{"location":"user-guide/#example-add-a-new-summary-for-tours-by-person-type","title":"Example: Add a new summary for tours by person type","text":"<p>Edit <code>data_model/ctramp_data_model.yaml</code> and add to the <code>summaries:</code> section:</p> <pre><code>summaries:\n  # ... existing summaries ...\n\n  tours_by_person_type:\n    description: \"Number of tours by person type\"\n    data_source: \"individual_tours\"\n    group_by: \"person_type_name\"\n    weight_field: \"sample_rate\"\n    count_name: \"tours\"\n</code></pre> <p>That's it! Next time you run the tool, it will generate <code>tours_by_person_type.csv</code>.</p>"},{"location":"user-guide/#example-add-filtered-summary-work-tours-only","title":"Example: Add filtered summary (work tours only)","text":"<pre><code>  work_tour_modes:\n    description: \"Mode choice for work tours only\"\n    data_source: \"individual_tours\"\n    filter: \"tour_purpose == 'Work'\"\n    group_by: \"tour_mode_name\"\n    weight_field: \"sample_rate\"\n    count_name: \"tours\"\n</code></pre>"},{"location":"user-guide/#example-calculate-shares-within-categories","title":"Example: Calculate shares within categories","text":"<pre><code>  mode_by_income:\n    description: \"Tour mode choice by household income (with shares)\"\n    data_source: \"individual_tours\"\n    group_by: [\"income_category_bin\", \"tour_mode_agg\"]\n    weight_field: \"sample_rate\"\n    count_name: \"tours\"\n    share_within: \"income_category_bin\"  # This adds a 'share' column\n</code></pre>"},{"location":"user-guide/#summary-configuration-reference","title":"Summary Configuration Reference","text":"<p>Each summary definition supports these fields:</p> Field Required Description Example <code>description</code> No Human-readable description <code>\"Vehicle ownership by income\"</code> <code>data_source</code> Yes Which table to use <code>\"households\"</code>, <code>\"persons\"</code>, <code>\"individual_tours\"</code>, <code>\"individual_trips\"</code> <code>group_by</code> Yes Column(s) to group by <code>\"num_vehicles\"</code> or <code>[\"income_category\", \"num_vehicles\"]</code> <code>weight_field</code> No Column with sampling weights <code>\"sample_rate\"</code> <code>count_name</code> No Name for count column in output <code>\"households\"</code>, <code>\"tours\"</code>, <code>\"trips\"</code> (default: <code>\"count\"</code>) <code>share_within</code> No Calculate shares within these groups <code>\"income_category\"</code> or <code>[\"county\", \"income\"]</code> <code>filter</code> No Pandas query to filter data <code>\"tour_purpose == 'Work'\"</code> or <code>\"age &gt;= 18\"</code>"},{"location":"user-guide/#understanding-the-data-flow","title":"Understanding the Data Flow","text":"<pre><code>CTRAMP CSV Files\n       \u2193\n   Load Data (Step 2)\n       \u2193\nhouseholdData_1.csv  \u2192  households dataframe (standardized columns)\npersonData_1.csv     \u2192  persons dataframe\nindivTourData_1.csv  \u2192  individual_tours dataframe\nindivTripData_1.csv  \u2192  individual_trips dataframe\n       \u2193\n   Apply Value Labels (Step 3)\n       \u2193\nperson_type: 1,2,3... \u2192 person_type_name: \"Full-time worker\", \"Part-time worker\", ...\ntour_mode: 1,2,3...   \u2192 tour_mode_name: \"SOV_GP\", \"SR2_GP\", \"WALK\", ...\n       \u2193\n   Apply Aggregations (Step 4)\n       \u2193\ntour_mode_name: 17 categories \u2192 tour_mode_agg: \"Auto-SOV\", \"Auto-Shared\", \"Transit\", ...\nnum_persons: 1,2,3,4,5,6...   \u2192 num_persons_agg: \"1\", \"2\", \"3\", \"4+\"\n       \u2193\n   Apply Binning (Step 5)\n       \u2193\nage: 0-100          \u2192 age_bin: \"0-4\", \"5-17\", \"18-24\", \"25-34\", ...\ntour_distance: 0-50 \u2192 tour_distance_bin: \"0-5mi\", \"5-10mi\", \"10-20mi\", ...\n       \u2193\n   Generate Summaries (Step 6)\n       \u2193\nFor each summary definition:\n  - Filter data if specified\n  - Group by specified columns\n  - Apply sample_rate weights\n  - Calculate shares if requested\n  - Save to CSV\n       \u2193\nIndividual CSV Files (one per summary)\n</code></pre>"},{"location":"user-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/#file-not-found-errors","title":"File Not Found Errors","text":"<p>Problem: <code>File not found matching pattern: personData_{iteration}.csv</code></p> <p>Solution:  - Check that your CTRAMP directory path is correct - Verify files exist: <code>ls &lt;ctramp_dir&gt;/*.csv</code> - Check file naming - should be <code>personData_1.csv</code> (or <code>_2.csv</code>, <code>_3.csv</code>)</p>"},{"location":"user-guide/#column-not-found-errors","title":"Column Not Found Errors","text":"<p>Problem: <code>KeyError: 'tour_mode_agg'</code></p> <p>Solution: This column is created in Step 4 (aggregations). Make sure: - The data model has the aggregation defined - The source column (<code>tour_mode</code>) exists in the data - The aggregation mapping is valid</p>"},{"location":"user-guide/#empty-output","title":"Empty Output","text":"<p>Problem: Summary CSV files are created but have no data</p> <p>Solution: - Check if filter is too restrictive (<code>filter: \"tour_purpose == 'InvalidValue'\"</code>) - Verify group_by columns exist in the data - Check if weight_field exists (if specified)</p>"},{"location":"user-guide/#memory-errors","title":"Memory Errors","text":"<p>Problem: <code>MemoryError</code> when loading large files</p> <p>Solution: - Process data in chunks (would require code modification) - Use a machine with more RAM - Sample the data first for testing</p>"},{"location":"user-guide/#for-developers","title":"For Developers","text":"<p>If you need to modify the tool's behavior, see <code>summarize_model_run.py</code>.</p> <p>The code is structured as simple functions in a clear sequence: 1. <code>load_data_model()</code> - Read YAML config 2. <code>load_ctramp_data()</code> - Load and standardize CSV files 3. <code>apply_value_labels()</code> - Create _name columns 4. <code>apply_aggregations()</code> - Create _agg columns 5. <code>apply_bins()</code> - Create _bin columns 6. <code>generate_summary()</code> - Group, weight, calculate shares 7. <code>generate_all_summaries()</code> - Loop through all summary configs</p> <p>Total code: ~350 lines with extensive comments and logging.</p>"},{"location":"user-guide/#next-steps","title":"Next Steps","text":"<p>After generating summaries:</p> <ol> <li>Inspect the CSVs - Open in Excel or pandas to verify results</li> <li>Compare across scenarios - Use simple pandas scripts to compare CSVs from different runs</li> <li>Visualize - Create plots, dashboards, or reports from the summary CSVs</li> <li>Validate - Compare to observed data (ACS, surveys, etc.)</li> </ol> <p>The summaries are simple CSV files - use them however you like!</p>"},{"location":"archived/","title":"Archived Documentation","text":"<p>This folder contains documentation for the old validation system that supported multi-dataset comparisons and dashboard deployment.</p> <p>Archived files: - <code>dashboard.md</code> - Streamlit dashboard guide - <code>deploy-dashboard.md</code> - Dashboard deployment instructions - <code>validation-system.md</code> - Old validation system overview - <code>code-flow.md</code> - Technical documentation of old system - <code>validation-development.md</code> - Development guide for old system</p> <p>Current system: The current system is simpler and focused on generating summaries from a single CTRAMP model run at a time. See the main documentation for the current workflow:</p> <ul> <li>Generate Summaries - How to run the summarizer</li> <li>Summaries Reference - List of all 30 summaries</li> <li>Configuration - YAML data model</li> </ul> <p>These archived files are kept for reference but are no longer maintained.</p>"},{"location":"archived/code-flow/","title":"Code Flow and Execution Guide","text":"<p>Detailed technical documentation of how the validation system code executes from configuration files to final dashboard outputs.</p>"},{"location":"archived/code-flow/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Entry Points</li> <li>Execution Flow</li> <li>Key Classes and Their Roles</li> <li>Data Processing Pipeline</li> <li>Configuration Loading</li> <li>Code Module Map</li> </ol>"},{"location":"archived/code-flow/#system-entry-points","title":"System Entry Points","text":""},{"location":"archived/code-flow/#primary-entry-point-run_allpy","title":"Primary Entry Point: <code>run_all.py</code>","text":"<p>Location: <code>tm2py_utils/summary/validation/summaries/run_all.py</code></p> <p>Purpose: Main orchestrator that reads configuration, loads data, generates all summaries, and writes combined CSVs.</p> <p>Usage: <pre><code># Run all summaries defined in validation_config.yaml\npython -m tm2py_utils.summary.validation.summaries.run_all \\\n    --config validation_config.yaml\n\n# Or with explicit paths\npython -m tm2py_utils.summary.validation.summaries.run_all \\\n    --input-dirs A:/model-run-1 A:/model-run-2 \\\n    --output-dir outputs/\n</code></pre></p> <p>Command-line Arguments: - <code>--config PATH</code>: Path to YAML configuration file (recommended) - <code>--input-dirs DIR [DIR ...]</code>: One or more CTRAMP output directories - <code>--output-dir PATH</code>: Where to write summary CSVs (default: <code>outputs/</code>) - <code>--summaries NAME [NAME ...]</code>: Specific summaries to run (default: all) - <code>--validate-only</code>: Validate configuration without running summaries</p>"},{"location":"archived/code-flow/#secondary-entry-point-run_and_deploy_dashboardpy","title":"Secondary Entry Point: <code>run_and_deploy_dashboard.py</code>","text":"<p>Location: <code>tm2py_utils/summary/validation/run_and_deploy_dashboard.py</code></p> <p>Purpose: Convenience wrapper that runs summaries AND launches dashboard.</p> <p>Usage: <pre><code>python run_and_deploy_dashboard.py --config validation_config.yaml --launch-dashboard\n</code></pre></p> <p>What it does: 1. Calls <code>run_all.py</code> to generate summaries 2. Optionally launches Streamlit dashboard on completion</p>"},{"location":"archived/code-flow/#dashboard-entry-point-streamlit_apppy","title":"Dashboard Entry Point: <code>streamlit_app.py</code>","text":"<p>Location: <code>tm2py_utils/summary/validation/streamlit_app.py</code></p> <p>Purpose: Streamlit web application for interactive visualization.</p> <p>Usage: <pre><code>streamlit run streamlit_app.py\n</code></pre></p>"},{"location":"archived/code-flow/#execution-flow","title":"Execution Flow","text":""},{"location":"archived/code-flow/#visual-code-flow-diagram","title":"Visual Code Flow Diagram","text":"<pre><code>USER COMMAND\n     \u2502\n     \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502                                                             \u2502\n     v                                                             v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 python -m ...       \u2502                              \u2502 streamlit run       \u2502\n\u2502 run_all.py          \u2502                              \u2502 streamlit_app.py    \u2502\n\u2502 --config X.yaml     \u2502                              \u2502                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                                                             \u2502\n     \u2502 main()                                                      \u2502 main()\n     v                                                             v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 STEP 1: Parse Arguments &amp; Load Config                                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 argparse.ArgumentParser()                                       \u2502   \u2502\n\u2502 \u2502   - Read --config path                                          \u2502   \u2502\n\u2502 \u2502   - Read --input-dirs (optional)                                \u2502   \u2502\n\u2502 \u2502   - Read --output-dir (optional)                                \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                              \u2193                                          \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 load_config(config_path)                                        \u2502   \u2502\n\u2502 \u2502   - yaml.safe_load(validation_config.yaml)                      \u2502   \u2502\n\u2502 \u2502   - ValidationConfig.parse_obj() \u2192 Pydantic validation          \u2502   \u2502\n\u2502 \u2502   - Returns: config object with .datasets, .summaries           \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 STEP 2: Initialize Summary Generator                                   \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 generator = SummaryGenerator(config)                            \u2502   \u2502\n\u2502 \u2502   - self.config = config                                        \u2502   \u2502\n\u2502 \u2502   - self.data_model = load_data_model()  \u2190 Load summary YAMLs   \u2502   \u2502\n\u2502 \u2502   - self.datasets = {}  \u2190 Empty dict for loaded data            \u2502   \u2502\n\u2502 \u2502   - Create output directories                                   \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 STEP 3: Load All Datasets into Memory                                  \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 generator.load_datasets()                                       \u2502   \u2502\n\u2502 \u2502                                                                 \u2502   \u2502\n\u2502 \u2502   FOR EACH dataset in config.datasets:                         \u2502   \u2502\n\u2502 \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502 \u2502   \u2502 dataset_name = \"TM22_2015\"                            \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 directory = \"A:/2015.../ctramp_output\"                \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                                                       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 Read CSVs:                                            \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   hh_df = pd.read_csv(\"householdData_1.csv\")         \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   per_df = pd.read_csv(\"personData_1.csv\")           \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   tour_df = pd.read_csv(\"indivTourData_1.csv\")       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   trip_df = pd.read_csv(\"indivTripData_1.csv\")       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                                                       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 Add dataset column:                                   \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   hh_df['dataset'] = \"TM22_2015\"                     \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   per_df['dataset'] = \"TM22_2015\"                    \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                                                       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 Store in memory:                                      \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   self.datasets[\"TM22_2015\"] = {                     \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502     \"households\": hh_df,                             \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502     \"persons\": per_df,                               \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502     \"tours\": tour_df,                                \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502     \"trips\": trip_df                                 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   }                                                   \u2502   \u2502   \u2502\n\u2502 \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502 \u2502                                                                 \u2502   \u2502\n\u2502 \u2502   Result: self.datasets = {                                    \u2502   \u2502\n\u2502 \u2502     \"TM22_2015\": {households: DF, persons: DF, ...},           \u2502   \u2502\n\u2502 \u2502     \"TM22_2023\": {households: DF, persons: DF, ...},           \u2502   \u2502\n\u2502 \u2502     \"HTS_2023\": {households: DF, persons: DF, ...}             \u2502   \u2502\n\u2502 \u2502   }                                                             \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 STEP 4: Generate All Summaries (MAIN LOOP)                             \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 generator.generate_all_summaries()                              \u2502   \u2502\n\u2502 \u2502                                                                 \u2502   \u2502\n\u2502 \u2502   FOR EACH summary in config.summaries:                        \u2502   \u2502\n\u2502 \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502 \u2502   \u2502 summary_name = \"auto_ownership_regional\"              \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                                                       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 Load summary definition from data_model/        \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 summary_def = load_summary_definition(          \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \"data_model/summary_auto_ownership_regional   \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502    .yaml\")                                       \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 Result:                                          \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   source_table: \"households\"                     \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   groupby: [\"num_vehicles\"]                      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   binning: {...}                                 \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   aggregation: {...}                             \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                      \u2193                                \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 Process EACH dataset for this summary           \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 dataset_results = []                             \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 FOR dataset_name in [\"TM22_2015\", \"TM22_2023\",  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                      \"HTS_2023\"]:                \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 df = self.datasets[dataset_name]     \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502                [\"households\"]         \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502                                       \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 APPLY TRANSFORMATIONS:                \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 1. apply_filters(df)                 \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 2. apply_binning(df)   \u2190 continuous  \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502                          to categories\u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 3. apply_aggregation(df) \u2190 combine   \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502                           categories  \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 4. groupby([\"num_vehicles\"])         \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 5. agg(count, sum, mean)             \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 6. apply weights (sample_rate)       \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 7. calculate shares (%)              \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502                                       \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 result_df['dataset'] = dataset_name  \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502                                       \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2502 dataset_results.append(result_df)    \u2502      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                      \u2193                                \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 Combine all datasets for this summary           \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 combined_df = pd.concat(dataset_results,        \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                         ignore_index=True)       \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 # Sort for consistent output                    \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 combined_df.sort_values(                        \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   [\"num_vehicles\", \"dataset\"])                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                      \u2193                                \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 Write CSV to disk                               \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 output_file = \"outputs/\" +                      \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502   \"auto_ownership_regional.csv\"                 \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                                                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502 combined_df.to_csv(output_file,                 \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2502                    index=False)                  \u2502 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502   \u2502   \u2502\n\u2502 \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502 \u2502                                                                 \u2502   \u2502\n\u2502 \u2502   REPEAT for next summary (tour_mode_by_purpose, etc.)        \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 STEP 5: Integrate External Data (Optional)                             \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 IF config.observed_summaries exists:                            \u2502   \u2502\n\u2502 \u2502                                                                 \u2502   \u2502\n\u2502 \u2502   FOR EACH observed_summary:                                   \u2502   \u2502\n\u2502 \u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502 \u2502   \u2502 # Load preprocessed external data                     \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 acs_df = pd.read_csv(                                \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   \"external_data/auto_ownership_acs_2023.csv\")       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 # Expected: same columns as model output              \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 #   + dataset column = \"ACS_2023\"                    \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                                                       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 # Load existing summary                               \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 existing = pd.read_csv(                              \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   \"outputs/auto_ownership_regional.csv\")             \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                                                       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 # Append external data                                \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 combined = pd.concat([existing, acs_df])             \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502                                                       \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 # Overwrite file                                      \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502 combined.to_csv(                                     \u2502   \u2502   \u2502\n\u2502 \u2502   \u2502   \"outputs/auto_ownership_regional.csv\")             \u2502   \u2502   \u2502\n\u2502 \u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 STEP 6: Prepare Dashboard Output                                       \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 Copy CSVs to dashboard folder:                                  \u2502   \u2502\n\u2502 \u2502   shutil.copy(\"outputs/*.csv\",                                  \u2502   \u2502\n\u2502 \u2502               \"outputs/dashboard/\")                             \u2502   \u2502\n\u2502 \u2502                                                                 \u2502   \u2502\n\u2502 \u2502 Dashboard configs already exist in dashboard/*.yaml             \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DONE - Summary CSVs ready in outputs/                                  \u2502\n\u2502                                                                         \u2502\n\u2502 Generated files:                                                        \u2502\n\u2502   outputs/auto_ownership_regional.csv                                  \u2502\n\u2502   outputs/tour_mode_by_purpose.csv                                     \u2502\n\u2502   outputs/cdap_by_household_type.csv                                   \u2502\n\u2502   ... (25 total CSV files)                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u2502 If --launch-dashboard flag used\n     v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DASHBOARD EXECUTION (streamlit_app.py)                                 \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502 \u2502 main()                                                          \u2502   \u2502\n\u2502 \u2502   \u2502                                                             \u2502   \u2502\n\u2502 \u2502   \u251c\u2500 Load variable_labels.yaml \u2192 Display names                 \u2502   \u2502\n\u2502 \u2502   \u251c\u2500 Load validation_config.yaml \u2192 Dataset order               \u2502   \u2502\n\u2502 \u2502   \u2502                                                             \u2502   \u2502\n\u2502 \u2502   \u251c\u2500 Scan outputs/dashboard/ for CSV files                     \u2502   \u2502\n\u2502 \u2502   \u251c\u2500 Scan dashboard/ for dashboard-*.yaml configs              \u2502   \u2502\n\u2502 \u2502   \u2502                                                             \u2502   \u2502\n\u2502 \u2502   \u2514\u2500 FOR EACH dashboard tab:                                   \u2502   \u2502\n\u2502 \u2502       \u2502                                                         \u2502   \u2502\n\u2502 \u2502       \u251c\u2500 Read dashboard-auto-ownership.yaml                    \u2502   \u2502\n\u2502 \u2502       \u2502   \u2192 Get list of summaries for this tab                 \u2502   \u2502\n\u2502 \u2502       \u2502                                                         \u2502   \u2502\n\u2502 \u2502       \u2514\u2500 FOR EACH summary in tab:                              \u2502   \u2502\n\u2502 \u2502           \u2502                                                     \u2502   \u2502\n\u2502 \u2502           \u251c\u2500 Load CSV: pd.read_csv(                            \u2502   \u2502\n\u2502 \u2502           \u2502   \"outputs/dashboard/auto_ownership_regional.csv\") \u2502   \u2502\n\u2502 \u2502           \u2502                                                     \u2502   \u2502\n\u2502 \u2502           \u251c\u2500 Create Plotly chart based on chart_type:          \u2502   \u2502\n\u2502 \u2502           \u2502   - bar: px.bar(df, x=\"num_vehicles\",              \u2502   \u2502\n\u2502 \u2502           \u2502                 y=\"households\",                     \u2502   \u2502\n\u2502 \u2502           \u2502                 color=\"dataset\")                    \u2502   \u2502\n\u2502 \u2502           \u2502   - line: px.line(...)                              \u2502   \u2502\n\u2502 \u2502           \u2502   - scatter: px.scatter(...)                        \u2502   \u2502\n\u2502 \u2502           \u2502                                                     \u2502   \u2502\n\u2502 \u2502           \u2514\u2500 st.plotly_chart(fig) \u2192 Render in browser          \u2502   \u2502\n\u2502 \u2502                                                                 \u2502   \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                         \u2502\n\u2502 Browser opens: http://localhost:8501                                   \u2502\n\u2502 User sees interactive dashboard with all charts                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"archived/code-flow/#high-level-flow-diagram","title":"High-Level Flow Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. START: User runs run_all.py with --config                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 2. CONFIGURATION LOADING (ConfigLoader class)                   \u2502\n\u2502    \u2022 Parse validation_config.yaml                               \u2502\n\u2502    \u2022 Validate dataset definitions                               \u2502\n\u2502    \u2022 Validate summary configurations                            \u2502\n\u2502    \u2022 Load data model schemas from data_model/                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 3. SUMMARY GENERATOR INITIALIZATION (SummaryGenerator class)    \u2502\n\u2502    \u2022 Create output directory structure                          \u2502\n\u2502    \u2022 Prepare for parallel processing                            \u2502\n\u2502    \u2022 Initialize logging                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 4. DATA LOADING LOOP (for each dataset in config)               \u2502\n\u2502    \u2022 Determine dataset type (model/survey/ACS/CTPP)             \u2502\n\u2502    \u2022 Load appropriate CSV files:                                \u2502\n\u2502      - Model: householdData_1.csv, personData_1.csv, etc.       \u2502\n\u2502      - Survey: Same format, different source directory          \u2502\n\u2502      - External: Preprocessed CSVs in external_data/            \u2502\n\u2502    \u2022 Apply data model validation                                \u2502\n\u2502    \u2022 Store in memory: {dataset_name: {table: DataFrame}}        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 5. SUMMARY GENERATION LOOP (for each summary in config)         \u2502\n\u2502    For each summary definition:                                 \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502    \u2502 5a. Load summary configuration from data_model/        \u2502   \u2502\n\u2502    \u2502     (groupby, filters, bins, aggregations)             \u2502   \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                          \u2193                                       \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502    \u2502 5b. For each dataset, apply processing pipeline:      \u2502   \u2502\n\u2502    \u2502     \u2022 Select source table (households/persons/tours)   \u2502   \u2502\n\u2502    \u2502     \u2022 Apply filters (if specified)                     \u2502   \u2502\n\u2502    \u2502     \u2022 Bin continuous variables \u2192 categories            \u2502   \u2502\n\u2502    \u2502     \u2022 Aggregate categories \u2192 broader groups            \u2502   \u2502\n\u2502    \u2502     \u2022 Group by dimensions                              \u2502   \u2502\n\u2502    \u2502     \u2022 Apply weights (sample_rate)                      \u2502   \u2502\n\u2502    \u2502     \u2022 Calculate counts and shares                      \u2502   \u2502\n\u2502    \u2502     \u2022 Add dataset identifier column                    \u2502   \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                          \u2193                                       \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502    \u2502 5c. Combine all datasets for this summary             \u2502   \u2502\n\u2502    \u2502     \u2022 Concatenate DataFrames vertically                \u2502   \u2502\n\u2502    \u2502     \u2022 Ensure consistent columns                        \u2502   \u2502\n\u2502    \u2502     \u2022 Sort by dimensions and dataset                   \u2502   \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                          \u2193                                       \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502    \u2502 5d. Write combined CSV to outputs/                    \u2502   \u2502\n\u2502    \u2502     Example: auto_ownership_regional.csv               \u2502   \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 6. EXTERNAL DATA INTEGRATION (if configured)                    \u2502\n\u2502    \u2022 Load preprocessed CSVs from external_data/                 \u2502\n\u2502    \u2022 Append to existing summary CSVs                            \u2502\n\u2502    \u2022 Re-write combined files                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 7. DASHBOARD-READY OUTPUT GENERATION                            \u2502\n\u2502    \u2022 Copy CSVs to outputs/dashboard/                            \u2502\n\u2502    \u2022 Generate dashboard configuration YAMLs                     \u2502\n\u2502    \u2022 Create variable_labels.yaml for display names             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 8. END: Summary CSVs ready for analysis and visualization       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"archived/code-flow/#detailed-step-by-step-execution","title":"Detailed Step-by-Step Execution","text":""},{"location":"archived/code-flow/#step-1-entry-and-argument-parsing","title":"Step 1: Entry and Argument Parsing","text":"<pre><code># In run_all.py main() function\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--config', help='Path to YAML configuration file')\n    args = parser.parse_args()\n\n    # Load and validate configuration\n    config = load_config(args.config)\n</code></pre> <p>What happens: 1. Parse command-line arguments 2. Determine if config file or explicit paths provided 3. Set up logging with timestamps</p>"},{"location":"archived/code-flow/#step-2-configuration-loading","title":"Step 2: Configuration Loading","text":"<p>File: <code>validation_config.yaml</code></p> <p>Pydantic Models (in <code>run_all.py</code>): - <code>ValidationConfig</code>: Top-level configuration container - <code>DatasetConfig</code>: Individual dataset specifications - <code>SummaryConfig</code>: Summary definition references - <code>ObservedSummary</code>: External data integration specs</p> <p>Loading Process: <pre><code>class ValidationConfig(BaseModel):\n    datasets: List[DatasetConfig]  # Model runs, surveys\n    summaries: List[SummaryConfig]  # Which summaries to generate\n    observed_summaries: Optional[List[ObservedSummary]]  # ACS, CTPP\n    dataset_order: List[str]  # Display order in charts\n    output_dir: Path = Path(\"outputs\")\n\n# Validation happens automatically via Pydantic\nconfig = ValidationConfig(**yaml.safe_load(config_file))\n</code></pre></p> <p>What gets validated: - All required fields present - Paths exist and are accessible - Dataset names are unique - Summary names match available summary definitions - Data model references are valid</p>"},{"location":"archived/code-flow/#step-3-data-model-loading","title":"Step 3: Data Model Loading","text":"<p>Location: <code>tm2py_utils/summary/validation/data_model/</code></p> <p>Files: - <code>variable_labels.yaml</code>: Human-readable display names - <code>summary_*.yaml</code>: Individual summary configurations (25 files)</p> <p>Loading Function: <pre><code>def load_data_model():\n    \"\"\"Load all summary definitions from YAML files.\"\"\"\n    summaries = {}\n    for yaml_file in Path(\"data_model\").glob(\"summary_*.yaml\"):\n        summary = SummaryDefinition(**yaml.safe_load(yaml_file))\n        summaries[summary.name] = summary\n    return summaries\n</code></pre></p> <p>SummaryDefinition Schema: <pre><code>name: auto_ownership_regional\ndescription: \"Household auto ownership by region\"\nsource_table: households\nfilters: null  # Optional: filter to specific records\nbinning:\n  - variable: income\n    bins: [0, 30000, 60000, 100000, 999999]\n    labels: [\"&lt;$30k\", \"$30-60k\", \"$60-100k\", \"$100k+\"]\naggregation:\n  num_persons:\n    \"4+\": [4, 5, 6, 7, 8, 9]  # Combine 4+ into single category\ngroupby:\n  - num_vehicles\n  - income_category\nmetrics:\n  - households  # Count of records\n  - share  # Percentage within group\n</code></pre></p>"},{"location":"archived/code-flow/#step-4-data-loading","title":"Step 4: Data Loading","text":"<p>CTRAMP Files Read (for each model dataset): <pre><code>def load_ctramp_dataset(directory: Path, dataset_name: str):\n    \"\"\"Load all CTRAMP output files for a model run.\"\"\"\n    data = {}\n\n    # Core tables (always required)\n    data['households'] = pd.read_csv(directory / \"householdData_1.csv\")\n    data['persons'] = pd.read_csv(directory / \"personData_1.csv\")\n\n    # Tour/trip data (if needed by summaries)\n    if any(s.source_table == 'tours' for s in summaries):\n        data['tours'] = pd.read_csv(directory / \"indivTourData_1.csv\")\n    if any(s.source_table == 'trips' for s in summaries):\n        data['trips'] = pd.read_csv(directory / \"indivTripData_1.csv\")\n\n    # Add dataset identifier\n    for table_name, df in data.items():\n        df['dataset'] = dataset_name\n\n    return data\n</code></pre></p> <p>Survey Files (same format, different directory): <pre><code># Survey must be preprocessed to CTRAMP format\nsurvey_data = load_ctramp_dataset(\n    directory=Path(\"surveys/2023_household_travel_survey\"),\n    dataset_name=\"HTS_2023\"\n)\n</code></pre></p> <p>External Data (preprocessed CSVs): <pre><code># Pre-aggregated to match summary output format\nacs_data = pd.read_csv(\"external_data/auto_ownership_acs.csv\")\n# Expected columns: same as model output + 'dataset' = 'ACS_2023'\n</code></pre></p>"},{"location":"archived/code-flow/#step-5-summary-generation-pipeline","title":"Step 5: Summary Generation Pipeline","text":"<p>For each summary, the system executes this pipeline:</p>"},{"location":"archived/code-flow/#51-select-source-data","title":"5.1 Select Source Data","text":"<pre><code>summary = summaries['auto_ownership_regional']\nsource_table = summary.source_table  # 'households'\ndf = datasets['TM22_2015']['households'].copy()\n</code></pre>"},{"location":"archived/code-flow/#52-apply-filters-if-specified","title":"5.2 Apply Filters (if specified)","text":"<pre><code>if summary.filters:\n    for filter_spec in summary.filters:\n        df = df[df[filter_spec.column].isin(filter_spec.values)]\n</code></pre>"},{"location":"archived/code-flow/#53-binning-continuous-categorical","title":"5.3 Binning (continuous \u2192 categorical)","text":"<pre><code>if summary.binning:\n    for bin_spec in summary.binning:\n        df[f'{bin_spec.variable}_category'] = pd.cut(\n            df[bin_spec.variable],\n            bins=bin_spec.bins,\n            labels=bin_spec.labels,\n            right=False\n        )\n</code></pre>"},{"location":"archived/code-flow/#54-aggregation-detailed-broader-categories","title":"5.4 Aggregation (detailed \u2192 broader categories)","text":"<pre><code>if summary.aggregation:\n    for var, mapping in summary.aggregation.items():\n        # Example: {4: [4,5,6,7,8,9]} -&gt; all 4+ become \"4+\"\n        df[f'{var}_agg'] = df[var].apply(lambda x: \n            next((k for k, v in mapping.items() if x in v), x)\n        )\n</code></pre>"},{"location":"archived/code-flow/#55-group-and-weight","title":"5.5 Group and Weight","text":"<pre><code>groupby_cols = summary.groupby\nresult = df.groupby(groupby_cols).agg({\n    'hh_id': 'count',  # Count households\n    'sample_rate': 'first'  # Expansion factor\n}).reset_index()\n\n# Apply weights\nresult['households'] = result['hh_id'] / result['sample_rate']\n\n# Calculate shares within groups\nif summary.share_within:\n    result['share'] = result.groupby(summary.share_within)['households'].transform(\n        lambda x: x / x.sum() * 100\n    )\n</code></pre>"},{"location":"archived/code-flow/#56-add-dataset-identifier","title":"5.6 Add Dataset Identifier","text":"<pre><code>result['dataset'] = dataset_name  # e.g., \"TM22_2015\"\n</code></pre>"},{"location":"archived/code-flow/#57-combine-all-datasets","title":"5.7 Combine All Datasets","text":"<pre><code>combined = pd.concat([\n    process_dataset(datasets['TM22_2015'], 'TM22_2015'),\n    process_dataset(datasets['TM22_2023'], 'TM22_2023'),\n    process_dataset(datasets['HTS_2023'], 'HTS_2023')\n], ignore_index=True)\n</code></pre>"},{"location":"archived/code-flow/#58-write-csv","title":"5.8 Write CSV","text":"<pre><code>output_file = output_dir / f\"{summary.name}.csv\"\ncombined.to_csv(output_file, index=False)\n</code></pre> <p>Example Output CSV: <pre><code>num_vehicles,income_category,households,share,dataset\n0,&lt;$30k,125430,45.2,TM22_2015\n0,&lt;$30k,118920,43.8,TM22_2023\n0,&lt;$30k,142000,48.1,HTS_2023\n0,&lt;$30k,139500,47.5,ACS_2023\n1,$30-60k,87500,31.5,TM22_2015\n...\n</code></pre></p>"},{"location":"archived/code-flow/#step-6-external-data-integration","title":"Step 6: External Data Integration","text":"<pre><code>if config.observed_summaries:\n    for obs_summary in config.observed_summaries:\n        # Load preprocessed external data\n        external_df = pd.read_csv(obs_summary.file_path)\n\n        # Load existing summary CSV\n        existing = pd.read_csv(output_dir / f\"{obs_summary.summary_name}.csv\")\n\n        # Append external data\n        combined = pd.concat([existing, external_df], ignore_index=True)\n\n        # Overwrite with combined data\n        combined.to_csv(output_dir / f\"{obs_summary.summary_name}.csv\", index=False)\n</code></pre>"},{"location":"archived/code-flow/#step-7-dashboard-preparation","title":"Step 7: Dashboard Preparation","text":"<pre><code># Copy CSVs to dashboard folder\ndashboard_dir = output_dir / \"dashboard\"\nfor csv_file in output_dir.glob(\"*.csv\"):\n    shutil.copy(csv_file, dashboard_dir / csv_file.name)\n\n# Generate dashboard config YAMLs (if not already present)\n# These define chart types, axes, titles for Streamlit app\n</code></pre>"},{"location":"archived/code-flow/#key-classes-and-their-roles","title":"Key Classes and Their Roles","text":""},{"location":"archived/code-flow/#core-processing-classes","title":"Core Processing Classes","text":""},{"location":"archived/code-flow/#summarygenerator-run_allpy","title":"<code>SummaryGenerator</code> (run_all.py)","text":"<p>Purpose: Orchestrates entire summary generation process</p> <p>Key Methods: - <code>__init__(config)</code>: Initialize with validated configuration - <code>load_datasets()</code>: Read all CTRAMP CSVs into memory - <code>generate_all_summaries()</code>: Main loop over all summaries - <code>generate_summary(summary_def, datasets)</code>: Process one summary - <code>write_outputs(results)</code>: Save combined CSVs</p> <p>Usage: <pre><code>generator = SummaryGenerator(config)\ngenerator.load_datasets()\nresults = generator.generate_all_summaries()\ngenerator.write_outputs(results)\n</code></pre></p>"},{"location":"archived/code-flow/#datamodelloader-ctramp_data_model_loaderpy","title":"<code>DataModelLoader</code> (ctramp_data_model_loader.py)","text":"<p>Purpose: Load and validate summary definitions from YAML</p> <p>Key Methods: - <code>load_summary_definitions()</code>: Read all summary_*.yaml files - <code>validate_summary(summary_def)</code>: Check for required fields - <code>get_summary(name)</code>: Retrieve specific summary configuration</p>"},{"location":"archived/code-flow/#configloader-run_allpy","title":"<code>ConfigLoader</code> (run_all.py)","text":"<p>Purpose: Load and validate top-level configuration</p> <p>Pydantic Models: - <code>ValidationConfig</code>: Complete config schema - <code>DatasetConfig</code>: Single dataset specification - <code>SummaryConfig</code>: Summary to generate - <code>ObservedSummary</code>: External data integration</p>"},{"location":"archived/code-flow/#data-model-classes","title":"Data Model Classes","text":""},{"location":"archived/code-flow/#summarydefinition-ctramp_data_model_loaderpy","title":"<code>SummaryDefinition</code> (ctramp_data_model_loader.py)","text":"<p>Purpose: Schema for individual summary configurations</p> <p>Fields: <pre><code>class SummaryDefinition(BaseModel):\n    name: str\n    description: str\n    source_table: str  # households, persons, tours, trips\n    filters: Optional[List[FilterSpec]]\n    binning: Optional[List[BinSpec]]\n    aggregation: Optional[Dict[str, Dict[str, List]]]\n    groupby: List[str]\n    metrics: List[str]\n    share_within: Optional[List[str]]\n</code></pre></p>"},{"location":"archived/code-flow/#binspec-ctramp_data_model_loaderpy","title":"<code>BinSpec</code> (ctramp_data_model_loader.py)","text":"<p>Purpose: Define continuous-to-categorical binning</p> <pre><code>class BinSpec(BaseModel):\n    variable: str  # Source column name\n    bins: List[float]  # Bin edges\n    labels: List[str]  # Category labels\n    output_column: str  # New column name (default: f\"{variable}_category\")\n</code></pre>"},{"location":"archived/code-flow/#data-processing-pipeline","title":"Data Processing Pipeline","text":""},{"location":"archived/code-flow/#pipeline-architecture","title":"Pipeline Architecture","text":"<pre><code>RAW DATA (CTRAMP CSV)\n       \u2193\n    FILTER  \u2190 Apply row filters (optional)\n       \u2193\n    BIN     \u2190 Convert continuous \u2192 categorical\n       \u2193\n  AGGREGATE \u2190 Combine detailed categories\n       \u2193\n   GROUP BY \u2190 Group by dimensions\n       \u2193\n   WEIGHT   \u2190 Apply sample_rate expansion\n       \u2193\n   METRICS  \u2190 Calculate counts, shares, averages\n       \u2193\n   OUTPUT   \u2190 Standardized CSV with dataset column\n</code></pre>"},{"location":"archived/code-flow/#processing-functions","title":"Processing Functions","text":""},{"location":"archived/code-flow/#filter-application","title":"Filter Application","text":"<pre><code>def apply_filters(df: pd.DataFrame, filters: List[FilterSpec]) -&gt; pd.DataFrame:\n    \"\"\"Apply row-level filters to data.\"\"\"\n    for filter_spec in filters:\n        if filter_spec.operator == 'in':\n            df = df[df[filter_spec.column].isin(filter_spec.values)]\n        elif filter_spec.operator == '==':\n            df = df[df[filter_spec.column] == filter_spec.value]\n        elif filter_spec.operator == '&gt;':\n            df = df[df[filter_spec.column] &gt; filter_spec.value]\n    return df\n</code></pre>"},{"location":"archived/code-flow/#binning-continuous-variables","title":"Binning Continuous Variables","text":"<pre><code>def apply_binning(df: pd.DataFrame, binning: List[BinSpec]) -&gt; pd.DataFrame:\n    \"\"\"Convert continuous variables to categorical bins.\"\"\"\n    for bin_spec in binning:\n        output_col = bin_spec.output_column or f\"{bin_spec.variable}_category\"\n        df[output_col] = pd.cut(\n            df[bin_spec.variable],\n            bins=bin_spec.bins,\n            labels=bin_spec.labels,\n            right=False,  # [a, b) intervals\n            include_lowest=True\n        )\n    return df\n</code></pre>"},{"location":"archived/code-flow/#category-aggregation","title":"Category Aggregation","text":"<pre><code>def apply_aggregation(df: pd.DataFrame, aggregation: Dict) -&gt; pd.DataFrame:\n    \"\"\"Combine detailed categories into broader groups.\"\"\"\n    for variable, mapping in aggregation.items():\n        output_col = f\"{variable}_agg\"\n\n        # Create mapping function\n        def map_value(x):\n            for new_value, old_values in mapping.items():\n                if x in old_values:\n                    return new_value\n            return x  # Keep original if not in mapping\n\n        df[output_col] = df[variable].apply(map_value)\n    return df\n</code></pre>"},{"location":"archived/code-flow/#grouping-and-weighting","title":"Grouping and Weighting","text":"<pre><code>def group_and_weight(df: pd.DataFrame, summary: SummaryDefinition) -&gt; pd.DataFrame:\n    \"\"\"Group by dimensions, apply weights, calculate metrics.\"\"\"\n\n    # Group and count\n    grouped = df.groupby(summary.groupby).agg({\n        'hh_id': 'count',\n        'sample_rate': 'first'\n    }).reset_index()\n\n    # Apply expansion weights\n    grouped['households'] = grouped['hh_id'] / grouped['sample_rate']\n\n    # Calculate shares if specified\n    if summary.share_within:\n        grouped['share'] = grouped.groupby(summary.share_within)['households'].transform(\n            lambda x: x / x.sum() * 100\n        )\n\n    # Select final columns\n    final_cols = summary.groupby + summary.metrics\n    return grouped[final_cols]\n</code></pre>"},{"location":"archived/code-flow/#configuration-loading","title":"Configuration Loading","text":""},{"location":"archived/code-flow/#configuration-file-structure","title":"Configuration File Structure","text":"<pre><code># validation_config.yaml\n\n# Dataset definitions\ndatasets:\n  - name: \"TM22_2015\"\n    directory: \"A:/2015-tm22-dev-sprint-01/ctramp_output\"\n    type: \"model\"\n\n  - name: \"TM22_2023\"\n    directory: \"A:/2023-tm22-dev-version-05/ctramp_output\"\n    type: \"model\"\n\n  - name: \"HTS_2023\"\n    directory: \"surveys/2023_formatted\"\n    type: \"survey\"\n\n# Summary specifications (references to data_model/*.yaml)\nsummaries:\n  - name: \"auto_ownership_regional\"\n  - name: \"tour_mode_by_purpose\"\n  - name: \"cdap_by_household_type\"\n\n# External data integration\nobserved_summaries:\n  - summary_name: \"auto_ownership_regional\"\n    file_path: \"external_data/auto_ownership_acs_2023.csv\"\n    dataset_name: \"ACS_2023\"\n\n# Dashboard display order\ndataset_order:\n  - \"TM22_2015\"\n  - \"TM22_2023\"\n  - \"HTS_2023\"\n  - \"ACS_2023\"\n\n# Output directory\noutput_dir: \"outputs\"\n</code></pre>"},{"location":"archived/code-flow/#configuration-loading-code","title":"Configuration Loading Code","text":"<pre><code>def load_config(config_path: Path) -&gt; ValidationConfig:\n    \"\"\"Load and validate configuration file.\"\"\"\n    with open(config_path, 'r') as f:\n        config_dict = yaml.safe_load(f)\n\n    # Pydantic automatically validates against schema\n    config = ValidationConfig(**config_dict)\n\n    # Additional validation\n    validate_dataset_paths(config.datasets)\n    validate_summary_references(config.summaries)\n\n    return config\n\ndef validate_dataset_paths(datasets: List[DatasetConfig]):\n    \"\"\"Ensure all dataset directories exist.\"\"\"\n    for dataset in datasets:\n        if not Path(dataset.directory).exists():\n            raise ValueError(f\"Dataset directory not found: {dataset.directory}\")\n\ndef validate_summary_references(summaries: List[SummaryConfig]):\n    \"\"\"Ensure all referenced summaries have definitions.\"\"\"\n    available_summaries = load_data_model()\n    for summary in summaries:\n        if summary.name not in available_summaries:\n            raise ValueError(f\"Summary definition not found: {summary.name}\")\n</code></pre>"},{"location":"archived/code-flow/#code-module-map","title":"Code Module Map","text":""},{"location":"archived/code-flow/#directory-structure","title":"Directory Structure","text":"<pre><code>tm2py_utils/summary/validation/\n\u2502\n\u251c\u2500\u2500 summaries/\n\u2502   \u251c\u2500\u2500 run_all.py              \u2190 MAIN ENTRY POINT\n\u2502   \u2514\u2500\u2500 config_driven_summaries.py  \u2190 Legacy (being phased out)\n\u2502\n\u251c\u2500\u2500 data_model/\n\u2502   \u251c\u2500\u2500 ctramp_data_model_loader.py  \u2190 Load summary definitions\n\u2502   \u251c\u2500\u2500 variable_labels.yaml         \u2190 Display names\n\u2502   \u251c\u2500\u2500 summary_auto_ownership_regional.yaml\n\u2502   \u251c\u2500\u2500 summary_tour_mode_by_purpose.yaml\n\u2502   \u2514\u2500\u2500 ... (25 summary definition files)\n\u2502\n\u251c\u2500\u2500 dashboard/\n\u2502   \u251c\u2500\u2500 dashboard_app.py        \u2190 Streamlit visualization\n\u2502   \u251c\u2500\u2500 dashboard-auto-ownership.yaml\n\u2502   \u2514\u2500\u2500 ... (8 dashboard config files)\n\u2502\n\u251c\u2500\u2500 outputs/\n\u2502   \u251c\u2500\u2500 auto_ownership_regional.csv\n\u2502   \u251c\u2500\u2500 tour_mode_by_purpose.csv\n\u2502   \u2514\u2500\u2500 dashboard/\n\u2502       \u251c\u2500\u2500 *.csv (copies for deployment)\n\u2502       \u2514\u2500\u2500 *.yaml (dashboard configs)\n\u2502\n\u251c\u2500\u2500 external_data/\n\u2502   \u251c\u2500\u2500 auto_ownership_acs_2023.csv\n\u2502   \u2514\u2500\u2500 ... (preprocessed ACS, CTPP data)\n\u2502\n\u251c\u2500\u2500 validation_config.yaml      \u2190 TOP-LEVEL CONFIGURATION\n\u251c\u2500\u2500 streamlit_app.py           \u2190 Dashboard entry point\n\u251c\u2500\u2500 run_and_deploy_dashboard.py  \u2190 Convenience wrapper\n\u2514\u2500\u2500 docs/\n    \u251c\u2500\u2500 validation-system.md    \u2190 User guide\n    \u251c\u2500\u2500 code-flow.md           \u2190 This file\n    \u251c\u2500\u2500 data-model.md\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"archived/code-flow/#module-dependencies","title":"Module Dependencies","text":"<pre><code>run_all.py\n  \u251c\u2500 imports \u2500\u2192 ctramp_data_model_loader.py\n  \u2502             \u2514\u2500 loads \u2500\u2192 data_model/summary_*.yaml\n  \u2502\n  \u251c\u2500 reads \u2500\u2192 validation_config.yaml\n  \u2502\n  \u251c\u2500 loads \u2500\u2192 CTRAMP CSVs from dataset directories\n  \u2502\n  \u2514\u2500 writes \u2500\u2192 outputs/*.csv\n\nstreamlit_app.py\n  \u251c\u2500 reads \u2500\u2192 outputs/dashboard/*.csv\n  \u251c\u2500 reads \u2500\u2192 dashboard/dashboard-*.yaml\n  \u2514\u2500 reads \u2500\u2192 data_model/variable_labels.yaml\n\nrun_and_deploy_dashboard.py\n  \u251c\u2500 calls \u2500\u2192 run_all.py\n  \u2514\u2500 launches \u2500\u2192 streamlit_app.py\n</code></pre>"},{"location":"archived/code-flow/#function-call-hierarchy","title":"Function Call Hierarchy","text":"<pre><code>main()  [run_all.py]\n  \u2502\n  \u251c\u2500 parse_arguments()\n  \u251c\u2500 load_config()\n  \u2502   \u251c\u2500 yaml.safe_load()\n  \u2502   \u2514\u2500 ValidationConfig.parse_obj()\n  \u2502\n  \u251c\u2500 SummaryGenerator.__init__()\n  \u2502\n  \u251c\u2500 generator.load_datasets()\n  \u2502   \u2514\u2500 For each dataset:\n  \u2502       \u251c\u2500 load_ctramp_dataset()\n  \u2502       \u2502   \u251c\u2500 pd.read_csv(\"householdData_1.csv\")\n  \u2502       \u2502   \u251c\u2500 pd.read_csv(\"personData_1.csv\")\n  \u2502       \u2502   \u2514\u2500 ...\n  \u2502       \u2514\u2500 validate_data_model()\n  \u2502\n  \u251c\u2500 generator.generate_all_summaries()\n  \u2502   \u2514\u2500 For each summary:\n  \u2502       \u251c\u2500 load_summary_definition()\n  \u2502       \u251c\u2500 generator.generate_summary()\n  \u2502       \u2502   \u2514\u2500 For each dataset:\n  \u2502       \u2502       \u251c\u2500 apply_filters()\n  \u2502       \u2502       \u251c\u2500 apply_binning()\n  \u2502       \u2502       \u251c\u2500 apply_aggregation()\n  \u2502       \u2502       \u251c\u2500 group_and_weight()\n  \u2502       \u2502       \u2514\u2500 calculate_metrics()\n  \u2502       \u2514\u2500 combine_datasets()\n  \u2502\n  \u251c\u2500 generator.integrate_external_data()\n  \u2502   \u2514\u2500 For each observed_summary:\n  \u2502       \u251c\u2500 pd.read_csv(external_file)\n  \u2502       \u2514\u2500 append_to_summary()\n  \u2502\n  \u2514\u2500 generator.write_outputs()\n      \u2514\u2500 For each summary result:\n          \u2514\u2500 df.to_csv()\n</code></pre>"},{"location":"archived/code-flow/#execution-examples","title":"Execution Examples","text":""},{"location":"archived/code-flow/#example-1-generate-all-summaries","title":"Example 1: Generate All Summaries","text":"<pre><code>cd tm2py_utils/summary/validation\npython -m tm2py_utils.summary.validation.summaries.run_all \\\n    --config validation_config.yaml\n</code></pre> <p>What happens: 1. Loads <code>validation_config.yaml</code> 2. Reads 3 datasets (2 model runs, 1 survey) 3. Generates 25 summaries 4. Writes 25 CSVs to <code>outputs/</code> 5. Integrates ACS data into 5 summaries 6. Copies files to <code>outputs/dashboard/</code> 7. Total time: ~2-5 minutes depending on data size</p>"},{"location":"archived/code-flow/#example-2-generate-specific-summaries","title":"Example 2: Generate Specific Summaries","text":"<pre><code>python -m tm2py_utils.summary.validation.summaries.run_all \\\n    --config validation_config.yaml \\\n    --summaries auto_ownership_regional tour_mode_by_purpose\n</code></pre> <p>What happens: - Only generates 2 specified summaries - Skips other 23 summaries - Faster execution (~30 seconds)</p>"},{"location":"archived/code-flow/#example-3-validate-configuration-only","title":"Example 3: Validate Configuration Only","text":"<pre><code>python -m tm2py_utils.summary.validation.summaries.run_all \\\n    --config validation_config.yaml \\\n    --validate-only\n</code></pre> <p>What happens: - Loads and validates configuration - Checks all paths exist - Verifies summary definitions found - Does NOT load data or generate summaries - Reports any errors - Exits</p>"},{"location":"archived/code-flow/#example-4-run-and-launch-dashboard","title":"Example 4: Run and Launch Dashboard","text":"<pre><code>python run_and_deploy_dashboard.py \\\n    --config validation_config.yaml \\\n    --launch-dashboard\n</code></pre> <p>What happens: 1. Generates all summaries (same as Example 1) 2. Launches Streamlit on http://localhost:8501 3. Opens dashboard in browser 4. Dashboard auto-loads CSVs from <code>outputs/dashboard/</code></p>"},{"location":"archived/code-flow/#performance-considerations","title":"Performance Considerations","text":""},{"location":"archived/code-flow/#memory-usage","title":"Memory Usage","text":"<p>Data Loading: All datasets loaded into memory simultaneously - Typical model run: ~500MB per dataset - 3 datasets = ~1.5GB RAM - Recommendation: 8GB+ RAM for production use</p> <p>Optimization: Process datasets sequentially if memory constrained <pre><code># Instead of loading all at once:\nfor dataset in datasets:\n    data = load_dataset(dataset)\n    process_summaries(data)\n    del data  # Free memory\n</code></pre></p>"},{"location":"archived/code-flow/#execution-time","title":"Execution Time","text":"<p>Typical Performance (on 2023 hardware): - Load 1 dataset (4 CSV files, ~2M records): 10-30 seconds - Generate 1 summary: 1-5 seconds - Total for 3 datasets \u00d7 25 summaries: 2-5 minutes</p> <p>Bottlenecks: 1. CSV reading (disk I/O) 2. Groupby operations on large datasets 3. Writing output CSVs</p> <p>Parallelization (future enhancement): <pre><code># Process summaries in parallel\nfrom multiprocessing import Pool\nwith Pool(4) as pool:\n    results = pool.map(generate_summary, summaries)\n</code></pre></p>"},{"location":"archived/code-flow/#data-size-limits","title":"Data Size Limits","text":"<p>Tested With: - Households: 2.7M records - Persons: 6.5M records - Tours: 12M records - Trips: 40M records</p> <p>Practical Limits: - CSV file size: &lt;2GB per file - Total memory: &lt;16GB for all data - If larger: Consider Parquet format or database backend</p>"},{"location":"archived/code-flow/#error-handling","title":"Error Handling","text":""},{"location":"archived/code-flow/#common-errors-and-solutions","title":"Common Errors and Solutions","text":""},{"location":"archived/code-flow/#configuration-errors","title":"Configuration Errors","text":"<p>Error: <code>Summary definition not found: xyz</code> - Cause: Referenced summary doesn't have YAML file - Solution: Check <code>data_model/</code> for <code>summary_xyz.yaml</code></p> <p>Error: <code>Dataset directory not found: path/to/data</code> - Cause: Invalid path in validation_config.yaml - Solution: Verify path exists and is accessible</p>"},{"location":"archived/code-flow/#data-errors","title":"Data Errors","text":"<p>Error: <code>KeyError: 'hh_id'</code> - Cause: CTRAMP CSV missing required column - Solution: Validate data against CTRAMP data model schema</p> <p>Error: <code>ValueError: invalid literal for int()</code> - Cause: Data type mismatch (e.g., text in numeric column) - Solution: Clean source data, check for NaN values</p>"},{"location":"archived/code-flow/#processing-errors","title":"Processing Errors","text":"<p>Error: <code>MemoryError</code> - Cause: Dataset too large for available RAM - Solution: Process datasets sequentially, increase RAM, or sample data</p> <p>Error: <code>Empty DataFrame after filtering</code> - Cause: Filters too restrictive, removed all records - Solution: Review filter specifications in summary YAML</p>"},{"location":"archived/code-flow/#logging-and-debugging","title":"Logging and Debugging","text":"<p>Enable Verbose Logging: <pre><code>logging.basicConfig(level=logging.DEBUG)\n</code></pre></p> <p>Log Output Example: <pre><code>2025-12-11 10:30:15 - INFO - Loading configuration from validation_config.yaml\n2025-12-11 10:30:16 - INFO - Found 3 datasets, 25 summaries\n2025-12-11 10:30:16 - INFO - Loading dataset: TM22_2015\n2025-12-11 10:30:45 - INFO - Loaded 2,700,000 households\n2025-12-11 10:30:58 - INFO - Generating summary: auto_ownership_regional\n2025-12-11 10:31:03 - INFO - Wrote outputs/auto_ownership_regional.csv\n</code></pre></p>"},{"location":"archived/code-flow/#next-steps","title":"Next Steps","text":"<ul> <li>User Guide: High-level system overview</li> <li>Data Model Reference: Complete schema documentation</li> <li>Custom Summaries: Create new summary definitions</li> <li>Dashboard Guide: Customize visualizations</li> <li>Development Tasks: Ongoing improvements</li> </ul> <p>Live Dashboard: https://tm2-dashboard.streamlit.app/</p>"},{"location":"archived/dashboard/","title":"Dashboard Guide","text":"<p>The tm2py-utils validation dashboard is an interactive web application for comparing model runs and validating outputs against observed data.</p>"},{"location":"archived/dashboard/#live-dashboard","title":"Live Dashboard","text":"<p>View the deployed dashboard: https://tm2-dashboard.streamlit.app/</p>"},{"location":"archived/dashboard/#running-locally","title":"Running Locally","text":""},{"location":"archived/dashboard/#quick-start","title":"Quick Start","text":"<pre><code>cd tm2py_utils/summary/validation\nstreamlit run dashboard/dashboard_app.py --server.port 8501\n</code></pre> <p>The dashboard will open at <code>http://localhost:8501</code></p>"},{"location":"archived/dashboard/#using-the-deployment-script","title":"Using the Deployment Script","text":"<pre><code># Generate summaries and launch dashboard\npython run_and_deploy_dashboard.py --config validation_config.yaml --launch-dashboard\n\n# Use custom port\npython run_and_deploy_dashboard.py --config validation_config.yaml --launch-dashboard --port 8503\n</code></pre>"},{"location":"archived/dashboard/#dashboard-tabs","title":"Dashboard Tabs","text":""},{"location":"archived/dashboard/#0-population","title":"0. Population","text":"<p>Synthetic population from PopulationSim with ACS validation: - Household size distribution - Income distribution - Geographic distribution by county - Workers per household - Age distribution</p>"},{"location":"archived/dashboard/#1-households","title":"1. Households","text":"<p>Auto ownership analysis from CTRAMP model: - Regional auto ownership - By income category - By household size (with ACS comparison) - By county</p>"},{"location":"archived/dashboard/#2-activity-patterns","title":"2. Activity Patterns","text":"<p>Coordinated daily activity patterns (CDAP): - Overall distribution - By person type (worker, student, etc.) - By age group - By home county - By auto ownership</p>"},{"location":"archived/dashboard/#3-tours","title":"3. Tours","text":"<p>Tour frequency and characteristics: - Tours by purpose - Tours by mode - Tour distance distribution - Tour duration distribution</p>"},{"location":"archived/dashboard/#4-trips","title":"4. Trips","text":"<p>Trip-level analysis: - Trips by mode - Trips by purpose - Mode by purpose cross-tabs - Trip distance and duration</p>"},{"location":"archived/dashboard/#5-journey-to-work","title":"5. Journey to Work","text":"<p>Commute pattern analysis: - Commute distance by origin-destination - Commute time by origin-destination - Mode share for work tours - Mode by origin-destination</p>"},{"location":"archived/dashboard/#6-time-of-day","title":"6. Time of Day","text":"<p>Temporal distribution of travel: - Tour departure times - Tour arrival times - Tour timing by purpose and mode - Trip mode by time period</p>"},{"location":"archived/dashboard/#7-trip-characteristics","title":"7. Trip Characteristics","text":"<p>Detailed distance and time analysis: - Trip distance distribution - Average distance by income/mode/purpose - Trip duration distribution - Average time by income/mode/purpose</p>"},{"location":"archived/dashboard/#dashboard-features","title":"Dashboard Features","text":""},{"location":"archived/dashboard/#interactive-charts","title":"Interactive Charts","text":"<ul> <li>Hover: See exact values</li> <li>Zoom: Click and drag to zoom in</li> <li>Pan: Shift+drag to pan</li> <li>Reset: Double-click to reset view</li> <li>Download: Camera icon to save as PNG</li> </ul>"},{"location":"archived/dashboard/#filters","title":"Filters","text":"<ul> <li>Dataset Comparison: Select which model runs to compare</li> <li>Faceting: Some charts split data across multiple panels</li> </ul>"},{"location":"archived/dashboard/#data-export","title":"Data Export","text":"<p>Click the download icon on any chart to export as PNG for reports.</p>"},{"location":"archived/dashboard/#customizing-the-dashboard","title":"Customizing the Dashboard","text":""},{"location":"archived/dashboard/#adding-new-charts","title":"Adding New Charts","text":"<p>Edit or create dashboard YAML files in <code>dashboard/</code> folder:</p> <pre><code>dashboard:\n  tab: My New Tab\n  title: Custom Analysis\n  description: Description of what this shows\n\nsections:\n  my_section:\n    title: \"Section Title\"\n    charts:\n      - type: bar\n        title: \"Chart Title\"\n        dataset: my_data.csv\n        x: category\n        y: value\n        color: dataset\n        axis_labels:\n          category: \"Category Name\"\n          value: \"Value Label\"\n</code></pre>"},{"location":"archived/dashboard/#chart-types","title":"Chart Types","text":"<p>Supported chart types: - <code>bar</code> - Bar charts (most common) - <code>line</code> - Line charts - <code>scatter</code> - Scatter plots</p>"},{"location":"archived/dashboard/#faceting","title":"Faceting","text":"<p>Split charts across multiple panels:</p> <pre><code>- type: bar\n  title: \"My Chart\"\n  dataset: data.csv\n  x: category\n  y: value\n  color: subcategory\n  facet: dataset  # Creates separate panel for each dataset\n</code></pre>"},{"location":"archived/dashboard/#data-requirements","title":"Data Requirements","text":"<p>The dashboard reads CSV files from <code>outputs/dashboard/</code> directory. Each CSV must have:</p> <ol> <li>Column for x-axis (categories, modes, etc.)</li> <li>Column for y-axis (counts, shares, averages, etc.)</li> <li>dataset column (to distinguish between model runs)</li> </ol> <p>Example CSV structure:</p> <pre><code>trip_mode,trips,share,dataset\nDrive Alone,1000000,45.2,2023 TM2.2 v05\nCarpool,300000,13.6,2023 TM2.2 v05\nTransit,200000,9.0,2023 TM2.2 v05\nDrive Alone,950000,43.8,2015 TM2.2 Sprint 04\n...\n</code></pre>"},{"location":"archived/dashboard/#troubleshooting","title":"Troubleshooting","text":""},{"location":"archived/dashboard/#no-data-available","title":"\"No data available\"","text":"<p>Ensure CSV files exist in <code>outputs/dashboard/</code> and column names match the YAML configuration.</p>"},{"location":"archived/dashboard/#port-already-in-use","title":"Port already in use","text":"<p>Use a different port: <pre><code>streamlit run dashboard/dashboard_app.py --server.port 8503\n</code></pre></p>"},{"location":"archived/dashboard/#charts-not-updating","title":"Charts not updating","text":"<p>Streamlit auto-reloads when files change. If not working, refresh the browser (F5).</p>"},{"location":"archived/dashboard/#missing-tabs","title":"Missing tabs","text":"<p>Check that dashboard YAML files are in <code>dashboard/</code> directory (not <code>outputs/dashboard/</code>).</p>"},{"location":"archived/dashboard/#deployment","title":"Deployment","text":"<p>The dashboard auto-deploys to Streamlit Cloud when changes are pushed to the main branch on GitHub.</p> <p>Live URL: https://tm2-dashboard.streamlit.app/</p>"},{"location":"archived/dashboard/#manual-deployment","title":"Manual Deployment","text":"<p>To deploy your own instance:</p> <ol> <li>Create a Streamlit Cloud account</li> <li>Connect your GitHub repository</li> <li>Set main file: <code>tm2py_utils/summary/validation/streamlit_app.py</code></li> <li>Deploy!</li> </ol>"},{"location":"archived/dashboard/#next-steps","title":"Next Steps","text":"<ul> <li>Generate Summaries to populate dashboard data</li> <li>Customize Configuration to add new analyses</li> </ul>"},{"location":"archived/deploy-dashboard/","title":"Deploy Dashboard","text":"<p>Guide to launching and customizing the Streamlit validation dashboard.</p>"},{"location":"archived/deploy-dashboard/#overview","title":"Overview","text":"<p>The validation dashboard is a Streamlit web application that visualizes summary data with interactive charts. It displays model-vs-model and model-vs-observed comparisons across multiple datasets.</p> <p>Features: - Interactive charts (bar, line, scatter, heatmap) - Multi-dataset comparisons - Filter by dataset, geography, time period - Export charts as images - Fully configurable via YAML</p> <p>Technology: Built with Streamlit and Plotly</p>"},{"location":"archived/deploy-dashboard/#quick-start","title":"Quick Start","text":""},{"location":"archived/deploy-dashboard/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the <code>tm2py-utils</code> conda environment activated:</p> <pre><code>conda activate tm2py-utils\n</code></pre> <p>This environment includes Streamlit, Plotly, and all required dependencies.</p>"},{"location":"archived/deploy-dashboard/#option-1-launch-dashboard-directly","title":"Option 1: Launch Dashboard Directly","text":"<p>From the validation directory:</p> <pre><code>cd C:\\GitHub\\tm2py-utils\\tm2py_utils\\summary\\validation\nstreamlit run dashboard/dashboard_app.py --server.port 8501\n</code></pre> <p>Dashboard opens at: http://localhost:8501</p>"},{"location":"archived/deploy-dashboard/#option-2-generate-summaries-launch-dashboard","title":"Option 2: Generate Summaries + Launch Dashboard","text":"<pre><code>cd C:\\GitHub\\tm2py-utils\\tm2py_utils\\summary\\validation\npython run_and_deploy_dashboard.py --config validation_config.yaml --launch-dashboard\n</code></pre> <p>This: 1. Generates all summaries 2. Copies CSVs to dashboard directory 3. Launches Streamlit</p>"},{"location":"archived/deploy-dashboard/#option-3-custom-port","title":"Option 3: Custom Port","text":"<p>If port 8501 is already in use:</p> <pre><code>streamlit run dashboard/dashboard_app.py --server.port 8503\n</code></pre>"},{"location":"archived/deploy-dashboard/#dashboard-structure","title":"Dashboard Structure","text":""},{"location":"archived/deploy-dashboard/#file-organization","title":"File Organization","text":"<pre><code>tm2py_utils/summary/validation/\n\u251c\u2500\u2500 dashboard/\n\u2502   \u251c\u2500\u2500 dashboard_app.py           # Main Streamlit app\n\u2502   \u251c\u2500\u2500 dashboard-households.yaml  # Household charts config\n\u2502   \u251c\u2500\u2500 dashboard-population.yaml  # Population charts config\n\u2502   \u251c\u2500\u2500 dashboard-commute.yaml     # Work location charts config\n\u2502   \u251c\u2500\u2500 dashboard-activity-patterns.yaml  # CDAP charts config\n\u2502   \u251c\u2500\u2500 dashboard-tours.yaml       # Tour charts config\n\u2502   \u251c\u2500\u2500 dashboard-trips.yaml       # Trip charts config\n\u2502   \u251c\u2500\u2500 dashboard-time-of-day.yaml # Time distribution charts config\n\u2502   \u2514\u2500\u2500 dashboard-trip-characteristics.yaml  # Trip distance/duration\n\u251c\u2500\u2500 outputs/\n\u2502   \u2514\u2500\u2500 dashboard/\n\u2502       \u251c\u2500\u2500 *.csv                  # Combined summary CSVs\n\u2502       \u2514\u2500\u2500 dashboard/             # (Optional) Copied CSVs for deployment\n</code></pre>"},{"location":"archived/deploy-dashboard/#tab-structure","title":"Tab Structure","text":"<p>The dashboard has 8 tabs, each configured by a YAML file:</p> Tab Config File Content Households <code>dashboard-households.yaml</code> Auto ownership, household size Population <code>dashboard-population.yaml</code> Person demographics, CDAP Commute <code>dashboard-commute.yaml</code> Work location, commute distance Activity Patterns <code>dashboard-activity-patterns.yaml</code> Daily activity patterns by person type Tours <code>dashboard-tours.yaml</code> Tour frequency, mode, purpose Trips <code>dashboard-trips.yaml</code> Trip mode, purpose Time of Day <code>dashboard-time-of-day.yaml</code> Tour start/end times Trip Characteristics <code>dashboard-trip-characteristics.yaml</code> Distance, duration distributions"},{"location":"archived/deploy-dashboard/#dashboard-configuration","title":"Dashboard Configuration","text":""},{"location":"archived/deploy-dashboard/#yaml-structure","title":"YAML Structure","text":"<p>Each tab is configured with a YAML file:</p> <pre><code>header:\n  tab: \"Households\"\n  title: \"Household Summary Statistics\"\n  description: \"Household demographics and auto ownership patterns\"\n\nlayout:\n  section_name:\n    - type: bar\n      title: \"Chart Title\"\n      props:\n        dataset: \"auto_ownership_regional.csv\"\n        x: \"num_vehicles\"\n        y: \"share\"\n        groupBy: \"dataset\"\n      description: \"Chart description\"\n</code></pre> <p>Sections:</p> Section Description <code>header</code> Tab metadata (name, title, description) <code>layout</code> Chart definitions grouped by section"},{"location":"archived/deploy-dashboard/#chart-types","title":"Chart Types","text":""},{"location":"archived/deploy-dashboard/#1-bar-chart","title":"1. Bar Chart","text":"<pre><code>- type: bar\n  title: \"Households by Vehicle Ownership\"\n  props:\n    dataset: \"auto_ownership_regional.csv\"\n    x: \"num_vehicles\"\n    y: \"share\"\n    groupBy: \"dataset\"\n</code></pre> <p>Props: - <code>dataset</code> - CSV filename (in <code>outputs/dashboard/</code>) - <code>x</code> - Column for x-axis - <code>y</code> - Column for y-axis (metric) - <code>groupBy</code> - Column for grouping (creates separate bars) - <code>facet</code> - (Optional) Column for faceting (small multiples) - <code>columns</code> - (Optional) Column for sub-grouping within bars</p>"},{"location":"archived/deploy-dashboard/#2-line-chart","title":"2. Line Chart","text":"<pre><code>- type: line\n  title: \"Tour Distance Distribution\"\n  props:\n    dataset: \"tour_distance.csv\"\n    x: \"tour_distance_bin\"\n    y: \"share\"\n    groupBy: \"dataset\"\n</code></pre> <p>Use for: Trends, distributions over continuous dimensions</p>"},{"location":"archived/deploy-dashboard/#3-scatter-plot","title":"3. Scatter Plot","text":"<pre><code>- type: scatter\n  title: \"Tour Mode vs Purpose\"\n  props:\n    dataset: \"tour_mode_by_purpose.csv\"\n    x: \"tour_purpose\"\n    y: \"share\"\n    groupBy: \"tour_mode\"\n</code></pre> <p>Use for: Relationships between two continuous variables</p>"},{"location":"archived/deploy-dashboard/#4-heatmap","title":"4. Heatmap","text":"<pre><code>- type: heatmap\n  title: \"Tour Time of Day Matrix\"\n  props:\n    dataset: \"time_of_day_tours.csv\"\n    x: \"start_period\"\n    y: \"end_period\"\n    z: \"tours\"\n    groupBy: \"dataset\"\n</code></pre> <p>Props: - <code>z</code> - Values for heatmap color intensity</p> <p>Use for: 2D matrices (start time \u00d7 end time, origin \u00d7 destination)</p>"},{"location":"archived/deploy-dashboard/#faceting-small-multiples","title":"Faceting (Small Multiples)","text":"<p>Create separate charts for each category:</p> <pre><code>- type: bar\n  title: \"Auto Ownership by Income\"\n  props:\n    dataset: \"auto_ownership_by_income.csv\"\n    x: \"num_vehicles\"\n    y: \"share\"\n    columns: \"dataset\"\n    facet: \"income_category_bin\"  # One chart per income category\n</code></pre> <p>Result: 4 side-by-side charts (one per income quartile)</p>"},{"location":"archived/deploy-dashboard/#grouping","title":"Grouping","text":"<p>Stack or group bars by a dimension:</p> <pre><code>props:\n  x: \"tour_purpose\"\n  y: \"tours\"\n  groupBy: \"tour_mode\"  # Separate bars for each mode\n</code></pre> <p>Result: Grouped bars showing mode distribution for each purpose</p>"},{"location":"archived/deploy-dashboard/#customizing-charts","title":"Customizing Charts","text":""},{"location":"archived/deploy-dashboard/#adding-a-new-chart","title":"Adding a New Chart","text":"<p>Step 1: Identify the summary CSV</p> <p>Example: <code>auto_ownership_by_county.csv</code></p> <p>Step 2: Choose appropriate YAML file</p> <p>Example: <code>dashboard-households.yaml</code> (for household-related charts)</p> <p>Step 3: Add chart configuration</p> <pre><code>layout:\n  auto_ownership_by_county:  # New section\n    - type: bar\n      title: \"Vehicle Ownership by County\"\n      props:\n        dataset: \"auto_ownership_by_county.csv\"\n        x: \"county_name\"\n        y: \"share\"\n        groupBy: \"num_vehicles\"\n      description: \"Share of households by vehicle ownership in each county\"\n</code></pre> <p>Step 4: Reload dashboard</p> <p>Dashboard auto-reloads when YAML file changes (Streamlit watches for file changes).</p>"},{"location":"archived/deploy-dashboard/#creating-a-new-tab","title":"Creating a New Tab","text":"<p>Step 1: Create new YAML file</p> <p>Example: <code>dashboard-network.yaml</code></p> <pre><code>header:\n  tab: \"Network\"\n  title: \"Network Performance\"\n  description: \"Highway and transit network statistics\"\n\nlayout:\n  congestion:\n    - type: line\n      title: \"VMT by Time Period\"\n      props:\n        dataset: \"vmt_by_period.csv\"\n        x: \"time_period\"\n        y: \"vmt\"\n        groupBy: \"dataset\"\n</code></pre> <p>Step 2: Update <code>dashboard_app.py</code></p> <p>Add to list of dashboard configurations (around line 500):</p> <pre><code>dashboard_configs = [\n    'dashboard-households.yaml',\n    'dashboard-population.yaml',\n    'dashboard-commute.yaml',\n    'dashboard-activity-patterns.yaml',\n    'dashboard-tours.yaml',\n    'dashboard-trips.yaml',\n    'dashboard-time-of-day.yaml',\n    'dashboard-trip-characteristics.yaml',\n    'dashboard-network.yaml',  # NEW\n]\n</code></pre> <p>Step 3: Restart dashboard</p>"},{"location":"archived/deploy-dashboard/#customizing-colors","title":"Customizing Colors","text":"<p>Dashboard uses MTC brand colors defined in <code>dashboard_app.py</code>:</p> <pre><code>MTC_COLORS = {\n    'primary_blue': '#003D7A',\n    'teal': '#00A19A',\n    'orange': '#ED8B00',\n    'purple': '#7A3F93',\n    'green': '#8CC63F',\n    'red': '#E31937',\n}\n</code></pre> <p>To change: Edit color definitions in <code>dashboard_app.py</code> and reload.</p>"},{"location":"archived/deploy-dashboard/#customizing-chart-layout","title":"Customizing Chart Layout","text":"<p>Edit <code>PLOTLY_LAYOUT</code> in <code>dashboard_app.py</code>:</p> <pre><code>PLOTLY_LAYOUT = {\n    'font': {'family': 'Inter, Arial, sans-serif', 'size': 13},\n    'plot_bgcolor': 'rgba(248, 249, 250, 0.3)',\n    'paper_bgcolor': 'white',\n    'margin': {'l': 60, 'r': 20, 't': 50, 'b': 70},\n}\n</code></pre> <p>Customizable: - Font family, size, color - Background colors - Margins - Hover behavior</p>"},{"location":"archived/deploy-dashboard/#example-configurations","title":"Example Configurations","text":""},{"location":"archived/deploy-dashboard/#example-1-simple-bar-chart","title":"Example 1: Simple Bar Chart","text":"<p>Goal: Compare vehicle ownership across datasets</p> <pre><code>- type: bar\n  title: \"Households by Vehicle Ownership\"\n  props:\n    dataset: \"auto_ownership_regional.csv\"\n    x: \"num_vehicles\"\n    y: \"share\"\n    groupBy: \"dataset\"\n  description: \"Regional vehicle ownership distribution\"\n</code></pre> <p>Output: Grouped bars showing share for each vehicle count, grouped by dataset</p>"},{"location":"archived/deploy-dashboard/#example-2-faceted-comparison","title":"Example 2: Faceted Comparison","text":"<p>Goal: Compare income quartiles side-by-side</p> <pre><code>- type: bar\n  title: \"Auto Ownership by Income Category\"\n  props:\n    dataset: \"auto_ownership_by_income.csv\"\n    x: \"num_vehicles\"\n    y: \"share\"\n    columns: \"dataset\"\n    facet: \"income_category_bin\"\n  description: \"Vehicle ownership by income quartile\"\n</code></pre> <p>Output: 4 charts (one per income category), each showing dataset comparison</p>"},{"location":"archived/deploy-dashboard/#example-3-model-vs-acs-comparison","title":"Example 3: Model vs. ACS Comparison","text":"<p>Goal: Compare model to ACS observed data</p> <pre><code>- type: bar\n  title: \"Auto Ownership by Household Size - Model vs ACS\"\n  props:\n    dataset: \"auto_ownership_by_household_size_acs.csv\"\n    x: \"num_persons_agg\"\n    y: \"share\"\n    columns: \"num_vehicles\"\n    groupBy: \"dataset\"\n    facet: \"dataset\"\n  description: \"Vehicle ownership by household size - Model vs ACS 2023\"\n</code></pre> <p>Output: Side-by-side charts comparing model runs to ACS data</p>"},{"location":"archived/deploy-dashboard/#example-4-heatmap-time-matrix","title":"Example 4: Heatmap Time Matrix","text":"<p>Goal: Visualize tour start/end time patterns</p> <pre><code>- type: heatmap\n  title: \"Tour Time-of-Day Matrix\"\n  props:\n    dataset: \"time_of_day_tours.csv\"\n    x: \"start_period\"\n    y: \"end_period\"\n    z: \"tours\"\n    groupBy: \"dataset\"\n  description: \"Tours by departure and arrival time\"\n</code></pre> <p>Output: Heatmap showing tour volume by start time (x) and end time (y)</p>"},{"location":"archived/deploy-dashboard/#running-the-dashboard","title":"Running the Dashboard","text":""},{"location":"archived/deploy-dashboard/#local-development","title":"Local Development","text":"<pre><code># From validation directory\ncd C:\\GitHub\\tm2py-utils\\tm2py_utils\\summary\\validation\nstreamlit run dashboard/dashboard_app.py\n</code></pre> <p>Features: - Auto-reload on file changes - Debug mode shows errors in browser - Ctrl+C to stop</p>"},{"location":"archived/deploy-dashboard/#production-deployment","title":"Production Deployment","text":"<p>For hosting on a server:</p> <pre><code>streamlit run dashboard/dashboard_app.py \\\n  --server.port 8501 \\\n  --server.address 0.0.0.0 \\\n  --server.headless true\n</code></pre> <p>Options: - <code>--server.address 0.0.0.0</code> - Accept connections from any IP - <code>--server.headless true</code> - Run without opening browser - <code>--server.fileWatcherType none</code> - Disable file watching (saves resources)</p>"},{"location":"archived/deploy-dashboard/#using-docker","title":"Using Docker","text":"<p>Create <code>Dockerfile</code>:</p> <pre><code>FROM python:3.9-slim\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY tm2py_utils/ ./tm2py_utils/\nCOPY outputs/dashboard/ ./outputs/dashboard/\n\nEXPOSE 8501\n\nCMD [\"streamlit\", \"run\", \"tm2py_utils/summary/validation/dashboard/dashboard_app.py\", \\\n     \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n</code></pre> <p>Build and run:</p> <pre><code>docker build -t tm2-dashboard .\ndocker run -p 8501:8501 tm2-dashboard\n</code></pre>"},{"location":"archived/deploy-dashboard/#troubleshooting","title":"Troubleshooting","text":""},{"location":"archived/deploy-dashboard/#port-already-in-use","title":"Port Already in Use","text":"<pre><code>ERROR: Port 8501 is already in use\n</code></pre> <p>Solution: Use a different port</p> <pre><code>streamlit run dashboard/dashboard_app.py --server.port 8503\n</code></pre>"},{"location":"archived/deploy-dashboard/#csv-not-found","title":"CSV Not Found","text":"<pre><code>FileNotFoundError: auto_ownership_regional.csv\n</code></pre> <p>Cause: Dashboard looks in <code>outputs/dashboard/</code> directory</p> <p>Solutions: 1. Run summary generation first 2. Check <code>output_directory</code> in <code>validation_config.yaml</code> 3. Verify CSV files exist in output directory</p>"},{"location":"archived/deploy-dashboard/#empty-charts","title":"Empty Charts","text":"<p>Cause: CSV has no data or wrong column names</p> <p>Solutions: 1. Check CSV has data: <code>head auto_ownership_regional.csv</code> 2. Verify column names match YAML <code>props</code> exactly 3. Check for case sensitivity (<code>num_vehicles</code> \u2260 <code>Num_Vehicles</code>)</p>"},{"location":"archived/deploy-dashboard/#module-not-found","title":"Module Not Found","text":"<pre><code>ModuleNotFoundError: No module named 'streamlit'\n</code></pre> <p>Solution: Activate correct conda environment</p> <pre><code>conda activate tm2py-utils\n</code></pre>"},{"location":"archived/deploy-dashboard/#encoding-errors","title":"Encoding Errors","text":"<pre><code>UnicodeDecodeError: 'charmap' codec can't decode\n</code></pre> <p>Fixed in code - dashboard_app.py uses <code>encoding='utf-8'</code> for YAML files</p>"},{"location":"archived/deploy-dashboard/#advanced-features","title":"Advanced Features","text":""},{"location":"archived/deploy-dashboard/#filtering-by-dataset","title":"Filtering by Dataset","text":"<p>Dashboard includes sidebar filter:</p> <pre><code># In dashboard_app.py\ndatasets = st.sidebar.multiselect(\n    \"Select Datasets\",\n    options=df['dataset'].unique(),\n    default=df['dataset'].unique()\n)\n</code></pre> <p>Users can toggle datasets on/off to focus comparisons.</p>"},{"location":"archived/deploy-dashboard/#exporting-charts","title":"Exporting Charts","text":"<p>Plotly charts include built-in export: - Hover over chart - Click camera icon - Save as PNG</p>"},{"location":"archived/deploy-dashboard/#custom-variable-labels","title":"Custom Variable Labels","text":"<p>Edit <code>data_model/variable_labels.yaml</code>:</p> <pre><code>num_vehicles: \"Number of Vehicles\"\nnum_persons: \"Household Size\"\ntour_mode: \"Tour Mode\"\n</code></pre> <p>Dashboard uses these labels for axis titles and legends.</p>"},{"location":"archived/deploy-dashboard/#categorical-ordering","title":"Categorical Ordering","text":"<p>Control order of categorical variables:</p> <pre><code>categorical_order:\n  tour_purpose:\n    - Work\n    - School\n    - University\n    - Shop\n    - Discretionary\n  income_category_bin:\n    - &lt;30K\n    - 30-60K\n    - 60-100K\n    - 100-150K\n    - 150K+\n</code></pre> <p>Charts display categories in this order (not alphabetical).</p>"},{"location":"archived/deploy-dashboard/#performance-optimization","title":"Performance Optimization","text":""},{"location":"archived/deploy-dashboard/#large-datasets","title":"Large Datasets","text":"<p>For very large CSVs (&gt;100MB):</p> <p>Option 1: Filter in query</p> <pre><code># In dashboard_app.py\ndf = pd.read_csv(csv_path)\ndf = df[df['county'] == selected_county]  # Filter before plotting\n</code></pre> <p>Option 2: Use Parquet instead of CSV</p> <pre><code># Convert CSV to Parquet\ndf = pd.read_csv('large_summary.csv')\ndf.to_parquet('large_summary.parquet')\n\n# Load in dashboard\ndf = pd.read_parquet('large_summary.parquet')\n</code></pre>"},{"location":"archived/deploy-dashboard/#caching","title":"Caching","text":"<p>Streamlit caches data automatically. For explicit caching:</p> <pre><code>@st.cache_data\ndef load_large_dataset(path):\n    return pd.read_csv(path)\n</code></pre>"},{"location":"archived/deploy-dashboard/#alternative-visualization-tools","title":"Alternative Visualization Tools","text":"<p>While the system provides a Streamlit dashboard, summary CSVs can be used with any BI tool:</p>"},{"location":"archived/deploy-dashboard/#tableau","title":"Tableau","text":"<ol> <li>Load combined CSVs as data sources</li> <li>Use <code>dataset</code> column for filtering</li> <li>Create calculated fields for custom metrics</li> </ol>"},{"location":"archived/deploy-dashboard/#power-bi","title":"Power BI","text":"<ol> <li>Import CSVs via \"Get Data\" \u2192 \"Text/CSV\"</li> <li>Use <code>dataset</code> as slicer</li> <li>Create measures with DAX</li> </ol>"},{"location":"archived/deploy-dashboard/#r-shiny","title":"R Shiny","text":"<pre><code>library(shiny)\nlibrary(ggplot2)\n\ndata &lt;- read.csv(\"auto_ownership_regional.csv\")\n\nui &lt;- fluidPage(\n  selectInput(\"dataset\", \"Dataset\", unique(data$dataset)),\n  plotOutput(\"plot\")\n)\n\nserver &lt;- function(input, output) {\n  output$plot &lt;- renderPlot({\n    filtered &lt;- data[data$dataset == input$dataset,]\n    ggplot(filtered, aes(x=num_vehicles, y=share)) +\n      geom_bar(stat=\"identity\")\n  })\n}\n\nshinyApp(ui, server)\n</code></pre>"},{"location":"archived/deploy-dashboard/#observable","title":"Observable","text":"<p>Upload CSVs to Observable and create interactive notebooks with D3.js.</p>"},{"location":"archived/deploy-dashboard/#next-steps","title":"Next Steps","text":"<ul> <li>Generate Summaries - Create summary CSVs for dashboard</li> <li>Custom Summaries - Define new summaries to visualize</li> <li>External Data Integration - Add ACS/CTPP comparisons</li> <li>Validation System Overview - Return to main guide</li> </ul>"},{"location":"archived/deploy-dashboard/#resources","title":"Resources","text":"<p>Streamlit Documentation: - https://docs.streamlit.io/ - https://docs.streamlit.io/library/api-reference</p> <p>Plotly Documentation: - https://plotly.com/python/ - https://plotly.com/python/bar-charts/ - https://plotly.com/python/facet-plots/</p> <p>Example Dashboards: - Streamlit Gallery: https://streamlit.io/gallery - Plotly Examples: https://plotly.com/python/</p>"},{"location":"archived/deploy-dashboard/#summary","title":"Summary","text":"<p>To launch dashboard: <pre><code>conda activate tm2py-utils\ncd C:\\GitHub\\tm2py-utils\\tm2py_utils\\summary\\validation\nstreamlit run dashboard/dashboard_app.py\n</code></pre></p> <p>To customize: 1. Edit YAML files in <code>dashboard/</code> directory 2. Dashboard auto-reloads on save 3. Add new tabs by creating new YAML files</p> <p>Key files: - <code>dashboard_app.py</code> - Main application - <code>dashboard-*.yaml</code> - Chart configurations - <code>outputs/dashboard/*.csv</code> - Data files</p> <p>The dashboard is fully configurable via YAML - no Python coding required for most customizations.</p>"},{"location":"archived/validation-development/","title":"Validation System Development Tasks","text":"<p>This page tracks ongoing development work for the validation summary system. These are tasks that need to be completed to make the system fully functional for TM2.2 calibration and validation.</p>"},{"location":"archived/validation-development/#1-update-data-model-with-new-postprocessing-fields","title":"1. Update Data Model with New Postprocessing Fields","text":""},{"location":"archived/validation-development/#current-status","title":"Current Status","text":"<p>The CTRAMP data model is being enhanced with additional fields from model postprocessing. The current data model (documented in data-model.md) reflects the core CTRAMP outputs, but several important fields are missing.</p>"},{"location":"archived/validation-development/#required-updates","title":"Required Updates","text":"<p>New fields being added to model outputs: - Income categories (aggregated from continuous income) - Distance bins for tours and trips - Time period aggregations - Mode aggregations (Auto/Transit/Active) - Geography lookups (TAZ \u2192 County, MAZ \u2192 TAZ) - Additional person/household categorizations</p>"},{"location":"archived/validation-development/#task-update-data-model-documentation","title":"Task: Update Data Model Documentation","text":"<p>When new fields are added to the postprocessing pipeline, you must update the data model documentation to reflect the changes.</p> <p>Steps:</p> <ol> <li> <p>Identify new fields in the postprocessed output files    <pre><code># Check actual columns in model outputs\ncd C:\\model_runs\\2023_base_year\\ctramp_output\npython -c \"import pandas as pd; df = pd.read_csv('householdData_1.csv', nrows=1); print(df.columns.tolist())\"\n</code></pre></p> </li> <li> <p>Update data-model.md with new field definitions</p> </li> </ol> <p>Add new fields to the appropriate table (households, persons, tours, trips):</p> <pre><code>### New Postprocessed Fields\n\n| Column | Type | Description | Values/Range | Required |\n|--------|------|-------------|--------------|----------|\n| income_category | string | Household income quartile | Q1, Q2, Q3, Q4 | Optional |\n| county_name | string | County name from TAZ lookup | Alameda, Contra Costa, etc. | Optional |\n| tour_distance_bin | string | Binned tour distance | 0-5, 5-10, 10-25, 25+ | Optional |\n</code></pre> <ol> <li>Document derivation logic</li> </ol> <p>Explain how new fields are calculated:</p> <pre><code>**Income Category Derivation:**\n- Q1: income &lt; $30,000\n- Q2: $30,000 - $60,000\n- Q3: $60,000 - $100,000\n- Q4: $100,000+\n\n**County Name Derivation:**\n- Lookup from TAZ to County using geography crosswalk file\n- Requires `taz_geography.csv` with columns: `taz`, `county_name`\n</code></pre> <ol> <li>Update example schemas</li> </ol> <p>Modify the sample CSV structure to include new fields:</p> <pre><code>hh_id,income,income_category,taz,county_name,num_persons,num_workers,num_vehicles\n1,45000,Q2,1001,Alameda,2,1,1\n</code></pre> <ol> <li>Update summary configurations that use new fields</li> </ol> <p>If summaries reference new fields, update <code>validation_config.yaml</code>:</p> <pre><code>summaries:\n  - name: \"auto_ownership_by_income_category\"\n    data_source: \"households\"\n    group_by:\n      - \"income_category\"  # NEW FIELD\n      - \"num_vehicles\"\n</code></pre>"},{"location":"archived/validation-development/#affected-components","title":"Affected Components","text":"<ul> <li>\u270f\ufe0f data-model.md - Add new field definitions</li> <li>\u270f\ufe0f validation_config.yaml - Update summaries using new fields</li> <li>\u270f\ufe0f custom-summaries.md - Add examples using new fields</li> <li>\u270f\ufe0f Postprocessing scripts - Document where fields are created</li> </ul>"},{"location":"archived/validation-development/#2-prepare-2023-household-travel-survey-data","title":"2. Prepare 2023 Household Travel Survey Data","text":""},{"location":"archived/validation-development/#current-status_1","title":"Current Status","text":"<p>The 2023 household travel survey data is being prepared for validation. This survey provides observed trip-making behavior for comparison with model outputs.</p>"},{"location":"archived/validation-development/#required-format","title":"Required Format","text":"<p>The survey data must be transformed to exactly match the CTRAMP data model (see data-model.md). This is a non-negotiable requirement - the validation system expects identical schemas.</p>"},{"location":"archived/validation-development/#task-convert-survey-to-ctramp-format","title":"Task: Convert Survey to CTRAMP Format","text":"<p>You must create 4 CSV files with the same structure as CTRAMP model outputs:</p>"},{"location":"archived/validation-development/#file-1-householddata_surveycsv","title":"File 1: <code>householdData_survey.csv</code>","text":"<p>Required columns (at minimum):</p> Column Description Notes <code>hh_id</code> Household ID Unique identifier from survey <code>home_taz</code> Home TAZ Map survey home location to TM2.2 TAZ system <code>income</code> Annual household income Continuous dollar amount <code>num_persons</code> Household size Count of persons <code>num_workers</code> Number of workers Count of workers <code>num_vehicles</code> Number of vehicles Count of vehicles <code>building_type</code> Housing type 1=Single Family, 2=Multi-Family, 3=Mobile Home, 4=Other <code>sample_rate</code> Sample expansion factor Survey weight for expanding to population <p>Derived fields (if using new postprocessed data model):</p> Column Description Derivation <code>income_category</code> Income quartile Bin <code>income</code> into Q1/Q2/Q3/Q4 <code>county_name</code> County name Map <code>home_taz</code> to county <code>num_persons_agg</code> Aggregated household size Aggregate to 1/2/3/4+ <p>Example transformation:</p> <pre><code>import pandas as pd\n\n# Load survey household data\nsurvey_hh = pd.read_csv('survey_households_raw.csv')\n\n# Map to CTRAMP format\nctramp_hh = pd.DataFrame({\n    'hh_id': survey_hh['household_id'],\n    'home_taz': survey_hh['home_taz_tm22'],  # Must use TM2.2 TAZ system\n    'income': survey_hh['annual_income'],\n    'num_persons': survey_hh['household_size'],\n    'num_workers': survey_hh['workers'],\n    'num_vehicles': survey_hh['vehicles'],\n    'building_type': survey_hh['housing_type'].map({\n        'Single Family': 1,\n        'Multi-Family': 2,\n        'Mobile Home': 3,\n        'Other': 4\n    }),\n    'sample_rate': survey_hh['expansion_factor']  # Survey weight\n})\n\n# Add derived fields (if using enhanced data model)\nctramp_hh['income_category'] = pd.cut(ctramp_hh['income'], \n    bins=[0, 30000, 60000, 100000, float('inf')],\n    labels=['Q1', 'Q2', 'Q3', 'Q4'])\n\nctramp_hh['num_persons_agg'] = ctramp_hh['num_persons'].apply(\n    lambda x: '4+' if x &gt;= 4 else str(x)\n)\n\n# Save in CTRAMP format\nctramp_hh.to_csv('householdData_survey.csv', index=False)\n</code></pre>"},{"location":"archived/validation-development/#file-2-persondata_surveycsv","title":"File 2: <code>personData_survey.csv</code>","text":"<p>Required columns:</p> Column Description Notes <code>person_id</code> Person ID Unique identifier <code>hh_id</code> Household ID Links to household file <code>person_num</code> Person number in household 1, 2, 3, etc. <code>person_type</code> Person type code 1-8 (see data-model.md) <code>age</code> Age in years Continuous <code>gender</code> Gender 1=Male, 2=Female <code>work_taz</code> Work location TAZ -1 if not working <code>school_taz</code> School location TAZ -1 if not in school <p>Person type mapping (critical for CDAP summaries):</p> <pre><code>def map_person_type(row):\n    \"\"\"Map survey person characteristics to CTRAMP person_type codes\"\"\"\n    if row['age'] &lt; 5:\n        return 8  # Preschool\n    elif row['age'] &lt; 16:\n        return 7 if row['enrolled_in_school'] else 8  # School age\n    elif row['age'] &lt; 18:\n        return 6  # Driving age student\n    elif row['full_time_worker']:\n        return 1  # Full-time worker\n    elif row['part_time_worker']:\n        return 2  # Part-time worker\n    elif row['enrolled_in_university']:\n        return 3  # University student\n    elif row['age'] &gt;= 65:\n        return 5  # Retired\n    else:\n        return 4  # Non-working adult\n\nsurvey_persons['person_type'] = survey_persons.apply(map_person_type, axis=1)\n</code></pre>"},{"location":"archived/validation-development/#file-3-indivtourdata_surveycsv","title":"File 3: <code>indivTourData_survey.csv</code>","text":"<p>Required columns:</p> Column Description Notes <code>tour_id</code> Tour ID Unique identifier <code>person_id</code> Person ID Links to person file <code>hh_id</code> Household ID Links to household file <code>tour_purpose</code> Primary tour purpose Work, School, Shop, Discretionary, etc. <code>tour_mode</code> Primary tour mode 1-17 (see data-model.md) <code>start_period</code> Departure time period 1-40 (half-hour periods) <code>end_period</code> Return time period 1-40 <code>tour_distance</code> Total tour distance (miles) Round-trip distance <code>num_ob_stops</code> Outbound stops Intermediate stops before primary destination <code>num_ib_stops</code> Inbound stops Intermediate stops on return <p>Mode code mapping (see data-model.md for full list):</p> <pre><code>mode_mapping = {\n    'Drive Alone': 1,\n    'Shared Ride 2': 2,\n    'Shared Ride 3+': 3,\n    'Walk to Transit': 4,\n    'Drive to Transit': 5,\n    'Walk': 6,\n    'Bike': 7,\n    # ... (see data-model.md for codes 8-17)\n}\n\nsurvey_tours['tour_mode'] = survey_tours['mode_description'].map(mode_mapping)\n</code></pre> <p>Time period mapping (5:00 AM = period 1, 30-minute increments):</p> <pre><code>def time_to_period(time_str):\n    \"\"\"Convert time string to period number (1-40)\"\"\"\n    hour, minute = map(int, time_str.split(':'))\n    total_minutes = (hour - 5) * 60 + minute  # Minutes since 5:00 AM\n    period = (total_minutes // 30) + 1\n    return max(1, min(40, period))  # Clamp to 1-40\n\nsurvey_tours['start_period'] = survey_tours['departure_time'].apply(time_to_period)\nsurvey_tours['end_period'] = survey_tours['return_time'].apply(time_to_period)\n</code></pre>"},{"location":"archived/validation-development/#file-4-indivtripdata_surveycsv","title":"File 4: <code>indivTripData_survey.csv</code>","text":"<p>Required columns:</p> Column Description Notes <code>trip_id</code> Trip ID Unique identifier <code>person_id</code> Person ID Links to person file <code>hh_id</code> Household ID Links to household file <code>tour_id</code> Parent tour ID Links to tour file <code>trip_mode</code> Trip mode 1-17 (same codes as tour_mode) <code>trip_purpose</code> Trip purpose Work, School, Shop, Eat, Discretionary, etc. <code>origin_taz</code> Origin TAZ Trip origin <code>destination_taz</code> Destination TAZ Trip destination <code>trip_distance</code> Trip distance (miles) One-way distance <code>depart_period</code> Departure time period 1-40"},{"location":"archived/validation-development/#integration-with-validation-system","title":"Integration with Validation System","text":"<p>Once survey data is in CTRAMP format, add to <code>validation_config.yaml</code>:</p> <pre><code>input_directories:\n  - path: \"C:/model_runs/2023_base_year\"\n    name: \"2023_base_year\"\n    display_name: \"2023 Base Year Model\"\n    source_type: \"model\"\n    iteration: 1\n\n  - path: \"C:/survey_data/2023_household_travel_survey\"\n    name: \"2023_survey\"\n    display_name: \"2023 Household Travel Survey\"\n    source_type: \"survey\"\n    iteration: 1  # Use _1.csv suffix or omit iteration for no suffix\n</code></pre> <p>The system will then: 1. Load survey data alongside model outputs 2. Apply same aggregations and binning 3. Compare model vs. survey in dashboard</p>"},{"location":"archived/validation-development/#critical-notes","title":"Critical Notes","text":"<p>\u26a0\ufe0f Geography Alignment: Survey TAZs must match TM2.2 TAZ system exactly. If survey uses different geography, you must crosswalk locations.</p> <p>\u26a0\ufe0f Sample Weights: <code>sample_rate</code> is critical for accurate aggregation. Survey weights expand sample to represent full population.</p> <p>\u26a0\ufe0f Mode/Purpose Codes: Must use exact CTRAMP codes. Do NOT create custom categories - map to standard codes.</p> <p>\u26a0\ufe0f Intersects with Task 1: If new postprocessed fields are added to data model, survey data must include those fields too (e.g., <code>income_category</code>, <code>county_name</code>).</p>"},{"location":"archived/validation-development/#3-fix-non-working-summaries","title":"3. Fix Non-Working Summaries","text":""},{"location":"archived/validation-development/#current-status_2","title":"Current Status","text":"<p>Some summaries defined in <code>validation_config.yaml</code> have errors and do not generate output correctly. These will be obvious on the dashboard - charts will be missing or show errors.</p>"},{"location":"archived/validation-development/#task-debug-and-fix-broken-summaries","title":"Task: Debug and Fix Broken Summaries","text":"<p>Steps to identify broken summaries:</p> <ol> <li>Run full summary generation</li> </ol> <pre><code>cd C:\\GitHub\\tm2py-utils\\tm2py_utils\\summary\\validation\nconda activate tm2py-utils\npython -m tm2py_utils.summary.validation.summaries.run_all --config validation_config.yaml\n</code></pre> <ol> <li>Check console output for errors</li> </ol> <p>Look for:    - <code>KeyError</code> - Missing column in data    - <code>ValueError</code> - Invalid binning or grouping    - <code>FileNotFoundError</code> - Missing input files    - Empty DataFrames - No data after filtering</p> <ol> <li>Identify missing output files</li> </ol> <pre><code>cd outputs/dashboard\nGet-ChildItem *.csv | Measure-Object  # Should be 25 files\n</code></pre> <p>Compare to expected summaries in <code>validation_config.yaml</code>.</p> <ol> <li>Debug specific summary</li> </ol> <p>For each broken summary, check:</p> <p>a) Column names match data model</p> <pre><code>summaries:\n  - name: \"broken_summary\"\n    group_by:\n      - \"tour_mode\"  # Does this column exist in indivTourData_1.csv?\n</code></pre> <p>Fix: Use actual column name from data model</p> <p>b) Binning spec references valid columns</p> <pre><code>binning_specs:\n  tour_distance_bins:\n    column: \"tour_distance\"  # Does this column exist?\n    bins: [0, 5, 10, 25, 100]\n</code></pre> <p>Fix: Add missing column to data model (Task 1) or remove binning</p> <p>c) Aggregation spec references valid categories</p> <pre><code>aggregation_specs:\n  mode_groups:\n    column: \"tour_mode\"\n    mapping:\n      Auto: [1, 2, 3]  # Are these valid tour_mode codes?\n</code></pre> <p>Fix: Use correct mode codes from data-model.md</p> <p>d) Filters use valid syntax</p> <pre><code>summaries:\n  - name: \"commute_tours\"\n    filter: \"tour_purpose == 'Work'\"  # Quotes correct? Column exists?\n</code></pre> <p>Fix: Use pandas query syntax, check column names</p> <ol> <li>Test fix</li> </ol> <p>Run single summary to verify:</p> <pre><code>from tm2py_utils.summary.validation.summaries.run_all import generate_summary\n\n# Test specific summary\ngenerate_summary('broken_summary', config)\n</code></pre>"},{"location":"archived/validation-development/#common-issues","title":"Common Issues","text":"Error Cause Fix <code>KeyError: 'tour_distance'</code> Column doesn't exist in data Add to data model (Task 1) or remove from config <code>Empty DataFrame after groupby</code> Filter too restrictive Check filter syntax, verify data exists <code>ValueError: bins must be monotonic</code> Invalid bin edges Fix bin specification in <code>binning_specs</code> <code>No observed data for summary</code> Missing observed_summaries config Add external data (Task 5) or remove comparison"},{"location":"archived/validation-development/#expected-output","title":"Expected Output","text":"<p>After fixes, all 25 summaries should generate without errors:</p> <pre><code>Processing summary: auto_ownership_regional... \u2713\nProcessing summary: auto_ownership_by_county... \u2713\nProcessing summary: auto_ownership_by_household_size... \u2713\n...\nAll summaries completed successfully!\n</code></pre>"},{"location":"archived/validation-development/#4-build-additional-summaries-from-calibrationvalidation-spreadsheet","title":"4. Build Additional Summaries from Calibration/Validation Spreadsheet","text":""},{"location":"archived/validation-development/#current-status_3","title":"Current Status","text":"<p>The system has 25 pre-configured summaries, but the calibration/validation spreadsheet lists additional validation targets that need summary generation.</p>"},{"location":"archived/validation-development/#task-add-new-summaries-from-spreadsheet","title":"Task: Add New Summaries from Spreadsheet","text":"<p>Steps:</p> <ol> <li>Review calibration/validation spreadsheet</li> </ol> <p>Identify targets not currently covered by the 25 summaries. Look for:    - Additional geography breakdowns (e.g., by district, superdistrict)    - New cross-tabulations (e.g., mode by income AND household size)    - Time-of-day summaries not yet implemented    - Trip length distributions by purpose/mode combinations</p> <ol> <li>Design summary configuration</li> </ol> <p>For each new target, create a summary specification. See custom-summaries.md for examples.</p> <p>Example: Add \"Trip Mode by Income and Household Size\"</p> <pre><code>summaries:\n  - name: \"trip_mode_by_income_household_size\"\n    description: \"Trip mode shares by income category and household size\"\n    data_source: \"trips\"\n    group_by:\n      - \"income_category\"  # Requires Task 1 - new field\n      - \"num_persons_agg\"\n      - \"trip_mode\"\n    metrics:\n      - column: \"trip_id\"\n        aggregation: \"count\"\n        output_name: \"trips\"\n    share_within:\n      - [\"income_category\", \"num_persons_agg\"]\n    weight_column: \"sample_rate\"\n    aggregation_specs:\n      - \"mode_groups\"  # Group modes into Auto/Transit/Active\n      - \"household_size_4plus\"\n</code></pre> <ol> <li>Add required binning/aggregation specs</li> </ol> <p>If new summary requires custom bins or aggregations:</p> <pre><code>binning_specs:\n  income_quartiles:  # For income_category\n    column: \"income\"\n    bins: [0, 30000, 60000, 100000, 999999]\n    labels: [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n    output_column: \"income_category\"\n\naggregation_specs:\n  mode_groups:\n    column: \"trip_mode\"\n    mapping:\n      Auto: [1, 2, 3]\n      Transit: [4, 5, 6, 7, 8, 9, 10, 11, 12]\n      Active: [13, 14]\n    output_column: \"mode_group\"\n</code></pre> <ol> <li>Test new summary</li> </ol> <pre><code># Run validation with new summary added\npython -m tm2py_utils.summary.validation.summaries.run_all --config validation_config.yaml\n\n# Check output\ncd outputs/dashboard\nGet-Content trip_mode_by_income_household_size.csv | Select-Object -First 10\n</code></pre> <ol> <li>Add to dashboard (if desired)</li> </ol> <p>Create chart configuration in appropriate dashboard YAML:</p> <pre><code># In dashboard-trips.yaml\nlayout:\n  trip_mode_by_income:\n    - type: bar\n      title: \"Trip Mode by Income and Household Size\"\n      props:\n        dataset: \"trip_mode_by_income_household_size.csv\"\n        x: \"income_category\"\n        y: \"share\"\n        groupBy: \"mode_group\"\n        facet: \"num_persons_agg\"\n      description: \"Trip mode shares across income categories, by household size\"\n</code></pre>"},{"location":"archived/validation-development/#prioritization","title":"Prioritization","text":"<p>High Priority (required for calibration): - VMT by facility type and time period - Transit boardings by line and time period - Work location by residence district - Mode shares for work and school tours</p> <p>Medium Priority (validation targets): - Trip length distributions by mode and purpose - Activity participation rates by person type - Auto occupancy by purpose - Park-and-ride usage</p> <p>Low Priority (nice to have): - Detailed origin-destination patterns - Toll facility usage - Non-motorized trip characteristics</p>"},{"location":"archived/validation-development/#documentation","title":"Documentation","text":"<p>After adding new summaries, update generate-summaries.md:</p> <pre><code>### Additional Summaries (Custom Configured)\n\n| Summary | Description | Geography | Source |\n|---------|-------------|-----------|--------|\n| trip_mode_by_income_household_size | Trip mode shares by income and household size | Regional | Trips |\n| vmt_by_facility_time | VMT by facility type and time period | Regional | Network |\n</code></pre>"},{"location":"archived/validation-development/#5-reformat-ctpp-data-to-match-system","title":"5. Reformat CTPP Data to Match System","text":""},{"location":"archived/validation-development/#current-status_4","title":"Current Status","text":"<p>Census Transportation Planning Products (CTPP) data provides observed journey-to-work patterns but is not currently formatted for the validation system.</p>"},{"location":"archived/validation-development/#required-format_1","title":"Required Format","text":"<p>CTPP data must be preprocessed into the same format as model summaries - same columns, same categories, same geography. See external-data.md for detailed guidance.</p>"},{"location":"archived/validation-development/#task-create-ctpp-preprocessing-script","title":"Task: Create CTPP Preprocessing Script","text":"<p>Goal: Convert CTPP tables into CSV files that match model summary output format.</p>"},{"location":"archived/validation-development/#step-1-identify-relevant-ctpp-tables","title":"Step 1: Identify Relevant CTPP Tables","text":"<p>Key tables for TM2.2 validation:</p> Table Description Validation Use A302100 Workers by Work Location Work location choice A302200 Workers by Mode to Work Commute mode choice A102100 Workers by Residence Home-work flow patterns B302105 Travel Time to Work Commute time distributions"},{"location":"archived/validation-development/#step-2-map-ctpp-geography-to-tm22-geography","title":"Step 2: Map CTPP Geography to TM2.2 Geography","text":"<p>CTPP uses Census geographies (tracts, PUMAs, counties). TM2.2 uses TAZs.</p> <p>Create geography crosswalk:</p> <pre><code>import pandas as pd\n\n# Load CTPP data (by county)\nctpp = pd.read_csv('ctpp_a302200_workers_by_mode.csv')\n# Columns: county_fips, mode_category, workers\n\n# Load TM2.2 county mapping\ntaz_county = pd.read_csv('taz_to_county.csv')\n# Columns: taz, county_name, county_fips\n\n# Map county_fips to county_name\ncounty_mapping = taz_county[['county_fips', 'county_name']].drop_duplicates()\nctpp = ctpp.merge(county_mapping, on='county_fips')\n</code></pre>"},{"location":"archived/validation-development/#step-3-map-ctpp-categories-to-ctramp-codes","title":"Step 3: Map CTPP Categories to CTRAMP Codes","text":"<p>Mode mapping example:</p> <pre><code># CTPP mode categories\nctpp_mode_mapping = {\n    'Car, truck, or van -- Drove alone': 'Drive Alone',\n    'Car, truck, or van -- Carpooled: 2-person': 'Shared Ride 2',\n    'Car, truck, or van -- Carpooled: 3-or-more': 'Shared Ride 3+',\n    'Public transportation': 'Transit',\n    'Walked': 'Walk',\n    'Bicycle': 'Bike',\n    'Taxicab, motorcycle, or other means': 'Other',\n    'Worked at home': 'Work from Home'\n}\n\nctpp['tour_mode'] = ctpp['mode_category'].map(ctpp_mode_mapping)\n</code></pre> <p>Aggregate to match model summary:</p> <pre><code># Model summary has mode_group aggregation (Auto/Transit/Active)\nmode_group_mapping = {\n    'Drive Alone': 'Auto',\n    'Shared Ride 2': 'Auto',\n    'Shared Ride 3+': 'Auto',\n    'Transit': 'Transit',\n    'Walk': 'Active',\n    'Bike': 'Active',\n    'Other': 'Other',\n    'Work from Home': 'Other'\n}\n\nctpp['mode_group'] = ctpp['tour_mode'].map(mode_group_mapping)\n</code></pre>"},{"location":"archived/validation-development/#step-4-calculate-shares","title":"Step 4: Calculate Shares","text":"<p>Match model summary metric structure:</p> <pre><code># Group by county and mode_group\nctpp_summary = ctpp.groupby(['county_name', 'mode_group']).agg({\n    'workers': 'sum'\n}).reset_index()\n\n# Calculate shares within each county\nctpp_summary['share'] = ctpp_summary.groupby('county_name')['workers'].transform(\n    lambda x: x / x.sum()\n)\n\n# Add dataset identifier\nctpp_summary['dataset'] = 'CTPP 2016-2020'\n</code></pre>"},{"location":"archived/validation-development/#step-5-match-model-summary-column-names","title":"Step 5: Match Model Summary Column Names","text":"<p>Ensure columns match exactly:</p> <pre><code># Model summary: work_mode_by_county.csv\n# Columns: county_name, mode_group, workers, share, dataset\n\nctpp_formatted = ctpp_summary[[\n    'county_name',\n    'mode_group', \n    'workers',\n    'share',\n    'dataset'\n]]\n\n# Save in same format as model summary\nctpp_formatted.to_csv('work_mode_by_county_ctpp.csv', index=False)\n</code></pre>"},{"location":"archived/validation-development/#step-6-add-to-validation-config","title":"Step 6: Add to Validation Config","text":"<pre><code>observed_summaries:\n  - name: \"work_mode_by_county_ctpp\"\n    file_path: \"C:/validation_data/ctpp/work_mode_by_county_ctpp.csv\"\n    description: \"CTPP 2016-2020 work mode by county\"\n    dataset_name: \"CTPP 2016-2020\"\n\n    column_mapping:\n      dimensions:\n        county_name: \"county_name\"\n        mode_group: \"mode_group\"\n      metrics:\n        workers: \"workers\"\n        share: \"share\"\n</code></pre>"},{"location":"archived/validation-development/#ctpp-tables-to-process","title":"CTPP Tables to Process","text":"<p>Priority 1 (commute patterns): - A302200: Mode to work by residence - A302100: Workers by workplace - B302105: Travel time to work</p> <p>Priority 2 (demographics): - A101102: Household size - A101103: Household income - A101104: Vehicles available</p> <p>Priority 3 (detailed flows): - A302106: Residence-workplace flows by mode - A302107: Residence-workplace flows by time</p>"},{"location":"archived/validation-development/#preprocessing-script-template","title":"Preprocessing Script Template","text":"<pre><code>\"\"\"\nCTPP Preprocessing for TM2.2 Validation System\n\nConverts CTPP tables to match model summary format\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\n\ndef process_ctpp_mode_choice(ctpp_file, county_mapping_file, output_file):\n    \"\"\"\n    Process CTPP A302200 (Mode to Work) table\n\n    Args:\n        ctpp_file: Path to CTPP CSV\n        county_mapping_file: Path to county mapping\n        output_file: Path for output CSV\n    \"\"\"\n    # Load CTPP data\n    ctpp = pd.read_csv(ctpp_file)\n\n    # Load county mapping\n    counties = pd.read_csv(county_mapping_file)\n\n    # Map CTPP mode categories to model mode groups\n    mode_mapping = {\n        'Drove alone': 'Auto',\n        'Carpooled': 'Auto',\n        'Public transportation': 'Transit',\n        'Walked': 'Active',\n        'Bicycle': 'Active',\n        'Other': 'Other'\n    }\n\n    ctpp['mode_group'] = ctpp['mode_category'].map(mode_mapping)\n\n    # Join geography\n    ctpp = ctpp.merge(counties, on='county_fips')\n\n    # Aggregate\n    summary = ctpp.groupby(['county_name', 'mode_group']).agg({\n        'workers': 'sum'\n    }).reset_index()\n\n    # Calculate shares\n    summary['share'] = summary.groupby('county_name')['workers'].transform(\n        lambda x: x / x.sum()\n    )\n\n    # Add dataset identifier\n    summary['dataset'] = 'CTPP 2016-2020'\n\n    # Save\n    summary.to_csv(output_file, index=False)\n    print(f\"Saved {len(summary)} rows to {output_file}\")\n\n# Run preprocessing\nprocess_ctpp_mode_choice(\n    ctpp_file='ctpp_a302200_raw.csv',\n    county_mapping_file='taz_to_county.csv',\n    output_file='work_mode_by_county_ctpp.csv'\n)\n</code></pre>"},{"location":"archived/validation-development/#validation","title":"Validation","text":"<p>After preprocessing, verify format matches model summaries:</p> <pre><code># Load model summary\nmodel = pd.read_csv('outputs/dashboard/work_mode_by_county.csv')\n\n# Load CTPP summary\nctpp = pd.read_csv('work_mode_by_county_ctpp.csv')\n\n# Check columns match\nassert set(model.columns) == set(ctpp.columns), \"Column mismatch!\"\n\n# Check categories match\nassert set(model['mode_group'].unique()).issubset(\n    set(ctpp['mode_group'].unique())\n), \"Mode categories don't align!\"\n\nprint(\"\u2713 CTPP format matches model summary\")\n</code></pre>"},{"location":"archived/validation-development/#integration","title":"Integration","text":"<p>Once CTPP is preprocessed, it will automatically appear in dashboard comparisons:</p> <pre><code># Combined file will have both datasets\ncombined = pd.read_csv('outputs/dashboard/work_mode_by_county.csv')\n\nprint(combined['dataset'].unique())\n# Output: ['2023_base_year', 'CTPP 2016-2020']\n</code></pre>"},{"location":"archived/validation-development/#summary-of-tasks","title":"Summary of Tasks","text":"Task Status Priority Effort Dependencies 1. Update data model docs \ud83d\udd04 In Progress High Medium Postprocessing pipeline updates 2. Format 2023 survey data \u23f3 Not Started High High Task 1 (data model changes) 3. Fix broken summaries \u23f3 Not Started High Low None 4. Add new summaries \u23f3 Not Started Medium Medium Task 1, Task 3 5. Reformat CTPP data \u23f3 Not Started Medium Medium Geography crosswalk"},{"location":"archived/validation-development/#recommended-sequence","title":"Recommended Sequence","text":"<ol> <li>Complete Task 1 first - Finalize data model with all postprocessed fields</li> <li>Then Task 2 - Format survey data to match finalized data model</li> <li>Then Task 3 - Fix broken summaries using updated data</li> <li>Parallel: Tasks 4 &amp; 5 - Add new summaries while preprocessing CTPP</li> </ol>"},{"location":"archived/validation-development/#success-criteria","title":"Success Criteria","text":"<p>\u2705 All 4 CTRAMP data files documented with complete schemas \u2705 2023 survey data loads without errors \u2705 All 25 existing summaries generate successfully \u2705 10+ new summaries added from calibration spreadsheet \u2705 CTPP data integrated for model-vs-observed comparison \u2705 Dashboard displays all comparisons without errors  </p>"},{"location":"archived/validation-development/#related-documentation","title":"Related Documentation","text":"<ul> <li>Data Model Reference - Current CTRAMP schema (needs updates per Task 1)</li> <li>Custom Summaries Guide - How to configure new summaries (Task 4)</li> <li>External Data Integration - CTPP preprocessing guidance (Task 5)</li> <li>Generate Summaries - Running validation after changes</li> <li>Validation System Overview - Return to main documentation</li> </ul>"},{"location":"archived/validation-development/#questions-or-issues","title":"Questions or Issues?","text":"<p>If you encounter issues with any of these tasks:</p> <ol> <li>Check error messages in console output - most issues are column name mismatches</li> <li>Review data model - ensure new fields are documented</li> <li>Test incrementally - process one summary at a time, not all 25 at once</li> <li>Verify geography alignment - TAZ systems must match exactly</li> <li>Document as you go - update relevant .md files when making changes</li> </ol>"},{"location":"archived/validation-system/","title":"Validation Summary System","text":"<p>Complete guide to creating, configuring, and deploying validation summaries for Travel Model Two analysis.</p>"},{"location":"archived/validation-system/#overview","title":"Overview","text":"<p>The validation summary system is a data aggregation and comparison pipeline that:</p> <ol> <li>Reads raw data from CTRAMP model outputs or household travel surveys formatted to match the CTRAMP data model</li> <li>Aggregates and transforms data according to user specifications in YAML configuration files</li> <li>Combines datasets into standardized CSVs for cross-scenario and model-vs-observed comparisons</li> <li>Visualizes results through a Streamlit dashboard (or any BI tool - Tableau, PowerBI, Shiny, etc.)</li> </ol>"},{"location":"archived/validation-system/#system-architecture","title":"System Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 INPUT DATA SOURCES (CTRAMP Data Model Format)              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 Model Outputs: householdData_1.csv, personData_1.csv,    \u2502\n\u2502                  indivTourData_1.csv, indivTripData_1.csv   \u2502\n\u2502 \u2022 Travel Surveys: Munged to exactly match CTRAMP format    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 AGGREGATION ENGINE (Config-Driven)                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 Group by dimensions (mode, purpose, county, etc.)        \u2502\n\u2502 \u2022 Apply weights (sample_rate)                              \u2502\n\u2502 \u2022 Bin continuous variables (distance, income, age)         \u2502\n\u2502 \u2022 Aggregate categories (4+ person households)              \u2502\n\u2502 \u2022 Calculate shares within groups                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 EXTERNAL DATA INTEGRATION (Preprocessed to Match Format)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 ACS: Preprocessed household/person summaries             \u2502\n\u2502 \u2022 CTPP: Journey-to-work tables matched to model geography  \u2502\n\u2502 \u2022 Other surveys: Aggregated to same dimensions as model    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OUTPUT: Combined CSVs by Topic Area                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 Single CSV per summary with all datasets                 \u2502\n\u2502 \u2022 Common schema: dimensions + metrics + dataset column     \u2502\n\u2502 \u2022 Ready for any visualization tool                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 VISUALIZATION (Streamlit Dashboard or Your Tool of Choice) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"archived/validation-system/#key-concepts","title":"Key Concepts","text":"<p>Data Model Alignment: All input data must conform to the CTRAMP data model. Model outputs already match this format. Household travel surveys must be transformed to match it exactly (same column names, same codes, same geography).</p> <p>Aggregation Pipeline: The system transforms raw microdata into summary statistics through: - Grouping: Combine records by categorical dimensions - Binning: Convert continuous variables to categories - Aggregation: Map detailed categories to broader groups (e.g., 4+ person households) - Weighting: Apply sample expansion factors - Share calculation: Compute percentages within groups</p> <p>External Data Integration: For comparison with observed data (ACS, CTPP, surveys), you must preprocess external data to match the model's summary format - same columns, same categories, same geography. The system then merges them automatically.</p> <p>Visualization Flexibility: While we provide a Streamlit dashboard, the output CSVs can be used with any BI tool. The value is in the data preparation, not the visualization layer.</p>"},{"location":"archived/validation-system/#what-this-system-does","title":"What This System Does","text":"<p>\u2705 Compiles data from multiple model runs and surveys \u2705 Transforms raw microdata into comparable summary statistics \u2705 Cleans and standardizes data for cross-dataset comparison \u2705 Packages results into analysis-ready CSV files  </p> <p>\u274c Does NOT automatically convert ACS/CTPP raw data (you must preprocess) \u274c Does NOT validate data quality (assumes correct CTRAMP format) \u274c Does NOT provide statistical testing (just descriptive summaries)</p>"},{"location":"archived/validation-system/#quick-navigation","title":"Quick Navigation","text":"<p>Getting Started: - Generate Summaries from Model Runs - Run summaries on CTRAMP outputs, understand system workflow - CTRAMP Data Model Reference - Complete schema for households, persons, tours, trips</p> <p>Advanced Configuration: - Create Custom Summaries - Define new aggregations, binning, and filtering - Integrate External Data - Add ACS, CTPP, or survey comparisons</p> <p>Visualization: - Deploy Dashboard - Launch and customize Streamlit dashboard</p> <p>Development: - Development Tasks &amp; Next Steps - Ongoing work: data model updates, survey formatting, CTPP integration - Code Flow and Execution Guide - Detailed technical documentation for developers</p>"},{"location":"archived/validation-system/#pre-configured-summaries","title":"Pre-Configured Summaries","text":"<p>The system includes 25 pre-configured summaries across 5 topic areas: - Auto Ownership (5 summaries) - Vehicle ownership by household characteristics - Work Location (3 summaries) - Journey to work patterns - CDAP (2 summaries) - Coordinated Daily Activity Patterns - Tours (6 summaries) - Tour frequency, mode, purpose, timing - Trips (9 summaries) - Trip mode, purpose, distance, time-of-day</p>"},{"location":"archived/validation-system/#development-roadmap","title":"Development Roadmap","text":"<p>See Development Tasks &amp; Next Steps for ongoing work including: - Updating the data model with new postprocessed fields - Formatting 2023 household travel survey data - Fixing broken summaries and adding new validation targets - Integrating CTPP journey-to-work data</p>"},{"location":"archived/validation-system/#code-flow","title":"Code Flow","text":"<p>For developers who want to understand how the validation system executes from configuration files to final outputs, see the Code Flow and Execution Guide for detailed technical documentation including class architecture, data processing pipelines, and visual execution diagrams.</p>"},{"location":"archived/validation-system/#quick-start","title":"Quick Start","text":""},{"location":"archived/validation-system/#generate-summaries-from-model-run","title":"Generate Summaries from Model Run","text":"<pre><code>cd tm2py_utils/summary/validation\n\n# Edit validation_config.yaml to point to your model outputs\n# Then generate summaries\npython -m tm2py_utils.summary.validation.summaries.run_all \\\n  --config validation_config.yaml\n</code></pre>"},{"location":"archived/validation-system/#deploy-dashboard","title":"Deploy Dashboard","text":"<pre><code># Copy summaries and launch dashboard\npython run_and_deploy_dashboard.py \\\n  --config validation_config.yaml \\\n  --launch-dashboard\n</code></pre> <p>Visit http://localhost:8501</p>"},{"location":"archived/validation-system/#1-working-with-model-run-data","title":"1. Working with Model Run Data","text":""},{"location":"archived/validation-system/#pointing-to-new-model-outputs","title":"Pointing to New Model Outputs","text":"<p>Edit <code>validation_config.yaml</code> to add your model run directory:</p> <pre><code>input_directories:\n  - path: \"C:/model_runs/2023_base_year\"\n    name: \"2023_base_year\"\n    display_name: \"2023 Base Year\"\n    source_type: \"model\"\n    iteration: 1  # Use iteration 1 files (_1.csv)\n\n  - path: \"C:/model_runs/2050_plan\"\n    name: \"2050_plan\"\n    display_name: \"2050 RTP\"\n    source_type: \"model\"\n    iteration: 1\n</code></pre> <p>Required files in directory: - <code>householdData_1.csv</code> - Household attributes - <code>personData_1.csv</code> - Person attributes - <code>indivTourData_1.csv</code> - Tour-level data - <code>indivTripData_1.csv</code> - Trip-level data - <code>wsLocResults.csv</code> - Work/school locations (optional)</p>"},{"location":"archived/validation-system/#creating-summaries-from-model-data","title":"Creating Summaries from Model Data","text":""},{"location":"archived/validation-system/#example-1-simple-trip-mode-choice","title":"Example 1: Simple Trip Mode Choice","text":"<pre><code>summaries:\n  - name: \"trip_mode_choice\"\n    description: \"Trip mode choice distribution\"\n    data_source: \"individual_trips\"\n    group_by: \"trip_mode\"\n    weight_field: \"sample_rate\"\n    count_name: \"trips\"\n</code></pre> <p>Output: <code>trip_mode_choice.csv</code> <pre><code>trip_mode,trips,share,dataset\nDrive Alone,450000,42.5,2023 Base Year\nCarpool,180000,17.0,2023 Base Year\nTransit,95000,9.0,2023 Base Year\n...\n</code></pre></p>"},{"location":"archived/validation-system/#example-2-tours-by-purpose-and-mode","title":"Example 2: Tours by Purpose and Mode","text":"<pre><code>summaries:\n  - name: \"tour_mode_by_purpose\"\n    description: \"Tour mode choice by purpose\"\n    data_source: \"individual_tours\"\n    group_by: [\"tour_purpose\", \"tour_mode\"]\n    weight_field: \"sample_rate\"\n    count_name: \"tours\"\n    share_within: \"tour_purpose\"\n</code></pre> <p>Output: Each purpose shows mode shares summing to 100%</p>"},{"location":"archived/validation-system/#example-3-trip-distance-binning","title":"Example 3: Trip Distance Binning","text":"<pre><code>summaries:\n  - name: \"trip_distance_distribution\"\n    description: \"Trip distance distribution (binned)\"\n    data_source: \"individual_trips\"\n    group_by: \"trip_distance_bin\"  # Uses binning_specs\n    weight_field: \"sample_rate\"\n    count_name: \"trips\"\n\n# Define bins in binning_specs section\nbinning_specs:\n  trip_distance:\n    bins: [0, 1, 3, 5, 10, 20, 1000]\n    labels: ['0-1', '1-3', '3-5', '5-10', '10-20', '20+']\n</code></pre>"},{"location":"archived/validation-system/#available-data-sources","title":"Available Data Sources","text":"Data Source File Pattern Common Uses <code>households</code> <code>householdData_1.csv</code> Auto ownership, household size, income <code>persons</code> <code>personData_1.csv</code> Person type, age, employment <code>individual_tours</code> <code>indivTourData_1.csv</code> Tour frequency, mode choice, timing <code>individual_trips</code> <code>indivTripData_1.csv</code> Trip mode, purpose, distance, time <code>workplace_school</code> <code>wsLocResults.csv</code> Journey to work, commute patterns"},{"location":"archived/validation-system/#2-working-with-other-data-sources-acs-ctpp-surveys","title":"2. Working with Other Data Sources (ACS, CTPP, Surveys)","text":""},{"location":"archived/validation-system/#overview_1","title":"Overview","text":"<p>Observed data from census sources (ACS, CTPP) and household travel surveys must be preprocessed to match the model output format before use in the validation system.</p> <p>Key requirements for all observed data: - Include <code>dataset</code> column with source name (e.g., \"ACS 2019\", \"2022 Travel Survey\") - Use same column names as model outputs (e.g., <code>trip_mode</code>, not <code>mode</code>) - Match model geography (regional, county, TAZ) - Pre-aggregate to summary level (counts/shares)</p>"},{"location":"archived/validation-system/#adding-preprocessed-observed-data","title":"Adding Preprocessed Observed Data","text":"<p>Once your data is preprocessed to match model format:</p>"},{"location":"archived/validation-system/#step-1-save-preprocessed-files","title":"Step 1: Save Preprocessed Files","text":"<p>Example: <code>survey_trip_mode.csv</code> <pre><code>trip_mode,trips,share,dataset\nDrive Alone,1250,45.2,2022 Travel Survey\nCarpool,380,13.7,2022 Travel Survey\nTransit,295,10.7,2022 Travel Survey\nWalk,520,18.8,2022 Travel Survey\nBike,320,11.6,2022 Travel Survey\n</code></pre></p>"},{"location":"archived/validation-system/#step-2-configure-as-observed-data-source","title":"Step 2: Configure as Observed Data Source","text":"<p>Add to <code>validation_config.yaml</code>:</p> <pre><code>observed_summaries:\n  - name: \"travel_survey_2022\"\n    display_name: \"2022 Travel Survey\"\n    summaries:\n      trip_mode_choice:\n        file: \"C:/data/travel_survey_2022/survey_trip_mode.csv\"\n        columns:\n          trip_mode: \"trip_mode\"\n          trips: \"trips\"\n          share: \"share\"\n</code></pre> <p>How it works: - System loads observed data from specified files - Applies column mapping to match model output format - Adds <code>dataset</code> column with display_name (\"2022 Travel Survey\") - Merges with model summaries automatically by matching name</p> <p>Result: Combined CSV with model and observed data for side-by-side comparison.</p>"},{"location":"archived/validation-system/#3-preprocessing-acs-and-ctpp-data","title":"3. Preprocessing ACS and CTPP Data","text":"<p>Census data (ACS, CTPP) and household travel surveys require preprocessing to match model geography and format. Below are examples of preprocessing workflows.</p>"},{"location":"archived/validation-system/#preprocessing-acs-data","title":"Preprocessing ACS Data","text":""},{"location":"archived/validation-system/#example-auto-ownership-from-acs","title":"Example: Auto Ownership from ACS","text":"<p>Step 1: Download ACS Table B08201</p> <p>Use Census API or data.census.gov: - Table: B08201 (Household Size by Vehicles Available) - Geography: Counties in Bay Area</p> <p>Step 2: Aggregate to Model Geography</p> <p>Python preprocessing script:</p> <pre><code>import pandas as pd\n\n# Load ACS data\nacs = pd.read_csv(\"acs_b08201_raw.csv\")\n\n# Aggregate to region\nregional = acs.groupby('vehicles_available').agg({\n    'estimate': 'sum',\n    'moe': lambda x: (x**2).sum()**0.5  # Combine margins of error\n}).reset_index()\n\n# Calculate shares\nregional['share'] = regional['estimate'] / regional['estimate'].sum() * 100\n\n# Format for validation system\noutput = pd.DataFrame({\n    'auto_ownership': regional['vehicles_available'].map({\n        0: '0 autos',\n        1: '1 auto',\n        2: '2 autos',\n        3: '3+ autos'\n    }),\n    'households': regional['estimate'],\n    'share': regional['share'],\n    'dataset': 'ACS 2019'\n})\n\noutput.to_csv(\"acs_auto_ownership_regional.csv\", index=False)\n</code></pre> <p>Step 3: Configure as Observed Data</p> <pre><code>observed_summaries:\n  - name: \"acs_2019\"\n    display_name: \"ACS 2019\"\n    summaries:\n      auto_ownership_regional:\n        file: \"C:/data/acs_2019/acs_auto_ownership_regional.csv\"\n        columns:\n          num_vehicles: \"num_vehicles\"\n          households: \"households\"\n          share: \"share\"\n</code></pre>"},{"location":"archived/validation-system/#preprocessing-ctpp-data","title":"Preprocessing CTPP Data","text":""},{"location":"archived/validation-system/#example-journey-to-work","title":"Example: Journey to Work","text":"<p>Step 1: Download CTPP Part 3</p> <ul> <li>Table: Means of Transportation to Work</li> <li>Geography: TAZ-to-TAZ or County-to-County</li> </ul> <p>Step 2: Process CTPP Data</p> <pre><code>import pandas as pd\n\n# Load CTPP data\nctpp = pd.read_csv(\"ctpp_journey_to_work.csv\")\n\n# Aggregate modes to match model categories\nmode_mapping = {\n    'Car, truck, or van - drove alone': 'Drive Alone',\n    'Car, truck, or van - carpooled': 'Carpool',\n    'Public transportation': 'Transit',\n    'Walked': 'Walk',\n    'Bicycle': 'Bike',\n    'Taxicab, motorcycle, or other means': 'Other'\n}\n\nctpp['mode'] = ctpp['mode_detailed'].map(mode_mapping)\n\n# Aggregate to region\nregional = ctpp.groupby('mode').agg({\n    'workers': 'sum'\n}).reset_index()\n\nregional['share'] = regional['workers'] / regional['workers'].sum() * 100\nregional['dataset'] = 'CTPP 2012-2016'\n\n# Save\nregional.to_csv(\"ctpp_journey_to_work_mode.csv\", index=False)\n</code></pre>"},{"location":"archived/validation-system/#geography-crosswalks","title":"Geography Crosswalks","text":"<p>For TAZ-level comparisons, create crosswalks:</p> <pre><code># Map Census tracts to model TAZs\ncrosswalk = pd.read_csv(\"tract_to_taz_crosswalk.csv\")\n\nacs_tract = pd.read_csv(\"acs_by_tract.csv\")\n\n# Apportion to TAZ based on population weights\nacs_taz = acs_tract.merge(crosswalk, on='tract')\nacs_taz['value'] = acs_taz['value'] * acs_taz['weight']\nacs_taz = acs_taz.groupby('taz')['value'].sum().reset_index()\n</code></pre>"},{"location":"archived/validation-system/#4-creating-custom-aggregations","title":"4. Creating Custom Aggregations","text":""},{"location":"archived/validation-system/#aggregating-household-size-4-category","title":"Aggregating Household Size (4+ Category)","text":"<p>To match ACS categories that group 4+ person households:</p> <pre><code># Define aggregation mapping\naggregation_specs:\n  num_persons_agg:\n    apply_to: [\"num_persons\"]\n    mapping:\n      1: 1\n      2: 2\n      3: 3\n      4: 4\n      5: 4\n      6: 4\n      7: 4\n      8: 4\n      9: 4\n      10: 4\n\n# Use in summary\nsummaries:\n  - name: \"auto_ownership_by_household_size_acs\"\n    description: \"Vehicle ownership by household size (ACS categories)\"\n    data_source: \"households\"\n    group_by: [\"num_persons_agg\", \"num_vehicles\"]\n    weight_field: \"sample_rate\"\n    count_name: \"households\"\n    share_within: \"num_persons_agg\"\n</code></pre> <p>How it works: - <code>aggregation_specs</code> section defines the mapping - <code>apply_to</code> specifies which column(s) to transform - <code>mapping</code> converts values (5\u21924, 6\u21924, etc.) - System creates new column <code>num_persons_agg</code> automatically - Use aggregated column in <code>group_by</code></p>"},{"location":"archived/validation-system/#5-creating-custom-bins","title":"5. Creating Custom Bins","text":"<p>Binning converts continuous variables to categories for analysis. Define bins once in <code>binning_specs</code>, then reference in summaries.</p>"},{"location":"archived/validation-system/#distance-bins","title":"Distance Bins","text":"<pre><code># Define bins in binning_specs section\nbinning_specs:\n  trip_distance:\n    bins: [0, 1, 3, 5, 10, 20, 1000]\n    labels: ['0-1', '1-3', '3-5', '5-10', '10-20', '20+']\n\n# Use in summary by referencing the binned column\nsummaries:\n  - name: \"trip_distance_distribution\"\n    description: \"Trip distance distribution (binned)\"\n    data_source: \"individual_trips\"\n    group_by: \"trip_distance_bin\"  # Automatically created from trip_distance\n    weight_field: \"sample_rate\"\n    count_name: \"trips\"\n</code></pre> <p>How it works: - System finds <code>trip_distance</code> column in data - Creates <code>trip_distance_bin</code> column using bins and labels - Use <code>_bin</code> suffix in <code>group_by</code></p> <p>Parameters: - <code>bins</code>: Bin boundaries (left-inclusive, right-exclusive) - <code>labels</code>: Display names for bins (one less than bins length)</p>"},{"location":"archived/validation-system/#time-of-day-bins","title":"Time of Day Bins","text":"<pre><code>binning_specs:\n  tour_start_hour:\n    bins: [0, 6, 9, 15, 19, 24]\n    labels: ['Early AM', 'AM Peak', 'Midday', 'PM Peak', 'Evening']\n</code></pre>"},{"location":"archived/validation-system/#age-bins","title":"Age Bins","text":"<pre><code>binning_specs:\n  worker_age:\n    bins: [0, 25, 35, 45, 55, 65, 120]\n    labels: ['&lt;25', '25-34', '35-44', '45-54', '55-64', '65+']\n</code></pre>"},{"location":"archived/validation-system/#income-categories","title":"Income Categories","text":"<pre><code>binning_specs:\n  income_category:\n    bins: [0, 30000, 60000, 100000, 150000, 1000000000]\n    labels: ['&lt;30K', '30-60K', '60-100K', '100-150K', '150K+']\n</code></pre>"},{"location":"archived/validation-system/#using-bins-in-summaries","title":"Using Bins in Summaries","text":"<p><pre><code>summaries:\n  - name: \"trips_by_distance_and_mode\"\n    data_source: \"individual_trips\"\n    group_by: [\"trip_distance_bin\", \"trip_mode\"]\n    weight_field: \"sample_rate\"\n    count_name: \"trips\"\n    share_within: \"trip_distance_bin\"\n</code></pre> custom_summaries:   - name: \"trip_distance_time_matrix\"     group_by: [\"distance_bin\", \"time_bin\", \"trip_mode\"]     bins:       distance:         breaks: [0, 5, 10, 20, 1000]         labels: ['&lt;5mi', '5-10mi', '10-20mi', '20+mi']       time:         breaks: [0, 15, 30, 60, 1000]         labels: ['&lt;15min', '15-30min', '30-60min', '60+min']         source_column: \"trip_time_minutes\" <pre><code>---\n\n## 6. Dashboard Visualization\n\n### Creating Dashboard YAML Files\n\nDashboard tabs are defined in `dashboard/dashboard-N-title.yaml`.\n\n#### Step 1: Create Dashboard File\n\n**Example: `dashboard-8-distance-analysis.yaml`**\n\n```yaml\ntitle: \"Distance Analysis\"\ndescription: \"Trip and tour distance patterns by mode and purpose\"\n\nsections:\n  - title: \"Trip Distance Distribution\"\n    layout: \"two_column\"\n    charts:\n      - type: \"bar\"\n        title: \"Trips by Distance\"\n        data_file: \"trips_by_distance_bin.csv\"\n        x: \"distance_bin\"\n        y: \"trips\"\n        color: \"dataset\"\n        orientation: \"v\"\n        category_orders:\n          distance_bin: ['&lt;1mi', '1-3mi', '3-5mi', '5-10mi', '10-20mi', '20-50mi', '50+mi']\n\n      - type: \"bar\"\n        title: \"Mode Share by Distance\"\n        data_file: \"trip_mode_by_distance.csv\"\n        x: \"distance_bin\"\n        y: \"share\"\n        color: \"trip_mode\"\n        orientation: \"v\"\n        barmode: \"stack\"\n\n  - title: \"Distance by Mode\"\n    layout: \"single_column\"\n    charts:\n      - type: \"box\"\n        title: \"Distance Distribution by Mode\"\n        data_file: \"trip_distance_detailed.csv\"\n        x: \"trip_mode\"\n        y: \"trip_distance_miles\"\n        color: \"dataset\"\n</code></pre></p>"},{"location":"archived/validation-system/#step-2-ensure-required-csvs-exist","title":"Step 2: Ensure Required CSVs Exist","text":"<p>Configure summaries to generate needed files:</p> <pre><code># In validation_config.yaml\ncustom_summaries:\n  - name: \"trips_by_distance_bin\"\n    # ... configuration\n\n  - name: \"trip_mode_by_distance\"\n    # ... configuration\n\n  - name: \"trip_distance_detailed\"\n    # ... configuration\n</code></pre>"},{"location":"archived/validation-system/#step-3-test-dashboard","title":"Step 3: Test Dashboard","text":"<pre><code>cd tm2py_utils/summary/validation\n\n# Generate summaries\npython run_and_deploy_dashboard.py --config validation_config.yaml\n\n# Dashboard auto-discovers new YAML files\n# Visit http://localhost:8501\n</code></pre>"},{"location":"archived/validation-system/#chart-types-reference","title":"Chart Types Reference","text":""},{"location":"archived/validation-system/#bar-chart","title":"Bar Chart","text":"<pre><code>- type: \"bar\"\n  title: \"Chart Title\"\n  data_file: \"summary.csv\"\n  x: \"category\"\n  y: \"value\"\n  color: \"dataset\"\n  orientation: \"h\"  # or \"v\"\n  barmode: \"group\"  # or \"stack\", \"relative\"\n</code></pre>"},{"location":"archived/validation-system/#line-chart","title":"Line Chart","text":"<pre><code>- type: \"line\"\n  title: \"Trend Over Time\"\n  data_file: \"trend.csv\"\n  x: \"year\"\n  y: \"value\"\n  color: \"category\"\n</code></pre>"},{"location":"archived/validation-system/#scatter-plot","title":"Scatter Plot","text":"<pre><code>- type: \"scatter\"\n  title: \"Correlation\"\n  data_file: \"scatter.csv\"\n  x: \"variable1\"\n  y: \"variable2\"\n  color: \"group\"\n  size: \"weight\"\n</code></pre>"},{"location":"archived/validation-system/#box-plot","title":"Box Plot","text":"<pre><code>- type: \"box\"\n  title: \"Distribution\"\n  data_file: \"distribution.csv\"\n  x: \"category\"\n  y: \"value\"\n  color: \"dataset\"\n</code></pre>"},{"location":"archived/validation-system/#faceting-small-multiples","title":"Faceting (Small Multiples)","text":"<p>Create subplots for each category:</p> <pre><code>- type: \"bar\"\n  title: \"Mode Share by County\"\n  data_file: \"mode_by_county.csv\"\n  x: \"trip_mode\"\n  y: \"share\"\n  color: \"dataset\"\n  facet_col: \"county\"\n  facet_col_wrap: 3  # 3 columns of subplots\n</code></pre>"},{"location":"archived/validation-system/#custom-category-ordering","title":"Custom Category Ordering","text":"<pre><code>category_orders:\n  trip_mode: [\"Walk\", \"Bike\", \"Transit\", \"Carpool\", \"Drive Alone\"]\n  tour_purpose: [\"Work\", \"School\", \"Shopping\", \"Maintenance\", \"Eating Out\", \"Social\"]\n  county: [\"San Francisco\", \"Alameda\", \"Contra Costa\", \"Santa Clara\", \"San Mateo\"]\n</code></pre>"},{"location":"archived/validation-system/#custom-labels","title":"Custom Labels","text":"<pre><code>labels:\n  trip_mode: \"Travel Mode\"\n  trips: \"Number of Trips\"\n  share: \"Mode Share (%)\"\n  distance_bin: \"Distance Category\"\n</code></pre>"},{"location":"archived/validation-system/#7-deploying-the-dashboard","title":"7. Deploying the Dashboard","text":""},{"location":"archived/validation-system/#local-deployment","title":"Local Deployment","text":""},{"location":"archived/validation-system/#option-1-full-workflow","title":"Option 1: Full Workflow","text":"<pre><code>cd tm2py_utils/summary/validation\n\n# Generate all summaries and launch\npython run_and_deploy_dashboard.py \\\n  --config validation_config.yaml \\\n  --launch-dashboard\n</code></pre>"},{"location":"archived/validation-system/#option-2-batch-script-windows","title":"Option 2: Batch Script (Windows)","text":"<pre><code># Double-click deploy_dashboard.bat\n# Select option 5: \"Generate and LAUNCH dashboard\"\n</code></pre>"},{"location":"archived/validation-system/#option-3-manual-steps","title":"Option 3: Manual Steps","text":"<pre><code># 1. Generate summaries\npython -m tm2py_utils.summary.validation.summaries.run_all \\\n  --config validation_config.yaml\n\n# 2. Copy to dashboard folder\npython run_and_deploy_dashboard.py \\\n  --config validation_config.yaml \\\n  --skip-generation\n\n# 3. Launch dashboard\nstreamlit run dashboard/dashboard_app.py --server.port 8501\n</code></pre>"},{"location":"archived/validation-system/#streamlit-cloud-deployment","title":"Streamlit Cloud Deployment","text":""},{"location":"archived/validation-system/#step-1-push-to-github","title":"Step 1: Push to GitHub","text":"<pre><code>git add .\ngit commit -m \"Update validation dashboard\"\ngit push origin main\n</code></pre>"},{"location":"archived/validation-system/#step-2-deploy-on-streamlit-cloud","title":"Step 2: Deploy on Streamlit Cloud","text":"<ol> <li>Go to https://share.streamlit.io</li> <li>Click \"New app\"</li> <li>Select repository: <code>BayAreaMetro/tm2py-utils</code></li> <li>Set branch: <code>main</code></li> <li>Set main file path: <code>tm2py_utils/summary/validation/dashboard/dashboard_app.py</code></li> <li>Click \"Deploy\"</li> </ol>"},{"location":"archived/validation-system/#step-3-configure-secrets-if-needed","title":"Step 3: Configure Secrets (if needed)","text":"<p>If using private data sources, add secrets in Streamlit Cloud:</p> <pre><code># .streamlit/secrets.toml\n[data_paths]\nmodel_runs = \"/path/to/data\"\n</code></pre>"},{"location":"archived/validation-system/#server-deployment","title":"Server Deployment","text":"<p>For internal servers:</p> <pre><code># Run in background with nohup\nnohup streamlit run dashboard/dashboard_app.py \\\n  --server.port 8501 \\\n  --server.address 0.0.0.0 &amp;\n\n# Or use screen/tmux\nscreen -S dashboard\nstreamlit run dashboard/dashboard_app.py --server.port 8501\n# Ctrl+A, D to detach\n</code></pre>"},{"location":"archived/validation-system/#8-frequently-asked-questions","title":"8. Frequently Asked Questions","text":""},{"location":"archived/validation-system/#data-issues","title":"Data Issues","text":"<p>Q: \"Column not found\" error when generating summaries</p> <p>A: Check <code>data_model/ctramp_data_model.yaml</code> for correct column mappings:</p> <pre><code>individual_trips:\n  columns:\n    trip_mode: \"trip_mode\"  # Match actual CTRAMP column name\n</code></pre> <p>Q: Summary CSV is empty</p> <p>A: Check filters and data availability: - Verify input directory path in <code>validation_config.yaml</code> - Check if CTRAMP files exist and contain data - Review any <code>filters</code> in summary definition</p> <p>Q: Shares don't sum to 100%</p> <p>A: Check <code>share_within</code> parameter:</p> <pre><code># Shares within each purpose sum to 100%\nshare_within: \"tour_purpose\"\n\n# Without share_within, shares across all rows sum to 100%\n</code></pre>"},{"location":"archived/validation-system/#configuration-issues","title":"Configuration Issues","text":"<p>Q: How do I add a new column to summaries?</p> <p>A: Two steps: 1. Add to <code>ctramp_data_model.yaml</code>: <pre><code>individual_trips:\n  columns:\n    my_new_column: \"ctramp_column_name\"\n</code></pre></p> <ol> <li>Add label to <code>variable_labels.yaml</code>: <pre><code>my_new_column: \"My Column Label\"\n</code></pre></li> </ol> <p>Q: Can I use calculated fields?</p> <p>A: Yes, create them in preprocessing or custom summary logic:</p> <pre><code># Example: Speed calculation\ndf['speed_mph'] = df['trip_distance_miles'] / (df['trip_time_minutes'] / 60)\n</code></pre> <p>Then reference in summary: <pre><code>aggregations:\n  avg_speed:\n    column: \"speed_mph\"\n    agg: \"mean\"\n</code></pre></p>"},{"location":"archived/validation-system/#dashboard-issues","title":"Dashboard Issues","text":"<p>Q: New dashboard tab doesn't appear</p> <p>A: Check: 1. File naming: Must be <code>dashboard-N-title.yaml</code> (with number) 2. Location: Must be in <code>dashboard/</code> directory, not <code>outputs/dashboard/</code> 3. YAML syntax: Validate with <code>python -c \"import yaml; yaml.safe_load(open('dashboard-N-title.yaml'))\"</code></p> <p>Q: Chart shows \"No data available\"</p> <p>A: Verify: 1. CSV file exists in <code>outputs/dashboard/</code> 2. <code>data_file</code> in YAML matches CSV filename exactly 3. CSV contains data (not empty) 4. Required columns exist in CSV</p> <p>Q: Categories in wrong order</p> <p>A: Use <code>category_orders</code>:</p> <pre><code>category_orders:\n  distance_bin: ['&lt;1mi', '1-3mi', '3-5mi', '5-10mi', '10-20mi']\n</code></pre>"},{"location":"archived/validation-system/#performance-issues","title":"Performance Issues","text":"<p>Q: Summary generation takes too long</p> <p>A: Optimization strategies: 1. Generate only core summaries for quick checks: <pre><code>generate_summaries: \"core\"\n</code></pre></p> <ol> <li> <p>Process fewer model runs (comment out in <code>input_directories</code>)</p> </li> <li> <p>Use more specific filters to reduce data size</p> </li> </ol> <p>Q: Dashboard is slow</p> <p>A: Tips: 1. Limit number of facets (subplots) 2. Reduce number of model runs being compared 3. Pre-aggregate data more (fewer rows in CSV) 4. Consider using Parquet instead of CSV for large files</p>"},{"location":"archived/validation-system/#comparison-issues","title":"Comparison Issues","text":"<p>Q: Model and observed data don't align in charts</p> <p>A: Ensure matching: 1. Column names: Model and observed must use same names 2. Categories: Mode names, purpose names must match exactly 3. Dataset column: Observed data must include <code>dataset</code> column</p> <p>Q: How do I compare to previous model version?</p> <p>A: Add as separate input directory:</p> <pre><code>input_directories:\n  - path: \"/model_runs/v05\"\n    label: \"TM2.2 v05\"\n\n  - path: \"/model_runs/v06\"\n    label: \"TM2.2 v06\"\n</code></pre> <p>Both will appear in same charts for side-by-side comparison.</p>"},{"location":"archived/validation-system/#9-common-workflows","title":"9. Common Workflows","text":""},{"location":"archived/validation-system/#workflow-1-quick-model-run-validation","title":"Workflow 1: Quick Model Run Validation","text":"<pre><code># 1. Point to new model run\n# Edit validation_config.yaml:\n#   input_directories:\n#     - path: \"C:/new_model_run\"\n#       label: \"Test Run\"\n\n# 2. Generate core summaries only (fast)\n# Edit validation_config.yaml:\n#   generate_summaries: \"core\"\n\n# 3. Run and deploy\npython run_and_deploy_dashboard.py \\\n  --config validation_config.yaml \\\n  --launch-dashboard\n\n# 4. Review dashboard at http://localhost:8501\n</code></pre>"},{"location":"archived/validation-system/#workflow-2-adding-new-observed-data","title":"Workflow 2: Adding New Observed Data","text":"<pre><code># 1. Preprocess observed data to match model format\n# (Create CSV with same columns as model output + dataset column)\npython convert_acs_data.py\n\n# 2. Add to validation_config.yaml:\n#   observed_summaries:\n#     - name: \"acs_2023\"\n#       display_name: \"ACS 2023\"\n#       summaries:\n#         auto_ownership_regional:\n#           file: \"C:/data/acs_2023/acs_auto_ownership.csv\"\n#           columns:\n#             num_vehicles: \"num_vehicles\"\n#             households: \"households\"\n#             share: \"share\"\n\n# 3. Regenerate summaries (system auto-merges by matching name)\npython -m tm2py_utils.summary.validation.summaries.run_all \\\n  --config validation_config.yaml\n\n# 4. Verify combined file includes observed data\n# Check outputs/dashboard/auto_ownership_regional.csv\n</code></pre>"},{"location":"archived/validation-system/#workflow-3-creating-complete-new-analysis","title":"Workflow 3: Creating Complete New Analysis","text":"<pre><code># 1. Define summary in validation_config.yaml under summaries section\n\n# 2. Test generation\npython -m tm2py_utils.summary.validation.summaries.run_all \\\n  --config validation_config.yaml\n\n# 3. Create dashboard YAML (optional - for visualization)\n# dashboard/dashboard-households.yaml (or appropriate tab)\n\n# 4. Deploy dashboard\npython run_and_deploy_dashboard.py \\\n  --config validation_config.yaml \\\n  --launch-dashboard\n</code></pre>"},{"location":"archived/validation-system/#system-architecture_1","title":"System Architecture","text":""},{"location":"archived/validation-system/#summary-file-generation","title":"Summary File Generation","text":"<p>The validation system generates two types of CSV files for each summary:</p> <ol> <li>Per-Dataset Files: One file per input directory with dataset name in filename</li> <li>Example: <code>cdap_by_share_2023 TM2.2 v05.csv</code>, <code>cdap_by_share_2015 TM2.2 Sprint 04.csv</code></li> <li>Contains data for single model run only</li> <li> <p>Useful for debugging and individual analysis</p> </li> <li> <p>Combined Files: Single file merging all datasets with <code>dataset</code> column</p> </li> <li>Example: <code>cdap_by_share.csv</code> (contains rows for all datasets)</li> <li>Used by dashboard for multi-run comparisons</li> <li>Generated automatically in <code>save_summaries()</code> function</li> </ol> <p>File locations: - <code>outputs/</code> - All generated CSV files (both types) - <code>outputs/dashboard/</code> - Copy of all files for dashboard use - <code>summary_index.csv</code> - Metadata catalog of all generated summaries</p>"},{"location":"archived/validation-system/#how-summary-combination-works","title":"How Summary Combination Works","text":"<p>When you have multiple model runs configured (e.g., base year and plan year), the system:</p> <ol> <li>Generates individual summary for each dataset</li> <li>Groups summaries by base name (removes dataset suffix)</li> <li>Concatenates DataFrames and adds <code>dataset</code> column</li> <li>Saves combined file without dataset suffix</li> </ol> <p>Example: <pre><code># Generated files:\ncdap_by_share_2023 TM2.2 v05.csv      # 3 rows (H, M, N)\ncdap_by_share_2015 TM2.2 Sprint 04.csv  # 3 rows (H, M, N)\n\n# Combined automatically:\ncdap_by_share.csv                     # 6 rows (3 per dataset)\n</code></pre></p>"},{"location":"archived/validation-system/#dashboard-integration","title":"Dashboard Integration","text":"<p>Dashboard YAML files reference the combined files (without dataset suffix):</p> <pre><code>charts:\n  - type: bar\n    dataset: cdap_by_share.csv  # Combined file\n    x: cdap\n    y: share\n    color: dataset  # Splits bars by model run\n</code></pre> <p>The <code>facet: dataset</code> or <code>color: dataset</code> parameter creates side-by-side comparisons.</p>"},{"location":"archived/validation-system/#troubleshooting","title":"Troubleshooting","text":""},{"location":"archived/validation-system/#summary-not-generating","title":"Summary Not Generating","text":"<p>Check 1: Required columns exist in data</p> <p>Some summaries require columns that must be derived or joined from other sources:</p> <pre><code># Example: This will FAIL if person data doesn't have age_category\n- name: \"cdap_by_age\"\n  group_by: [\"cdap\", \"age_category\"]  # \u274c age_category doesn't exist\n</code></pre> <p>Solutions: - Check <code>personData_1.csv</code> columns: <code>python -c \"import pandas as pd; print(pd.read_csv('personData_1.csv', nrows=1).columns.tolist())\"</code> - Derive needed columns in data preprocessing - Comment out summary in <code>validation_config.yaml</code> if not feasible</p> <p>Check 2: Data source file exists</p> <pre><code># This fails if wsLocResults.csv is missing\n- name: \"journey_to_work\"\n  data_source: \"workplace_school\"  # Requires wsLocResults.csv\n</code></pre> <p>Check 3: Review summary_index.csv</p> <pre><code># See what actually generated\ncat outputs/dashboard/summary_index.csv | grep \"your_summary_name\"\n</code></pre>"},{"location":"archived/validation-system/#dashboard-shows-no-data","title":"Dashboard Shows No Data","text":"<p>Symptom: Chart area is blank or shows \"No data\"</p> <p>Common causes:</p> <ol> <li> <p>CSV file doesn't exist <pre><code># Check if file exists\nls outputs/dashboard/cdap_by_share.csv\n</code></pre></p> </li> <li> <p>Column names don't match <pre><code># Dashboard expects 'cdap' but CSV has 'cdap_pattern'\ncharts:\n  - x: cdap  # \u274c Column not found\n</code></pre></p> </li> <li> <p>Wrong file referenced (per-dataset instead of combined)    <pre><code># Wrong:\ndataset: cdap_by_share_2023 TM2.2 v05.csv\n\n# Right:\ndataset: cdap_by_share.csv\n</code></pre></p> </li> </ol> <p>Debug steps: <pre><code># Check CSV structure\npython -c \"import pandas as pd; df = pd.read_csv('outputs/dashboard/cdap_by_share.csv'); print(df.columns); print(df.head())\"\n</code></pre></p>"},{"location":"archived/validation-system/#known-limitations","title":"Known Limitations","text":"<p>Disabled Summaries (commented out in <code>validation_config.yaml</code>):</p> Summary Issue Solution Required <code>cdap_by_age</code> Needs <code>age_category</code> column Derive from <code>age</code> (e.g., &lt;18, 18-64, 65+) <code>cdap_by_home_county</code> Needs <code>county_name</code> column Join household geography or derive from MAZ <code>cdap_by_auto_ownership</code> Needs <code>num_vehicles</code> from household Join person to household data <code>journey_to_work</code> <code>workplace_school</code> data not loading Fix <code>wsLocResults.csv</code> data loading <code>journey_to_work_by_mode</code> <code>workplace_school</code> data not loading Fix <code>wsLocResults.csv</code> data loading <p>To enable these summaries: 1. Implement required data derivation/joins 2. Uncomment summary configuration in <code>validation_config.yaml</code> 3. Update dashboard YAML if needed 4. Test generation and verify output</p>"},{"location":"archived/validation-system/#additional-resources","title":"Additional Resources","text":"<ul> <li>Configuration Reference - Complete YAML syntax</li> <li>Dashboard Guide - Chart types and options</li> <li>Summary Generation - Aggregation and filtering</li> <li>Contributing Guide - Adding features</li> <li>Consolidation Proposal - System architecture</li> </ul>"},{"location":"archived/validation-system/#support","title":"Support","text":"<ul> <li>Issues: https://github.com/BayAreaMetro/tm2py-utils/issues</li> <li>Email: modeling@bayareametro.gov</li> <li>Documentation: https://bayareametro.github.io/tm2py-utils/</li> </ul>"}]}