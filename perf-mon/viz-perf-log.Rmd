---
title: "Performance Monitor vs Model Run Analysis"
author: "Suzanne Childress"
date: "`r Sys.Date()`"
output:
  html_document:
    highlight: tango
    theme: default
---

```{r setup, include=FALSE}
# Setup chunk: load libraries and set global options
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)

library(data.table)    # Fast data import and manipulation
library(tidyverse)     # ggplot2, dplyr, tidyr
library(lubridate)     # Date-time parsing (hms)
library(stringr)

# Set working directory to where your logs live
setwd("C:/GitHub/tm2py-utils/perf-mon")
```

# Convert .blg to CSV

```{r convert_blg, eval=FALSE, cache=TRUE}
# Skip conversion if CSV already exists
if (!file.exists("perfmon.csv")) {
  blg_files <- list.files(pattern = "\\.blg$", full.names = TRUE)
  blg_file  <- blg_files[which.max(file.info(blg_files)$mtime)]
  message("Starting relog conversion for: ", blg_file)
  system2(
    "relog",
    args = c(shQuote(blg_file), "-f", "CSV", "-o", "perfmon.csv"),
    stdout = "", stderr = ""
  )
  if (!file.exists("perfmon.csv")) stop("perfmon.csv not created. Check relog call.")
} else {
  message("perfmon.csv already exists; skipping conversion.")
}
```

# Read & Tidy Performance Monitor Data

```{r read_perf}
# Locate and read the CSV (skip first metadata line) using base R
perf_file <- list.files(pattern = "^perfmon\\.csv$", full.names = TRUE)[1]
perf_raw  <- read.csv(
  perf_file,
  sep          = ",",
  skip         = 0,
  header       = TRUE,
  check.names  = FALSE,
  comment.char = "",
  stringsAsFactors = FALSE
)

perf_raw <- perf_raw %>%
  filter(if_all(everything(), ~ !is.na(.) & . != ""))

# Rename first column to "Time"
names(perf_raw)[1] <- "Time"

# Simplify metric names: strip everything up to last backslash '\'
orig_names     <- names(perf_raw)
simple_names   <- c(
  "Time",
  gsub("^.*\\\\", "", orig_names[-1])
)
names(perf_raw) <- simple_names

# Pivot to long format and parse timestamps
perf <- perf_raw %>%
  pivot_longer(
    cols      = -Time,
    names_to  = "Metric",
    values_to = "Value"
  ) %>%
  mutate(
    Timestamp = today() + as.numeric(hms(Time)),
    Value     = as.numeric(Value)
  ) %>%
  select(Timestamp, Metric, Value)
```

# Read & Parse Model Run Log

```{r read_model_logs}
model_files <- list.files(pattern = "^tm2py_run.*\\.log$", full.names = TRUE)
message("Found log files: ", paste(basename(model_files), collapse=", "))
if (length(model_files) == 0) {
  stop("No tm2py_run log files found in working directory: ", getwd())
}
model_log <- model_files[which.max(file.info(model_files)$mtime)]
message("Using log file: ", basename(model_log))

lines <- readLines(model_log)

```

```{r parse_model_logs}
# Define pattern: captures Date, Time, Level, and Message
datetime_str <- gsub("[()]", "", substr(lines, 1, 22))
Timestamp    <- dmy_hms(datetime_str)

# Extract Level and Message by splitting at first colon after timestamp
# Remove the timestamp and any leading spaces
rest <- substr(lines, 23, nchar(lines))
# Level is before first ':'
Level   <- str_trim(sub(":.*$", "", rest))
# Message is after the first ':'
Message <- str_trim(sub("^[^:]+:\\s*", "", rest))

# Build events tibble
model_events <- tibble(
  Timestamp = Timestamp,
  Level     = Level,
  Message   = Message
) %>%
  filter(Level %in% c("INFO", "STATUS"))
```


# Visualizations with ggplot2

```{r plot_cpu_mem}
# CPU & Memory usage
cpu_mem <- perf %>%
  filter(str_detect(Metric, "% Processor Time") |
         str_detect(Metric, "Available MBytes") |
         str_detect(Metric, "Pages/sec"))

ggplot(cpu_mem, aes(x = Timestamp, y = Value, color = Metric)) +
  geom_line() +
  geom_vline(data = model_events, aes(xintercept = Timestamp),
             linetype = "dashed", color = "red", alpha = 0.6) +
  labs(
    title = "CPU & Memory Usage",
    x     = "Time",
    y     = "Value"
  ) +
  theme_minimal()
```

```{r plot_io_net}
# Disk I/O & Network throughput
io_net <- perf %>%
  filter(str_detect(Metric, "Avg\\. Disk sec/Read") |
         str_detect(Metric, "Avg\\. Disk sec/Write") |
         str_detect(Metric, "Current Disk Queue Length") |
         str_detect(Metric, "Bytes Total/sec"))

ggplot(io_net, aes(x = Timestamp, y = Value, color = Metric)) +
  geom_line() +
  geom_vline(data = model_events, aes(xintercept = Timestamp),
             linetype = "dashed", alpha = 0.5) +
  labs(
    title = "Disk I/O & Network Throughput",
    x     = "Time",
    y     = "Value"
  ) +
  theme_minimal()
```

```{r plot_faceted}
# Faceted view of key metrics
perf %>%
  filter(str_detect(Metric, "% Processor Time") |
         str_detect(Metric, "Available MBytes") |
         str_detect(Metric, "Pages/sec") |
         str_detect(Metric, "Avg\\. Disk sec") |
         str_detect(Metric, "Bytes Total/sec") |
         str_detect(Metric, "Context Switches/sec") |
         str_detect(Metric, "% Usage")) %>%
  ggplot(aes(x = Timestamp, y = Value)) +
  geom_line() +
  facet_wrap(~ Metric, scales = "free_y", ncol = 1) +
  geom_vline(data = model_events, aes(xintercept = Timestamp),
             linetype = "dashed", alpha = 0.5) +
  labs(
    title = "PerfMon Counters with Model Events",
    x     = "Time",
    y     = "Value"
  ) +
  theme_minimal()
```

# Save Plots to Files

```{r save_plots}
ggsave("cpu_mem_vs_model.png", width = 10, height = 6)
ggsave("io_net_vs_model.png",  width = 10, height = 6)
ggsave("faceted_counters.png", width = 6,  height = 10)
```




