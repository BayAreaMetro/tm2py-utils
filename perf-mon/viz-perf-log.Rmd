---
title: "Performance Monitor vs Model Run Analysis"
author: "Suzanne Childress"
date: "`r Sys.Date()`"
output:
  html_document:
    highlight: tango  # code highlighting style with gray background for code blocks
    theme: default
editor_options: 
  markdown: 
    wrap: 72
---

<!-- Custom CSS to ensure code blocks have a gray background -->

```{=html}
<style>
pre, code {
  background-color: #f5f5f5;
  padding: 8px;
  border-radius: 4px;
}
</style>
```

```{r setup, include=FALSE}
# Setup chunk: load libraries and set global options
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  background = "#f5f5f5"  # ensures code chunk background in some themes
)

library(data.table)    # Fast data import and manipulation
library(tidyverse)     # ggplot2, dplyr, tidyr
library(lubridate)     # Date-time parsing
library(fuzzyjoin)     # Rolling/fuzzy joins if needed

# Set working directory to where your logs live
setwd("C:/GitHub/tm2py-utils/perf-mon")
```

# Convert .blg to CSV

```{=html}
<!--
We detect the most recent .blg file and convert it with relog.exe.
This requires that relog.exe be on your PATH (Windows).
-->
```

```{r convert_blg, eval=FALSE}
# Find latest .blg file
blg_files <- list.files(pattern = "\\.blg$", full.names = TRUE)
blg_file  <- blg_files[which.max(file.info(blg_files)$mtime)]

# Convert to CSV (adjust output filename if you like)
system2("relog", args = c(shQuote(blg_file), "-f", "CSV", "-o", "perfmon.csv"))
```

# Read & Tidy Performance Monitor Data

```{r read_perf}
# Locate the CSV just created
perf_csvs <- list.files(pattern = "perfmon\\.csv$", full.names = TRUE)
perf_file <- perf_csvs[1]

# Read and tidy
perf_raw <- fread(perf_file, skip = 1)
perf <- perf_raw %>%
  rename(Timestamp = `#DateTime`) %>%
  mutate(
    Timestamp = mdy_hms(Timestamp),    # parse timestamp
    across(-Timestamp, as.numeric)     # convert counters to numeric
  ) %>%
  pivot_longer(
    -Timestamp,
    names_to  = "Metric",
    values_to = "Value"
  )
```

# Read & Parse Model Run Log

```{r read_model_logs}
# Find the most recent model-run log (starts with tm2py_run)
log_files <- list.files(pattern = "^tm2py_run.*\\.txt$", full.names = TRUE)
model_log <- log_files[which.max(file.info(log_files)$mtime)]

# Extract timestamp and message
lines <- readLines(model_log)
model_events <- tibble(raw = lines) %>%
  extract(
    raw,
    into  = c("Timestamp", "Level", "Message"),
    regex = "^(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\s+(\\w+):\\s+(.*)$"
  ) %>%
  mutate(
    Timestamp = ymd_hms(Timestamp)
  ) %>%
  select(Timestamp, Level, Message)
```

# Visualizations with ggplot2

Below we overlay model-run events as dashed vertical lines on various
PerfMon counters.

```{r plot_cpu_mem}
# CPU & Memory usage
cpu_mem <- perf %>%
  filter(Metric %in% c(
    "Processor(_Total)_% Processor Time",
    "Memory_% Committed Bytes In Use"
  ))

ggplot(cpu_mem, aes(x = Timestamp, y = Value, color = Metric)) +
  geom_line() +
  geom_vline(data = model_events, aes(xintercept = Timestamp),
             linetype = "dashed", color = "red", alpha = 0.6) +
  geom_text(data = model_events,
            aes(x = Timestamp, y = Inf, label = Message),
            angle = 90, vjust = -0.5, hjust = 0, size = 2.5) +
  labs(
    title = "CPU & Memory Usage vs Model Steps",
    x     = "Time",
    y     = "Value",
    color = "Metric"
  ) +
  theme_minimal()
```

\`\`\`{r plot_io_net} \# Disk I/O & Network throughput io_net \<- perf
%\>% filter(Metric %in% c( "PhysicalDisk(\_Total)\_Disk Transfers/sec",
"Network Interface(\_Total)\_Bytes Total/sec" ))

ggplot(io_net, aes(x = Timestamp, y = Value, color = Metric)) +
geom_line() + geom_vline(data
